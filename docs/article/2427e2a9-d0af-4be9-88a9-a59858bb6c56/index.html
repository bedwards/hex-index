<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Deep Learning Weekly: Issue 426 - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Deep Learning Weekly: Issue 426</h1>
        <div class="article-meta">
          <span class="author">By Various</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/deeplearningweekly/index.html" class="publication">
            Deep Learning Weekly
          </a>
          <span class="separator">&middot;</span><time>Oct 15, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">5 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>This week in deep learning, we bring you <a href="https://cloud.google.com/blog/products/ai-machine-learning/introducing-gemini-enterprise">Introducing Gemini Enterprise</a>, <a href="https://www.anthropic.com/research/small-samples-poison">A small number of samples can poison LLMs of any size</a>, and <a href="https://arxiv.org/abs/2506.10943">a paper on Self-Adapting Language Models</a>.</p><p>You may also enjoy <a href="https://microsoft.ai/news/introducing-mai-image-1-debuting-in-the-top-10-on-lmarena/">Microsoft AI’s MAI-Image-1</a>, <a href="https://www.philschmid.de/agents-2.0-deep-agents">Agents 2.0: From Shallow Loops to Deep Agents</a>, <a href="https://cohere.com/research/papers/making-not-taking-the-best-of-n-2025-10-01">a paper on Making, not Taking, the Best of N</a>, and more!</p><p>As always, happy reading and hacking. If you have something you think should be in next week’s issue, find us on Twitter: <a href="https://twitter.com/dl_weekly">@dl_weekly</a>.</p><p>Until next week!</p><div><hr></div><h2><strong>Industry</strong></h2><p><strong><a href="https://cloud.google.com/blog/products/ai-machine-learning/introducing-gemini-enterprise">Introducing Gemini Enterprise</a></strong></p><p>Google introduced Gemini Enterprise, a complete, AI-optimized platform that includes a no-code workbench, a centralized government framework, as well as various integrations to existing business applications.</p><p><strong><a href="https://microsoft.ai/news/introducing-mai-image-1-debuting-in-the-top-10-on-lmarena/">Introducing MAI-Image-1, debuting in the top 10 on LMArena</a></strong></p><p>Microsoft AI announced MAI-Image-1, their first image generation model developed entirely in-house, debuting in the top 10 text-to-image models on LMArena.</p><p><strong><a href="https://techcrunch.com/2025/10/13/salesforce-announces-agentforce-360-as-enterprise-ai-competition-heats-up/">Salesforce announces Agentforce 360 as enterprise AI competition heats up</a></strong></p><p>Salesforce announced the latest version of Agentforce 360, which includes new ways to instruct, build, and deploy AI agents.</p><p><strong><a href="https://siliconangle.com/2025/10/09/kernel-raises-22m-power-browser-infrastructure-ai-agents/">Kernel raises $22M to power browser infrastructure for AI agents</a></strong></p><p>Kernel has raised $22 million in funding to scale its platform so AI agents can reliably navigate, persist, and use the web.</p><h2><strong>MLOps &amp; LLMOps</strong></h2><p><strong><a href="https://www.philschmid.de/agents-2.0-deep-agents">Agents 2.0: From Shallow Loops to Deep Agents</a></strong></p><p>An architectural post about the shift from “Shallow Agents” to “Deep Agents” that utilize explicit planning, sub-agents, and persistent memory to solve complex, multi-step problems.</p><p><strong><a href="https://www.letta.com/blog/letta-v1-agent">Rearchitecting Letta’s Agent Loop: Lessons from ReAct, MemGPT, &amp; Claude Code</a></strong></p><p>A technical post detailing the rearchitecture of Letta’s agent loop, transitioning from older models like MemGPT to a V1 design leveraging modern LLM capabilities such as native reasoning.</p><p><strong><a href="https://blog.langchain.com/agent-authorization-explainer/">Securing your agents with authentication and authorization</a></strong></p><p>An article on securing agents by implementing authentication and authorization (AuthN/AuthZ), addressing their dynamic access needs.</p><h2><strong>Learning</strong></h2><p><strong><a href="https://www.anthropic.com/research/small-samples-poison">A small number of samples can poison LLMs of any size \ Anthropic</a></strong></p><p>An article about data-poisoning attacks shows that as few as 250 malicious documents can backdoor LLMs of any size, challenging the assumption that attackers need to control a percentage of training data.</p><p><strong><a href="https://weaviate.io/blog/when-good-models-go-bad">When Good Models Go Bad</a></strong></p><p>A strategic blog post analyzing the high costs and risks of upgrading vector embedding models at scale, offering a decision framework that balances cutting-edge performance with stability and operational constraints.</p><p><strong><a href="https://www.lesswrong.com/posts/qgvSMwRrdqoDMJJnD/towards-a-typology-of-strange-llm-chains-of-thought">Towards a Typology of Strange LLM Chains-of-Thought</a></strong></p><p>A post outlining six ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://www.deeplearningweekly.com/p/deep-learning-weekly-issue-426" class="read-button" target="_blank" rel="noopener">
          Read full article on Deep Learning Weekly &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>