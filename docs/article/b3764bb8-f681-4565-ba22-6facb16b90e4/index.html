<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI leaderboards are no longer useful. It&#039;s time to switch to Pareto curves. - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>AI leaderboards are no longer useful. It&#039;s time to switch to Pareto curves.</h1>
        <div class="article-meta">
          <span class="author">By Arvind Narayanan</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/aisnakeoil/index.html" class="publication">
            AI Snake Oil
          </a>
          <span class="separator">&middot;</span><time>Apr 30, 2024</time>
          <span class="separator">&middot;</span>
          <span class="read-time">19 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p><em>By Sayash Kapoor, <a href="https://citp.princeton.edu/citp-people/benedikt-strobl/">Benedikt Stroebl</a>, Arvind Narayanan</em></p><p>Which is the most accurate AI system for generating code? Surprisingly, there isn’t currently a good way to answer questions like these.&nbsp; </p><p>Based on <a href="https://paperswithcode.com/sota/code-generation-on-humaneval">HumanEval</a>, a widely used benchmark for code generation, the most accurate publicly available system is <a href="https://arxiv.org/abs/2402.16906">LDB</a> (short for LLM debugger).<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1" href="#footnote-1" target="_self">1</a> But there’s a catch. The most accurate generative AI systems, including LDB, tend to be agents,<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2" href="#footnote-2" target="_self">2</a> which repeatedly invoke language models like GPT-4. That means they can be orders of magnitude more costly to run than the models themselves (which are already pretty costly). If we eke out a 2% accuracy improvement for 100x the cost, is that really better?</p><p>In this post, we argue that:</p><ul><li><p>AI agent accuracy measurements that don’t control for cost aren’t useful.</p></li><li><p>Pareto curves can help visualize the accuracy-cost tradeoff.</p></li><li><p>Current state-of-the-art agent architectures are complex and costly but no more accurate than extremely simple baseline agents that cost 50x less in some cases.</p></li><li><p>Proxies for cost such as parameter count are misleading if the goal is to identify the best system for a given task. We should directly measure dollar costs instead.</p></li><li><p>Published agent evaluations are difficult to reproduce because of a lack of standardization and questionable, undocumented evaluation methods in some cases.</p></li></ul><h4><strong>Maximizing accuracy can lead to unbounded cost</strong></h4><p>LLMs are stochastic. Simply calling a model <a href="https://arxiv.org/abs/2402.05120">many</a> <a href="https://arxiv.org/pdf/2403.02419.pdf">times</a> and outputting the most common answer can increase accuracy.&nbsp;</p><p>On some tasks, there is seemingly no limit to the amount of inference compute that can improve accuracy.<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3" href="#footnote-3" target="_self">3</a> Google Deepmind's <a href="https://arxiv.org/pdf/2203.07814.pdf">AlphaCode</a>, which improved accuracy on automated coding evaluations, showed that this trend holds even when calling LLMs millions of times.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!2od5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa22df54d-213b-44da-aacd-a55fb24f9089_688x544.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2od5!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa22df54d-213b-44da-aacd-a55fb24f9089_688x544.jpeg 424w, https://substackcdn.com/image/fetch/$s_!2od5!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa22df54d-213b-44da-aacd-a55fb24f9089_688x544.jpeg 848w, https://substackcdn.com/image/fetch/$s_!2od5!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa22df54d-213b-44da-aacd-a55fb24f9089_688x544.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!2od5!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa22df54d-213b-44da-aacd-a55fb24f9089_688x544.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2od5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa22df54d-213b-44da-aacd-a55fb24f9089_688x544.jpeg" width="472" height="373.2093023255814" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a22df54d-213b-44da-aacd-a55fb24f9089_688x544.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:544,&quot;width&quot;:688,&quot;resizeWidth&quot;:472,&quot;bytes&quot;:64235,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2od5!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa22df54d-213b-44da-aacd-a55fb24f9089_688x544.jpeg 424w, https://substackcdn.com/image/fetch/$s_!2od5!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa22df54d-213b-44da-aacd-a55fb24f9089_688x544.jpeg 848w, https://substackcdn.com/image/fetch/$s_!2od5!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa22df54d-213b-44da-aacd-a55fb24f9089_688x544.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!2od5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa22df54d-213b-44da-aacd-a55fb24f9089_688x544.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a><figcaption class="image-caption"><em>The accuracy of <a href="https://arxiv.org/pdf/2203.07814.pdf">AlphaCode</a> on coding tasks continues to improve even after making a million calls to the underlying model (the different curves represent varying parameter counts). Accuracy is measured by how often one of the top 10 answers generated by the model is correct.</em></figcaption></figure></div><p>A useful evaluation of agents must therefore ask: What did it cost? If we don’t do cost-controlled comparisons, it will encourage researchers to develop extremely costly agents just to claim they topped the leaderboard.</p><p>In fact, when we evaluate agents that have been proposed in the last year for solving coding tasks, we find that visualizing the tradeoff between cost and accuracy yields surprising insights.&nbsp;</p><h4><strong>Visualizing the accuracy-cost tradeoff on HumanEval, with new baselines</strong></h4><p>We </p>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://www.normaltech.ai/p/ai-leaderboards-are-no-longer-useful" class="read-button" target="_blank" rel="noopener">
          Read full article on AI Snake Oil &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>