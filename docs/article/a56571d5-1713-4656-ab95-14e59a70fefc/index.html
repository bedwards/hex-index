<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>New paper: AI agents that matter - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>New paper: AI agents that matter</h1>
        <div class="article-meta">
          <span class="author">By Arvind Narayanan</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/aisnakeoil/index.html" class="publication">
            AI Snake Oil
          </a>
          <span class="separator">&middot;</span><time>Jul 3, 2024</time>
          <span class="separator">&middot;</span>
          <span class="read-time">8 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>Some of the most exciting applications of large language models involve taking real-world action, such as booking flight tickets or finding and fixing software bugs. AI systems that carry out such tasks are called agents. They use LLMs in combination with other software to use tools such as web search and code terminals. </p><p>The North Star of this field is to build assistants like Siri or Alexa and get them to actually work — handle complex tasks, accurately interpret users’ requests, and perform reliably. But this is far from a reality, and even the research direction is fairly new. To stimulate the development of agents and measure their effectiveness, researchers have created benchmark datasets. But as we’ve said before, <a href="https://www.cs.princeton.edu/~arvindn/talks/evaluating_llms_minefield/">LLM evaluation is a minefield</a>, and it turns out that agent evaluation has a bunch of additional pitfalls that affect today’s benchmarks and evaluation practices. This state of affairs encourages the development of agents that do well on benchmarks without being useful in practice.</p><p>We have released a new paper that identifies the challenges in evaluating agents and proposes ways to address them. <strong>Read the paper <a href="https://arxiv.org/abs/2407.01502">here</a>. </strong>The authors are Sayash Kapoor, <a href="https://citp.princeton.edu/citp-people/benedikt-strobl/">Benedikt Ströbl</a>, <a href="https://www.zacharysiegel.org/">Zachary S. Siegel</a>, <a href="https://citp.princeton.edu/citp-people/nitya-nadgir/">Nitya Nadgir</a>, and Arvind Narayanan, all at Princeton University.&nbsp;</p><p>In this post, we offer thoughts on the definition of AI agents, why we are cautiously optimistic about the future of AI agent research, whether AI agents are more hype or substance, and give a brief overview of the paper.</p><h4><strong>What does the term agent mean? Is it just a buzzword?</strong></h4><p>The term agent has been used by AI researchers without a formal definition.<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1" href="#footnote-1" target="_self">1</a> This has led to its being hijacked as a marketing term, and has generated a bit of pushback against its use. But the term isn’t meaningless. Many researchers have tried to formalize the community's intuitive understanding of what constitutes an agent in the context of language-model-based systems [<a href="https://cdn.openai.com/papers/practices-for-governing-agentic-ai-systems.pdf">1</a>, <a href="https://dl.acm.org/doi/10.1145/3593013.3594033">2</a>, <a href="https://arxiv.org/abs/2404.16244">3</a>, <a href="https://lilianweng.github.io/posts/2023-06-23-agent/">4</a>, <a href="https://blog.langchain.dev/what-is-an-agent/">5</a>]. Rather than a binary, it can be seen as a spectrum, sometimes denoted by the term <a href="https://www.deeplearning.ai/the-batch/welcoming-diverse-approaches-keeps-machine-learning-strong/">'agentic'</a>.&nbsp;</p><p>The five recent definitions of AI agents cited above are all distinct but with strong similarities to each other. Rather than propose a new definition, we identified three clusters of properties that cause an AI system to be considered more agentic according to existing definitions:</p><p><strong>Environment and goals.</strong> The ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://www.normaltech.ai/p/new-paper-ai-agents-that-matter" class="read-button" target="_blank" rel="noopener">
          Read full article on AI Snake Oil &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>