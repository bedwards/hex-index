<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Generate Better Synthetic Datasets with a &quot;User&quot; LLM - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Generate Better Synthetic Datasets with a &quot;User&quot; LLM</h1>
        <div class="article-meta">
          <span class="author">By Various</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/kaitchup/index.html" class="publication">
            The Kaitchup
          </a>
          <span class="separator">&middot;</span><time>Oct 27, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">2 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!KnEs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84da9710-360e-471d-b5aa-435f70016320_1024x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!KnEs!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84da9710-360e-471d-b5aa-435f70016320_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!KnEs!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84da9710-360e-471d-b5aa-435f70016320_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!KnEs!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84da9710-360e-471d-b5aa-435f70016320_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!KnEs!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84da9710-360e-471d-b5aa-435f70016320_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!KnEs!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84da9710-360e-471d-b5aa-435f70016320_1024x1024.png" width="408" height="408" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/84da9710-360e-471d-b5aa-435f70016320_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:408,&quot;bytes&quot;:2025256,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://kaitchup.substack.com/i/176119562?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84da9710-360e-471d-b5aa-435f70016320_1024x1024.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!KnEs!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84da9710-360e-471d-b5aa-435f70016320_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!KnEs!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84da9710-360e-471d-b5aa-435f70016320_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!KnEs!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84da9710-360e-471d-b5aa-435f70016320_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!KnEs!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84da9710-360e-471d-b5aa-435f70016320_1024x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a><figcaption class="image-caption">Image generated with ChatGPT</figcaption></figure></div><p>Most guides on synthetic data start from the assistant’s point of view. You prompt an instruct model with a “persona,” ask for user messages, and let it role-play both sides of a conversation. That’s convenient, but there’s a hidden mismatch: instruct models are fine-tuned and aligned to <em>be helpful assistants</em>, not to <em>behave like users</em>. When you ask them to generate “user” turns, they tend to speak like assistants in disguise, too cooperative, too formal, too on-task. This skews the distribution of user intents, errors, and edge cases, which then flows straight into your synthetic dataset.</p><p>A better approach is to split responsibilities. Keep a standard instruct model for the assistant side, and introduce a second model that is fine-tuned specifically to act like a user. Think of this “User LLM” as a generator of realistic user goals, constraints, hesitations, and mistakes. <strong>It can ask incomplete questions, follow odd preferences, change its mind, and produce the kind of messy inputs assistants see in the wild. </strong>Pairing the two models produces richer dialogs and, in turn, more faithful training data for downstream tasks like intent classification, tool-use planning, and multi-turn guidance.</p><p>In this article, we’ll run an assistant-tuned instruct model alongside a User LLM, <a href="https://arxiv.org/abs/2510.06552">the one recently introduced by Microsoft</a>, and have them converse to produce dialog-style synthetic datasets. If you have two GPUs, vLLM makes this straightforward: load both models as separate engines and stream turns between them. Many of us don’t have that headroom, though, so we’ll plan for a single consumer GPU setup.</p><p>Here is my notebook showing how to generate synthetic dialogues with two LLMs:</p><p>Each part of the code is explained below.</p>
      <p>
          <a href="https://kaitchup.substack.com/p/generate-better-synthetic-datasets">
              Read more
          </a>
      </p></source>
      </div>

      <div class="read-full-article">
        <a href="https://kaitchup.substack.com/p/generate-better-synthetic-datasets" class="read-button" target="_blank" rel="noopener">
          Read full article on The Kaitchup &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>