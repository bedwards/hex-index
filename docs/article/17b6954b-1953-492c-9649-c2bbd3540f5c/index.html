<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The Necessity of Overfitting LLM Applications - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>The Necessity of Overfitting LLM Applications</h1>
        <div class="article-meta">
          <span class="author">By Various</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/nobsai/index.html" class="publication">
            NO BS AI
          </a>
          <span class="separator">&middot;</span><time>Dec 6, 2024</time>
          <span class="separator">&middot;</span>
          <span class="read-time">8 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>In this post I will explain:</p><ol><li><p>How to quickly automate parts of customer service traffic with minimal investment.</p></li><li><p>Which technology to use for achieving a high ROI on your first automation solution.</p></li><li><p>The challenges encountered when using AI for the seemingly simple task of email classification.</p></li></ol><div><hr></div><p>To create an effective automated customer support solution, it’s essential to view it as a system of interconnected components working seamlessly together.</p><p>Previously, <a href="https://nobsai.substack.com/p/want-to-unlock-answers-from-your">we’ve discussed RAG (Retrieval Augmented Generation)</a> and why it is often the preferred choice for automating customer service. </p><blockquote><p>However, a significant challenge remains: many companies lack a well-structured knowledge base. As a result, applying the standard RAG approach—which relies on high-quality data and organized knowledge—becomes difficult.</p></blockquote><p>That said, even without an optimal dataset, the capabilities of modern LLMs (Large Language Models) offer an opportunity to take a crucial first step and achieve two key objectives simultaneously:</p><ol><li><p>Deeply understand your data and evaluate the technical feasibility of automating 20%, 40%, 60%, or even 90% of customer requests.</p></li><li><p>Implement an initial automation solution that delivers immediate, measurable business impact.</p></li></ol><p>I firmly believe in the <strong>“low-hanging fruit” approach</strong>. While it may sound like a cliché, my experience shows it builds trust and helps uncover unknowns. You can’t fully anticipate the challenges or benefits until you begin testing and iterating.</p><p>For many companies, a significant portion of incoming customer requests are repetitive. While they may not appear so at first glance—since each issue is described differently and reflects the unique perspective of the customer—the underlying problem is often the same.</p><h3>In my experience, a considerable percentage of these inquiries involve recurring questions that human customer support routinely addresses.</h3><p>This process, which often requires agents to send standardized responses, is both <strong>monotonous and unnecessary</strong> given current technological advancements.</p><p>Before the advent of LLMs, automating such workflows required training a classification model. Each email would be categorized into a specific topic, and once classified, a predefined template would be used to respond to the customer. This process, while functional, was far more labor-intensive and less adaptable than modern solutions.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!-6EM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d6f1236-47b3-4fe0-be57-7f600210a8de_1920x1080.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!-6EM!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d6f1236-47b3-4fe0-be57-7f600210a8de_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!-6EM!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d6f1236-47b3-4fe0-be57-7f600210a8de_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!-6EM!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d6f1236-47b3-4fe0-be57-7f600210a8de_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!-6EM!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d6f1236-47b3-4fe0-be57-7f600210a8de_1920x1080.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!-6EM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d6f1236-47b3-4fe0-be57-7f600210a8de_1920x1080.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3d6f1236-47b3-4fe0-be57-7f600210a8de_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:153541,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!-6EM!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d6f1236-47b3-4fe0-be57-7f600210a8de_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!-6EM!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d6f1236-47b3-4fe0-be57-7f600210a8de_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!-6EM!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d6f1236-47b3-4fe0-be57-7f600210a8de_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!-6EM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d6f1236-47b3-4fe0-be57-7f600210a8de_1920x1080.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a></figure></div><p>This approach has a relatively low ROI because it requires extensive data collection and annotation. For instance, if you introduce a new feature and customers frequently ask specific questions about it, <strong>updating the system is impossible without retraining</strong>. Moreover, since this solution is not generative, it remains imperfect and inflexible. </p><p>In contrast, LLMs do not have </p>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://nobsai.substack.com/p/the-necessity-of-overfitting-llm" class="read-button" target="_blank" rel="noopener">
          Read full article on NO BS AI &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>