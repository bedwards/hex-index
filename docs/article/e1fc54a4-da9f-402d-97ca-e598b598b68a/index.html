<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Mistral Large 3: Not a Reasoning Model - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Mistral Large 3: Not a Reasoning Model</h1>
        <div class="article-meta">
          <span class="author">By Various</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/kaitchup/index.html" class="publication">
            The Kaitchup
          </a>
          <span class="separator">&middot;</span><time>Dec 5, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">4 min read</span>
        </div>
      </header>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/conference-on-neural-information-processing-systems/index.html">
          <strong>Conference on Neural Information Processing Systems</strong>
          <span class="read-time">11 min read</span>
        </a>
        <p class="topic-summary">The article extensively discusses NeurIPS attendance growth and format changes. Understanding the history and significance of this flagship ML conference provides valuable context for why Mistral chose this venue for their release and the conference&#039;s evolution from 4k to 29k attendees.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/prompt-engineering/index.html">
          <strong>Prompt engineering</strong>
          <span class="read-time">13 min read</span>
        </a>
        <p class="topic-summary">The core distinction the article makes between &#039;instruct&#039; and &#039;reasoning&#039; models hinges on chain-of-thought techniques. Understanding this prompting methodology explains why reasoning models generate 10x more tokens and why the author emphasizes this is &#039;not a reasoning model.&#039;</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/floating-point-arithmetic/index.html">
          <strong>Floating-point arithmetic</strong>
          <span class="read-time">7 min read</span>
        </a>
        <p class="topic-summary">The article discusses FP8 vs BF16 model variants and post-training quantization. Understanding floating-point precision helps readers grasp why these format choices matter for model behavior and why &#039;dequantized&#039; BF16 versions might behave differently from native training.</p>
      </li>
        </ul>
      </section>
    

      <div class="article-excerpt">
        <div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!c7_f!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!c7_f!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png 424w, https://substackcdn.com/image/fetch/$s_!c7_f!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png 848w, https://substackcdn.com/image/fetch/$s_!c7_f!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png 1272w, https://substackcdn.com/image/fetch/$s_!c7_f!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!c7_f!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png" width="1456" height="815" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:815,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:245022,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://kaitchup.substack.com/i/167992895?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!c7_f!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png 424w, https://substackcdn.com/image/fetch/$s_!c7_f!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png 848w, https://substackcdn.com/image/fetch/$s_!c7_f!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png 1272w, https://substackcdn.com/image/fetch/$s_!c7_f!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a></figure></div><p>Hi everyone,</p><p>In this edition of The Weekly Kaitchup, I briefly discuss Mistral AI’s new (and somewhat unusual) releases.</p><div><hr></div><p>I’m currently at NeurIPS. There are about 29k attendees this year (including virtual), up 64% compared to last year. Ten years ago in Montreal, 4k participants already felt like a huge conference. At this pace, 100k people by 2030 doesn’t sound impossible. </p><p>This year, they tried to split the conference over three venues (San Diego, Mexico City, and Copenhagen), but unsurprisingly, most people want to be at the main site, in this case San Diego. Also: so many sponsors. It feels more and more like a trade expo!</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!Hlnx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Hlnx!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png 424w, https://substackcdn.com/image/fetch/$s_!Hlnx!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png 848w, https://substackcdn.com/image/fetch/$s_!Hlnx!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png 1272w, https://substackcdn.com/image/fetch/$s_!Hlnx!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Hlnx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png" width="1225" height="603" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:603,&quot;width&quot;:1225,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1231116,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://kaitchup.substack.com/i/180319476?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Hlnx!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png 424w, https://substackcdn.com/image/fetch/$s_!Hlnx!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png 848w, https://substackcdn.com/image/fetch/$s_!Hlnx!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png 1272w, https://substackcdn.com/image/fetch/$s_!Hlnx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aabc6e8-9557-4d4c-ac2a-e30a3d7b57e0_1225x603.png 1456w" sizes="100vw"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a></figure></div><div><hr></div><h2>Mistral Large 3: not a reasoning model</h2><p>Mistral AI knows how to get attention: they released a large open model on the first day of NeurIPS. It worked. Everyone is talking about it, but many are missing a key point: <strong>Mistral Large 3 is not a reasoning model.</strong></p><ul><li><p><a href="https://huggingface.co/collections/mistralai/mistral-large-3">Mistral Large 3</a></p></li></ul><p>Despite this, I saw third-party evaluations placing it on the same charts as reasoning models, often flagged with a “reasoning” icon or bubble that is very easy to miss.</p><p>This is misleading. Mistral Large 3 is an instruct model, not a long-chain-of-thought “thinking” model. Quite unusual for a model of that size. Artificial Analysis <a href="https://artificialanalysis.ai/models/mistral-large-3">confirms this: Mistral Large 3 generates 10 times fewer tokens</a> than KIMI K2 Thinking and GPT-OSS 120B (reasoning_effort=”high”).</p><p>Why did Mistral AI only release an instruct version?</p><p>I can see several plausible reasons:</p><ul><li><p><strong>Positioning:</strong> It’s one of the only instruct models at that scale, so they may want to focus on making that variant broadly available and reliable before investing in a public reasoning counterpart.</p></li><li><p><strong>Product strategy:</strong> They may already have a reasoning version but prefer to keep it private for their paid API customers rather than releasing it openly.</p></li><li><p><strong>Demand:</strong> “Thinking” models are much less popular than instruct models. <a href="https://huggingface.co/models">Hugging Face’s trending models page</a> shows this clearly. Most users don’t want to wait minutes for each answer.</p></li></ul><div><hr></div><h2>Ministral 3: base, reasoning, and instruct “small” models</h2><p>Mistral AI also released the Ministral 3 family: multimodal models at 3B, 8B, and 14B. </p><ul><li><p><a href="https://huggingface.co/collections/mistralai/ministral-3">Ministral 3</a></p></li></ul><p>These are more “regularly sized” models, but the release has a few unusual aspects:</p><ul><li><p><strong>No official multimodal benchmarks:</strong> The models are multimodal, but Mistral didn’t publish benchmark numbers. Evaluation is effectively delegated to the community.</p></li><li><p><strong>Instruct = FP8 post-trained:</strong> The instruct models are available in </p></li></ul></source>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://kaitchup.substack.com/p/mistral-large-3-not-a-reasoning-model" class="read-button" target="_blank" rel="noopener">
          Read full article on The Kaitchup &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>