<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>GPU Networking Basics Part 3: Scale-Out  - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>GPU Networking Basics Part 3: Scale-Out </h1>
        <div class="article-meta">
          <span class="author">By Various</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/chipstrat/index.html" class="publication">
            Chipstrat
          </a>
          <span class="separator">&middot;</span><time>Sep 8, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">24 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>AI networking is heating up, and Chipstrat is here to make sense of it. If you‚Äôre new to the series, start with Part 1 and Part 2. In Part 3 we go deeper on scale-out networking for AI and why it matters for training at cluster scale.</p><div class="digest-post-embed" data-attrs="{&quot;nodeId&quot;:&quot;4c472978-8aea-4ad3-98ce-7dc8b80d7a96&quot;,&quot;caption&quot;:&quot;We‚Äôre going to very gently discuss networking and GPUs. It‚Äôs an important topic, but it can feel boring or esoteric. Hang with me!&quot;,&quot;cta&quot;:&quot;Read full story&quot;,&quot;showBylines&quot;:true,&quot;size&quot;:&quot;sm&quot;,&quot;isEditorNode&quot;:true,&quot;title&quot;:&quot;GPU Networking Basics, Part 1&quot;,&quot;publishedBylines&quot;:[{&quot;id&quot;:8066776,&quot;name&quot;:&quot;Austin Lyons&quot;,&quot;bio&quot;:&quot;Trusted by tech industry leaders. Chipstrat &amp; Creative Strategies. MSEE + MBA.&quot;,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a87596eb-ae5c-4494-977f-88bbfa070882_400x400.png&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:100}],&quot;post_date&quot;:&quot;2025-03-19T21:01:55.649Z&quot;,&quot;cover_image&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a796af3-d2d8-4358-b609-ce7bcf74abd9_480x720.png&quot;,&quot;cover_image_alt&quot;:null,&quot;canonical_url&quot;:&quot;https://www.chipstrat.com/p/gpu-networking-basics-part-1&quot;,&quot;section_name&quot;:null,&quot;video_upload_id&quot;:null,&quot;id&quot;:159437511,&quot;type&quot;:&quot;newsletter&quot;,&quot;reaction_count&quot;:102,&quot;comment_count&quot;:0,&quot;publication_id&quot;:null,&quot;publication_name&quot;:&quot;Chipstrat&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!rCMl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27769444-42f3-4b43-9683-4fe7826c06b8_608x608.png&quot;,&quot;belowTheFold&quot;:false}"></div><div class="digest-post-embed" data-attrs="{&quot;nodeId&quot;:&quot;d42d95ae-0e00-4d3a-a449-e8f30fbca654&quot;,&quot;caption&quot;:&quot;We‚Äôre continuing with our very gentle introduction to GPU networking. Catch up with Part 1 if you missed it:&quot;,&quot;cta&quot;:&quot;Read full story&quot;,&quot;showBylines&quot;:true,&quot;size&quot;:&quot;sm&quot;,&quot;isEditorNode&quot;:true,&quot;title&quot;:&quot;GPU Networking Basics, Part 2&quot;,&quot;publishedBylines&quot;:[{&quot;id&quot;:8066776,&quot;name&quot;:&quot;Austin Lyons&quot;,&quot;bio&quot;:&quot;Trusted by tech industry leaders. Chipstrat &amp; Creative Strategies. MSEE + MBA.&quot;,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a87596eb-ae5c-4494-977f-88bbfa070882_400x400.png&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:100}],&quot;post_date&quot;:&quot;2025-04-10T14:39:23.998Z&quot;,&quot;cover_image&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff277d0c-f614-4d48-97c2-2852825f3164_1364x1174.png&quot;,&quot;cover_image_alt&quot;:null,&quot;canonical_url&quot;:&quot;https://www.chipstrat.com/p/gpu-networking-basics-part-2&quot;,&quot;section_name&quot;:null,&quot;video_upload_id&quot;:null,&quot;id&quot;:160977008,&quot;type&quot;:&quot;newsletter&quot;,&quot;reaction_count&quot;:35,&quot;comment_count&quot;:0,&quot;publication_id&quot;:null,&quot;publication_name&quot;:&quot;Chipstrat&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!rCMl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27769444-42f3-4b43-9683-4fe7826c06b8_608x608.png&quot;,&quot;belowTheFold&quot;:false}"></div><p>We will explain why <strong>low latency</strong> and <strong>low jitter</strong> govern iteration time in distributed training. We will show where <strong>traditional Ethernet falls short</strong> and <strong>why InfiniBand became the default</strong> fabric for HPC-style, lockstep workloads.</p><p>We will also <strong>clear up common misconceptions</strong>. (No worries, I had these coming into this article too!) For example, Mellanox did not invent InfiniBand. InfiniBand is not proprietary, but rather an open standard born from an industry consortium. Mellanox, and later Nvidia, have long supported Ethernet for scale-out via RoCE and its evolution. <strong>Along the way we will define what ‚Äúopen‚Äù actually means in networking. </strong>And more! </p><p>We will then contrast InfiniBand with modern Ethernet-for-AI stacks such as Nvidia Spectrum-X and the Ultra Ethernet Consortium‚Äôs 1.0 spec.</p><p>Then behind the paywall we‚Äôll examine Nvidia‚Äôs monster networking business. We will compare Nvidia‚Äôs mix across InfiniBand, NVLink, and Spectrum-X with Broadcom and Arista to show why networking is an important piece of Nvidia‚Äôs expanding TAM.</p><p>But first, context. I‚Äôll walk through a simple example to make it clear why AI networking is a different beast than networking of the past. </p><p><em>If you already know the basics, feel free to skip ahead!</em>  Many readers have said they value starting in the shallow end before diving deep, so we‚Äôll ease in there first.</p><h2>AI Networking is Different</h2><p>So what <em>are </em>the networking needs of an AI workload? </p><p><em>BTW: when I say AI training here, I mean LLMs and transformer variants driving the Generative AI boom.</em></p><h3><strong>LLM Training ü§ù Networking</strong></h3><p>At its core, LLM training is a <strong>distributed computing</strong> workload, with thousands of machines working together on a single problem. </p><p>The idea of distributed computing isn‚Äôt new. Anyone remember Folding@Home, which harnessed volunteer PCs to run protein simulations?</p><div id="youtube2-iVVojA-5ijs" class="youtube-wrap" data-attrs="{&quot;videoId&quot;:&quot;iVVojA-5ijs&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><div class="youtube-inner"><iframe src="https://www.youtube-nocookie.com/embed/iVVojA-5ijs?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></div></div><blockquote><p><strong>Vijay Pande:</strong> So in 2000 we had the idea of how we could actually use lots and lots of computers to solve our problems‚Äî<strong>instead of waiting for a million days on one computer to get the problem done in 10 days on 100,000 computers</strong>. But then you reach a sort of fork in the road where you decide whether you just want to </p>...</blockquote>
      </div>

      <div class="read-full-article">
        <a href="https://www.chipstrat.com/p/gpu-networking-basics-part-3-scale" class="read-button" target="_blank" rel="noopener">
          Read full article on Chipstrat &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>