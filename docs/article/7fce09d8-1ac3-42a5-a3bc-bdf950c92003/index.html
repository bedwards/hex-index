<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>TPU Mania - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>TPU Mania</h1>
        <div class="article-meta">
          <span class="author">By Babbage</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/thechipletter/index.html" class="publication">
            The Chip Letter
          </a>
          <span class="separator">&middot;</span><time>Dec 13, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">11 min read</span>
        </div>
      </header>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/systolic-array/index.html">
          <strong>Systolic array</strong>
          <span class="read-time">10 min read</span>
        </a>
        <p class="topic-summary">The article discusses how TPUs are based on systolic arrays from Kung and Leiserson&#039;s 1978 paper - understanding this fundamental architecture explains why TPUs are efficient for matrix multiplication</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/bfloat16-floating-point-format/index.html">
          <strong>bfloat16 floating-point format</strong>
          <span class="read-time">9 min read</span>
        </a>
        <p class="topic-summary">TPU v2 introduced bfloat16 for matrix multiplication - this specialized number format is crucial to understanding why AI accelerators can be more efficient than general-purpose chips</p>
      </li>
        </ul>
      </section>
    

      <div class="article-excerpt">
        <blockquote><div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://paulkrugman.substack.com/p/talking-with-paul-kedrosky" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!beOv!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98b65c43-1b6c-4758-94ba-56b6c3b38350_1440x220.png 424w, https://substackcdn.com/image/fetch/$s_!beOv!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98b65c43-1b6c-4758-94ba-56b6c3b38350_1440x220.png 848w, https://substackcdn.com/image/fetch/$s_!beOv!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98b65c43-1b6c-4758-94ba-56b6c3b38350_1440x220.png 1272w, https://substackcdn.com/image/fetch/$s_!beOv!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98b65c43-1b6c-4758-94ba-56b6c3b38350_1440x220.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!beOv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98b65c43-1b6c-4758-94ba-56b6c3b38350_1440x220.png" width="1440" height="220" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/98b65c43-1b6c-4758-94ba-56b6c3b38350_1440x220.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:220,&quot;width&quot;:1440,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:65674,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:&quot;https://paulkrugman.substack.com/p/talking-with-paul-kedrosky&quot;,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://thechipletter.substack.com/i/180421815?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98b65c43-1b6c-4758-94ba-56b6c3b38350_1440x220.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!beOv!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98b65c43-1b6c-4758-94ba-56b6c3b38350_1440x220.png 424w, https://substackcdn.com/image/fetch/$s_!beOv!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98b65c43-1b6c-4758-94ba-56b6c3b38350_1440x220.png 848w, https://substackcdn.com/image/fetch/$s_!beOv!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98b65c43-1b6c-4758-94ba-56b6c3b38350_1440x220.png 1272w, https://substackcdn.com/image/fetch/$s_!beOv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98b65c43-1b6c-4758-94ba-56b6c3b38350_1440x220.png 1456w" sizes="100vw" fetchpriority="high"></picture><div></div></div></a></figure></div><p><em>Nobel Prize winning economist, Paul Krugman, <a href="https://paulkrugman.substack.com/p/talking-with-paul-kedrosky">discusses</a> TPUs and GPUs with Paul Kedrosky. No criticism of Krugman intended, it’s great that computer architecture is getting so much attention.</em></p></blockquote><p>All of a sudden, everyone is talking - and writing - about Google’s TPUs (Tensor Processing Units). The use of TPUs to train Google latest, market leading Gemini 3 model together with Google’s decision to sell TPUs to third parties (apparently including arch-rival Meta) have combined to create a major ‘vibe-shift’ away from Nvidia and towards Google’s hardware.</p><p>Not just a vibe-shift either as Alphabet’s stock price has been on a tear:</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!LsY7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!LsY7!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg 424w, https://substackcdn.com/image/fetch/$s_!LsY7!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg 848w, https://substackcdn.com/image/fetch/$s_!LsY7!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!LsY7!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!LsY7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg" width="1350" height="988" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:988,&quot;width&quot;:1350,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:135854,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://thechipletter.substack.com/i/180421815?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!LsY7!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg 424w, https://substackcdn.com/image/fetch/$s_!LsY7!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg 848w, https://substackcdn.com/image/fetch/$s_!LsY7!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!LsY7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9503ead0-aa7b-4d66-852f-fc2241fc02cf_1350x988.jpeg 1456w" sizes="100vw"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a></figure></div><p>The coverage of the latest TPUs (v7) has been so extensive that, rather than add another series of takes, I thought it would more useful for readers to curate a selection of some of the most informative posts and links on TPUv7.</p><p>Before that, though, I wanted to briefly highlight several points that I can’t recall seeing much discussed elsewhere.</p><h4>A Twelve Year Overnight Success</h4><p>We looked at the origins of Google’s TPU programme in: </p><div class="digest-post-embed" data-attrs="{&quot;nodeId&quot;:&quot;90d5858e-2e9d-4b5d-b8b4-37a8d8192dfb&quot;,&quot;caption&quot;:&quot;Note: This is a two-part post. This part provides context and covers the story of the development of the first Google TPU. Part 2 looks at the architecture and the performance of the TPU in more detail.&quot;,&quot;cta&quot;:&quot;Read full story&quot;,&quot;showBylines&quot;:true,&quot;size&quot;:&quot;lg&quot;,&quot;isEditorNode&quot;:true,&quot;title&quot;:&quot;Google's First Tensor Processing Unit: Origins&quot;,&quot;publishedBylines&quot;:[{&quot;id&quot;:102722254,&quot;name&quot;:&quot;Babbage&quot;,&quot;bio&quot;:&quot;Computer history and architecture&quot;,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F82525b9c-ee3c-4996-916c-54267a4d354b_416x416.png&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:100}],&quot;post_date&quot;:&quot;2024-02-25T15:25:19.334Z&quot;,&quot;cover_image&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede3c6cd-726f-4a26-995d-d2981d47a725_1600x923.png&quot;,&quot;cover_image_alt&quot;:null,&quot;canonical_url&quot;:&quot;https://thechipletter.substack.com/p/googles-first-tensor-processing-unit&quot;,&quot;section_name&quot;:null,&quot;video_upload_id&quot;:null,&quot;id&quot;:141519410,&quot;type&quot;:&quot;newsletter&quot;,&quot;reaction_count&quot;:63,&quot;comment_count&quot;:16,&quot;publication_id&quot;:1063960,&quot;publication_name&quot;:&quot;The Chip Letter&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!vwjY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fffe682d7-ab93-463b-b714-8f98c0c072d2_1280x1280.png&quot;,&quot;belowTheFold&quot;:false}"></div><p>The origins of the TPU program date Google date all the way back to 2013 - almost a decade before the launch of ChatGPT - when it first became apparent that Google might need to start applying deep learning at scale.</p><p>The essence of the design dates back even further - into the 1970s. In their 1978 paper <a href="https://www.eecs.harvard.edu/htk/static/files/1978-cmu-cs-report-kung-leiserson.pdf">Systolic Arrays (for VLSI)</a> H.T Kung and Charles E. Leiserson of Carnegie Mellon University had set out proposals for what they called a ‘systolic system’.</p><blockquote><p>A systolic system is a network of processors which rhythmically compute and pass data through the system….In a systolic computer system, the function of a processor is analogous to that of the heart. Every processor regularly pumps data in and out, each time performing some short computation so that a regular flow of data is kept up in the network.</p></blockquote><p>The approach didn’t gain widespread adoption in the 1970s and 1980s, but by 2013 the time was right:</p><blockquote><p>By 2013 some of the original motivation behind Kung and Lieberson’s ideas had fallen away, particularly dealing with the limits of fabrication technology of the 1970s, had fallen away. However, the inherent efficiency, and of particular relevance in 2013, the relatively low power consumption, of this approach for tasks such as matrix multiplication remained. So the TPU would use systolic arrays.</p></blockquote><p>We discussed the </p></source>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://thechipletter.substack.com/p/tpu-mania" class="read-button" target="_blank" rel="noopener">
          Read full article on The Chip Letter &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>