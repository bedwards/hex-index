<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Nobody ever gets credit for fixing security problems that never happened - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Nobody ever gets credit for fixing security problems that never happened</h1>
        <div class="article-meta">
          <span class="author">By Ross Haleliuk</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/ventureinsecurity/index.html" class="publication">
            Venture in Security
          </a>
          <span class="separator">&middot;</span><time>Nov 18, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">13 min read</span>
        </div>
      </header>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/fundamental-attribution-error/index.html">
          <strong>Fundamental attribution error</strong>
          <span class="read-time">12 min read</span>
        </a>
        <p class="topic-summary">The article explicitly discusses this psychological phenomenon as central to why managers blame individuals rather than systemic processes. Understanding the cognitive bias deeply would help readers recognize it in their own organizations.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/systems-thinking/index.html">
          <strong>Systems thinking</strong>
          <span class="read-time">10 min read</span>
        </a>
        <p class="topic-summary">The article references feedback loops, time delays, and capability erosion - all core systems thinking concepts from the Sterman/Repenning research. Understanding systems thinking provides the theoretical foundation for the &#039;working smarter vs harder&#039; framework.</p>
      </li>
        </ul>
      </section>
    

      <div class="article-excerpt">
        <p>Over 20 years ago, Nelson Repenning and John Sterman published an article in the Engineering Management Review, IEEE titled “<a href="https://web.mit.edu/nelsonr/www/Repenning=Sterman_CMR_su01_.pdf">Nobody ever gets credit for fixing problems that never happened: creating and sustaining process improvement</a>”. When you read this article, you’ll realize that security is not unique in facing the problems it does, but also that our industry amplifies a lot of the challenges common in other fields and makes them much harder to tackle.</p><p>In this piece, I am doing a deep dive into the aspects of that great article that are most relevant to security. First and foremost, there’s the fact that nobody ever gets credit for fixing security problems that never happened. This has serious consequences for security teams and startup founders alike, as it effectively defines what initiatives (or products) are likely to be doomed from the start. It also answers many other questions, like why we blame people and not processes, why people are conditioned to work harder instead of working smarter, and why we love shortcuts even if the long-term impact of taking them can be pretty bad.</p><div><hr></div><p><em>This issue is <a href="https://ventureinsecurity.net/p/sponsor">brought</a> to you by… <a href="https://www.intruder.io/research/shadow-it-risks?utm_source=ventureinsecurity&amp;utm_medium=p_referral&amp;utm_campaign=global|fixed|shadow_it">Intruder</a>.</em></p><p><strong><a href="https://www.intruder.io/research/shadow-it-risks?utm_source=ventureinsecurity&amp;utm_medium=p_referral&amp;utm_campaign=global|fixed|shadow_it">30M Domains Later, Here’s What We Found Hiding In Shadow IT</a></strong></p><p>How much Shadow IT can you uncover with only public data? We ran the experiment and the answer was: too much. From backups holding live credentials to admin panels with no authentication, these exposures stay invisible to you but wide open to attackers. Read the research to see what we found and how Intruder helps you find it first.</p><div><hr></div><div><hr></div><h1>Working harder vs. working smarter</h1><p>Nelson and John, authors of the IEEE article, explain in very simple terms why security teams, similar to other functions, get stuck in the endless cycle of firefighting.</p><p>The idea here is simple. Security teams spend all their time dealing with incidents, tickets, and alerts - all the stuff that causes the well-known fatigue. Everything is on fire, the amount of work is overwhelming, and it’s impossible to ever reach a point where the team has time to pursue more strategic initiatives. Because the teams are bogged down doing all this manual, repetitive, low-value work, they never get the time to prioritize investing in foundational hygiene, architecture changes, or resilience. This creates a vicious cycle: the more they firefight, the more fragile the system becomes, and the more fragile the system, ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://ventureinsecurity.net/p/nobody-ever-gets-credit-for-fixing" class="read-button" target="_blank" rel="noopener">
          Read full article on Venture in Security &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>