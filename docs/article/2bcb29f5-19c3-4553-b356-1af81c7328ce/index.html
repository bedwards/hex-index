<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The Z.ai Playbook - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>The Z.ai Playbook</h1>
        <div class="article-meta">
          <span class="author">By Jordan Schneider</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/chinatalk/index.html" class="publication">
            ChinaTalk
          </a>
          <span class="separator">&middot;</span><time>Nov 21, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">38 min read</span>
        </div>
      </header>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/knowledge-distillation/index.html">
          <strong>Knowledge distillation</strong>
          <span class="read-time">13 min read</span>
        </a>
        <p class="topic-summary">The article describes Z.ai&#039;s technique of building three separate &#039;teaching models&#039; and distilling them into GLM 4.5. Knowledge distillation is a foundational machine learning technique that readers would benefit from understanding to grasp how modern AI labs efficiently create unified models.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/tsinghua-university/index.html">
          <strong>Tsinghua University</strong>
          <span class="read-time">14 min read</span>
        </a>
        <p class="topic-summary">Zhipu AI was founded by researchers from Tsinghua University in 2019, and the article discusses the close relationship between Chinese AI companies and academic institutions. Understanding Tsinghua&#039;s role as China&#039;s premier technical university provides context for the talent pipeline feeding Chinese AI development.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/open-source-software/index.html">
          <strong>Open-source software</strong>
          <span class="read-time">11 min read</span>
        </a>
        <p class="topic-summary">The article explicitly discusses &#039;the role of open source in the Chinese AI ecosystem&#039; as a key topic and mentions Z.ai&#039;s relationship with open-source coding tools. Understanding the philosophy and economics of open source helps readers grasp the strategic decisions Chinese AI companies make about model release.</p>
      </li>
        </ul>
      </section>
    

      <div class="article-excerpt">
        <p>Zixuan Li is Director of Product and genAI Strategy at Z.ai (also known as Zhipu 智谱 AI). The release of their benchmark-topping flagship model, GLM 4.5, was akin to “another DeepSeek moment,” in the words of Nathan Lambert.</p><p><strong>Our conversation today covers…</strong></p><ul><li><p><strong>What sets Z.ai apart from other Chinese models, including coding, role-playing capabilities, and translations of cryptic Chinese internet content,</strong></p></li><li><p><strong>Why Chinese AI companies chase recognition from Silicon Valley thought leaders,</strong></p></li><li><p><strong>The role of open source in the Chinese AI ecosystem,</strong></p></li><li><p><strong>Fears of job loss and the prevalence of AI pessimism in China,</strong></p></li><li><p><strong>How Z.ai trains its models, and what capabilities the company is targeting next.</strong></p></li></ul><p>Co-hosting today are <span class="mention-wrap" data-attrs="{&quot;name&quot;:&quot;Irene Zhang&quot;,&quot;id&quot;:12682021,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/af57f9bb-ce01-4a87-9ca9-13612d58e4d9_1168x930.png&quot;,&quot;uuid&quot;:&quot;6d475209-6930-4c90-be90-2c3cc541d927&quot;}" data-component-name="MentionToDOM"></span>, long-time ChinaTalk analyst, as well as<span class="mention-wrap" data-attrs="{&quot;name&quot;:&quot;Nathan Lambert&quot;,&quot;id&quot;:10472909,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!RihO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fedcdfb-e137-4f6a-9089-a46add6c6242_500x500.jpeg&quot;,&quot;uuid&quot;:&quot;3f516039-acdb-471f-ab4b-f9e8a3ad5486&quot;}" data-component-name="MentionToDOM"></span> of <a href="https://www.interconnects.ai/">the Interconnects Substack</a>. </p><p><strong>Listen now <a href="https://link.chtbl.com/chinatalk">on your favorite podcast app</a>.</strong></p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!7nam!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d960003-a175-46e0-ba5b-a55a6de8cd0c_1242x690.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!7nam!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d960003-a175-46e0-ba5b-a55a6de8cd0c_1242x690.png 424w, https://substackcdn.com/image/fetch/$s_!7nam!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d960003-a175-46e0-ba5b-a55a6de8cd0c_1242x690.png 848w, https://substackcdn.com/image/fetch/$s_!7nam!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d960003-a175-46e0-ba5b-a55a6de8cd0c_1242x690.png 1272w, https://substackcdn.com/image/fetch/$s_!7nam!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d960003-a175-46e0-ba5b-a55a6de8cd0c_1242x690.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!7nam!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d960003-a175-46e0-ba5b-a55a6de8cd0c_1242x690.png" width="1242" height="690" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4d960003-a175-46e0-ba5b-a55a6de8cd0c_1242x690.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:690,&quot;width&quot;:1242,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1824323,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!7nam!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d960003-a175-46e0-ba5b-a55a6de8cd0c_1242x690.png 424w, https://substackcdn.com/image/fetch/$s_!7nam!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d960003-a175-46e0-ba5b-a55a6de8cd0c_1242x690.png 848w, https://substackcdn.com/image/fetch/$s_!7nam!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d960003-a175-46e0-ba5b-a55a6de8cd0c_1242x690.png 1272w, https://substackcdn.com/image/fetch/$s_!7nam!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d960003-a175-46e0-ba5b-a55a6de8cd0c_1242x690.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a></figure></div><h1>The Z.ai Model and Chinese Open Source</h1><p><strong>Jordan Schneider:</strong> Zixuan, could you introduce yourself?</p><p><strong>Zixuan Li:</strong> Hi everyone, I’m Zixuan Li from Z.ai. I manage a lot of things, like global partnerships, Z.ai chat model evaluation, and our API services. If you’ve heard of the GLM Coding Plan, I’m actually in charge of that, too. I studied AI for science and AI safety at MIT, where I did research on AI applications and AI alignment.</p><p><strong>Jordan Schneider:</strong> Let’s do a little bit of Zhipu AI’s backstory. When was it founded? How would you place it within the broader landscape of teams developing models in China?</p><p><strong>Zixuan Li:</strong> Zhipu AI and Z.ai were founded in 2019, and we were chasing AGI at that time, but not with LLMs, but with some graphic network or graphic compute. We did something similar to Google Scholar called <a href="https://www.aminer.cn/">AMiner</a>. We used that type of thing to connect all the data resources from journals and research papers into a database. People could easily search and map these scholars and their contributions. It was very popular at that time.</p><p>However, we shifted to the exploration of large language models in 2020. We launched our paper, GLM, in 2021. I believe that was about one year ahead of the launch of GPT-3.5, so it was a very, very early stage. We were one of the first companies to explore large language models. After that, we continuously improved the performance of our models and tried a new architecture. GLM is a new architecture, actually, but we’re going to explore more in the future.</p><p>I believe we became famous </p>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://www.chinatalk.media/p/the-zai-playbook" class="read-button" target="_blank" rel="noopener">
          Read full article on ChinaTalk &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>