<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LLM Research Papers: The 2024 List - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>LLM Research Papers: The 2024 List</h1>
        <div class="article-meta">
          <span class="author">By Sebastian Raschka</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/sebastianraschka/index.html" class="publication">
            Ahead of AI
          </a>
          <span class="separator">&middot;</span><time>Dec 8, 2024</time>
          <span class="separator">&middot;</span>
          <span class="read-time">30 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>It’s been a very eventful and exciting year in AI research. This is especially true if you are interested in LLMs.</p><p>I had big plans for this December edition and was planning to publish a new article with a discussion of all my research highlights from 2024. I still plan to do so, but due to an accident and serious injury, I am currently unable to work at a computer and finish the draft. But I hope to recover in the upcoming weeks and be back on my feet soon.</p><p>In the meantime, I want to share my running bookmark list of many fascinating (mostly LLM-related) papers I stumbled upon in 2024. It’s just a list, but maybe it will come in handy for those who are interested in finding some gems to read for the holidays.</p><p>And if you are interested in more code-heavy reading and tinkering, <a href="https://amzn.to/4fqvn0D">My Build A Large Language Model (From Scratch)</a> book is out on Amazon as of last month.</p><p>In addition, I added a lot of bonus materials to the <a href="https://github.com/rasbt/LLMs-from-scratch">GitHub repository</a>. </p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!WXSG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9390f1a2-1dd5-4471-9ed7-80359f95639a_1616x2066.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!WXSG!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9390f1a2-1dd5-4471-9ed7-80359f95639a_1616x2066.jpeg 424w, https://substackcdn.com/image/fetch/$s_!WXSG!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9390f1a2-1dd5-4471-9ed7-80359f95639a_1616x2066.jpeg 848w, https://substackcdn.com/image/fetch/$s_!WXSG!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9390f1a2-1dd5-4471-9ed7-80359f95639a_1616x2066.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!WXSG!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9390f1a2-1dd5-4471-9ed7-80359f95639a_1616x2066.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!WXSG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9390f1a2-1dd5-4471-9ed7-80359f95639a_1616x2066.jpeg" width="1456" height="1861" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9390f1a2-1dd5-4471-9ed7-80359f95639a_1616x2066.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1861,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:371770,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!WXSG!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9390f1a2-1dd5-4471-9ed7-80359f95639a_1616x2066.jpeg 424w, https://substackcdn.com/image/fetch/$s_!WXSG!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9390f1a2-1dd5-4471-9ed7-80359f95639a_1616x2066.jpeg 848w, https://substackcdn.com/image/fetch/$s_!WXSG!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9390f1a2-1dd5-4471-9ed7-80359f95639a_1616x2066.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!WXSG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9390f1a2-1dd5-4471-9ed7-80359f95639a_1616x2066.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a><figcaption class="image-caption"><a href="https://github.com/rasbt/LLMs-from-scratch">Bonus materials in the GitHub repository</a> (stars highlight my personal favorites)</figcaption></figure></div><p>Thanks for your understanding and support, and I hope to make a full recovery soon and be back with the Research Highlights 2024 article in a few weeks!</p><h2><strong>January 2024</strong></h2><ul><li><p>1 Jan, <em>Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models</em>, <a href="https://arxiv.org/abs/2401.00788">https://arxiv.org/abs/2401.00788</a></p></li><li><p>2 Jan, <em>A Comprehensive Study of Knowledge Editing for Large Language Models</em>, <a href="https://arxiv.org/abs/2401.01286">https://arxiv.org/abs/2401.01286</a></p></li><li><p>2 Jan, <em>LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning</em>, <a href="https://arxiv.org/abs/2401.01325">https://arxiv.org/abs/2401.01325</a></p></li><li><p>2 Jan, <em>Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models</em>, <a href="https://arxiv.org/abs/2401.01335">https://arxiv.org/abs/2401.01335</a></p></li><li><p>2 Jan, <em>LLaMA Beyond English: An Empirical Study on Language Capability Transfer</em>, <a href="https://arxiv.org/abs/2401.01055">https://arxiv.org/abs/2401.01055</a></p></li><li><p>3 Jan, <em>A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity</em>, <a href="https://arxiv.org/abs/2401.01967">https://arxiv.org/abs/2401.01967</a></p></li><li><p>4 Jan, <em>LLaMA Pro: Progressive LLaMA with Block Expansion</em>, <a href="https://arxiv.org/abs/2401.02415">https://arxiv.org/abs/2401.02415</a></p></li><li><p>4 Jan, <em>LLM Augmented LLMs: Expanding Capabilities through Composition</em>, <a href="https://arxiv.org/abs/2401.02412">https://arxiv.org/abs/2401.02412</a></p></li><li><p>4 Jan, <em>Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM</em>, <a href="https://arxiv.org/abs/2401.02994">https://arxiv.org/abs/2401.02994</a></p></li><li><p>5 Jan, <em>DeepSeek LLM: Scaling Open-Source Language Models with Longtermism</em>, <a href="https://arxiv.org/abs/2401.02954">https://arxiv.org/abs/2401.02954</a></p></li><li><p>5 Jan, <em>Denoising Vision Transformers</em>, <a href="https://arxiv.org/abs/2401.02957">https://arxiv.org/abs/2401.02957</a></p></li><li><p>7 Jan, <em>Soaring from 4K to 400K: Extending LLM’s Context with Activation Beacon</em>, <a href="https://arxiv.org/abs/2401.03462">https://arxiv.org/abs/2401.03462</a></p></li><li><p>8 Jan, <em>Mixtral of Experts</em>, <a href="https://arxiv.org/abs/2401.04088">https://arxiv.org/abs/2401.04088</a></p></li><li><p>8 Jan, <em>MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts</em>, <a href="https://arxiv.org/abs/2401.04081">https://arxiv.org/abs/2401.04081</a></p></li><li><p>8 Jan, <em>A Minimaximalist </em></p></li></ul>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://magazine.sebastianraschka.com/p/llm-research-papers-the-2024-list" class="read-button" target="_blank" rel="noopener">
          Read full article on Ahead of AI &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>