<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Sessions #1: AI - A Normal Technology or a Superintelligent Alien Species? - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>AI Sessions #1: AI - A Normal Technology or a Superintelligent Alien Species?</h1>
        <div class="article-meta">
          <span class="author">By Dan Williams</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/conspicuouscognition/index.html" class="publication">
            Conspicuous Cognition
          </a>
          <span class="separator">&middot;</span><time>Sep 18, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">3 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>Is artificial intelligence (AI) a “normal technology” or a potentially “superintelligent” alien species? Is it true, as some influential people <a href="https://www.penguin.co.uk/books/474267/if-anyone-builds-it-everyone-dies-by-soares-eliezer-yudkowsky-and-nate/9781847928924">claim</a>, that if anyone builds “super-intelligent” AI systems, everyone dies? What even <em>is </em>superintelligence”?</p><p>In this conversation, the first official episode of Conspicuous Cognition’s “AI Sessions”, <a href="https://henryshevlin.com/">Henry Shevlin</a> and I discuss these and many more issues.</p><p>Specifically, we explore two highly influential perspectives on the future trajectory, impacts, and dangers of AI. </p><p>The first models AI as a “<a href="https://knightcolumbia.org/content/ai-as-normal-technology">normal technology</a>”, potentially transformative but still a tool, which will diffuse throughout society in ways similar to previous technologies like electricity or the internet. Through this lens, we examine how AI is likely to impact the world and discuss deep philosophical and scientific questions about the nature of intelligence and power.</p><p>The <a href="https://www.penguin.co.uk/books/474267/if-anyone-builds-it-everyone-dies-by-soares-eliezer-yudkowsky-and-nate/9781847928924">second perspective</a> presents a very different possibility: that we may be on the path to creating superintelligent autonomous agents that threaten to wipe out the human species. We unpack what "superintelligence" means and explore not just whether future AI systems could cause human extinction but whether they would “want” to.</p><p>Here are the primary sources we cite in our conversation, which also double up as a helpful introductory reading list covering some of the most significant current debates concerning artificial intelligence and the future.  </p><p><strong>Main Sources Cited:</strong></p><ul><li><p><strong>Narayanan, Arvind and Sayash Kapoor</strong> (2025). <a href="https://knightcolumbia.org/content/ai-as-normal-technology">"AI as Normal Technology."</a> </p></li><li><p><strong>Yudkowsky, Eliezer and Nate Soares</strong> (2025). <em><a href="https://www.penguin.co.uk/books/474267/if-anyone-builds-it-everyone-dies-by-soares-eliezer-yudkowsky-and-nate/9781847928924">If Anyone Builds It, Everyone Dies: Why Superhuman AI Would Kill Us All</a></em>. </p></li><li><p><strong>Kokotajlo, Daniel, Scott Alexander, Thomas Larsen, Eli Lifland, and Romeo Dean</strong> (2025). <a href="https://ai-2027.com/">"AI 2027."</a> </p></li><li><p><strong>Alexander, Scott and the AI Futures Project</strong> (2025). <a href="https://blog.ai-futures.org/p/ai-as-profoundly-abnormal-technology">"AI as Profoundly Abnormal Technology."</a> AI Futures Project Blog.</p></li><li><p><strong>Henrich, Joseph</strong> (2016). <em><a href="https://press.princeton.edu/books/paperback/9780691178431/the-secret-of-our-success?srsltid=AfmBOop7cUu4W1D1mljN0g_Zd_5U59GqNgtsNCQ-txM0AXTXB677a491">The Secret of Our Success: How Culture Is Driving Human Evolution, Domesticating Our Species, and Making Us Smarter</a></em>. </p></li><li><p><strong>Huemer, Michael</strong>. "<a href="https://link.springer.com/article/10.1007/s00146-025-02505-5">I for one, welcome our AI Overlords"</a> </p></li><li><p><strong>Pinker, Steven</strong> (2018). <em><a href="https://www.amazon.co.uk/Enlightenment-Now-Science-Humanism-Progress/dp/0525427570">Enlightenment Now: The Case for Reason, Science, Humanism, and Progress</a></em></p></li></ul><p><strong>Further Reading:</strong></p><ul><li><p><strong>Bostrom, Nick</strong> (2014). <em><a href="https://www.amazon.co.uk/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111">Superintelligence: Paths, Dangers, Strategies</a></em>. </p></li><li><p><strong>Pinsof, David</strong> (2025). <a href="https://www.everythingisbullshit.blog/p/ai-doomerism-is-bullshit">"AI Doomerism is Bullshit."</a> </p></li><li><p><strong>Kulveit, Jan, Raymond Douglas, Nora Ammann, Deger Turan, David Krueger, and David Duvenaud</strong> (2025). <a href="https://arxiv.org/abs/2501.16946">"Gradual Disempowerment: Systemic Existential Risks from Incremental AI Development."</a> arXiv preprint.</p></li></ul><p>For a more expansive reading list, see my syllabus here: </p><div class="digest-post-embed" data-attrs="{&quot;nodeId&quot;:&quot;a9a98c27-127f-4e82-996d-a6f18e2b7778&quot;,&quot;caption&quot;:&quot;Over the next several decades, advances in artificial intelligence are likely to transform our societies, economies, cultures, and understanding of what it means to be human. Not enough people have begun to grapple with this fact, and with the wide range of philosophical, ethical, and political issues it raises. If you…&quot;,&quot;cta&quot;:&quot;Read full story&quot;,&quot;showBylines&quot;:true,&quot;size&quot;:&quot;sm&quot;,&quot;isEditorNode&quot;:true,&quot;title&quot;:&quot;Philosophy of Artificial Intelligence: 10-Week Syllabus &amp; Readings&quot;,&quot;publishedBylines&quot;:[{&quot;id&quot;:192522122,&quot;name&quot;:&quot;Dan Williams&quot;,&quot;bio&quot;:&quot;Writer. Academic philosopher. PhD from University of Cambridge, 2018. Writes about: philosophy, social science, evolution, artificial intelligence, politics. &quot;,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1024549-3e73-4be0-b941-eb22e3995a5f_1024x1024.jpeg&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:100}],&quot;post_date&quot;:&quot;2025-09-07T15:54:02.264Z&quot;,&quot;cover_image&quot;:&quot;https://images.unsplash.com/photo-1713345248737-2698000f143d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxOHx8YWl8ZW58MHx8fHwxNzU3MjU2Njg5fDA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080&quot;,&quot;cover_image_alt&quot;:null,&quot;canonical_url&quot;:&quot;https://www.conspicuouscognition.com/p/philosophy-of-artificial-intelligence&quot;,&quot;section_name&quot;:null,&quot;video_upload_id&quot;:null,&quot;id&quot;:173017863,&quot;type&quot;:&quot;newsletter&quot;,&quot;reaction_count&quot;:98,&quot;comment_count&quot;:25,&quot;publication_id&quot;:null,&quot;publication_name&quot;:&quot;Conspicuous Cognition&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!g57e!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28186027-13c2-4585-9fe7-93241b46888e_1024x1024.png&quot;,&quot;belowTheFold&quot;:true}"></div><p>You can also see the first conversation that Henry and I had here, which was recorded live and where the sound ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://www.conspicuouscognition.com/p/ai-sessions-1-ai-a-normal-technology" class="read-button" target="_blank" rel="noopener">
          Read full article on Conspicuous Cognition &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>