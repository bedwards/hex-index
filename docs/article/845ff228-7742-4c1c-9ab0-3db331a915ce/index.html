<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Deep Learning Weekly: Issue 428 - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Deep Learning Weekly: Issue 428</h1>
        <div class="article-meta">
          <span class="author">By Various</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/deeplearningweekly/index.html" class="publication">
            Deep Learning Weekly
          </a>
          <span class="separator">&middot;</span><time>Oct 30, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">5 min read</span>
        </div>
      </header>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/self-supervised-learning/index.html">
          <strong>Self-supervised learning</strong>
          <span class="read-time">15 min read</span>
        </a>
        <p class="topic-summary">The Concerto paper discusses joint 2D-3D self-supervised learning for spatial representations. Understanding self-supervised learning—how models learn from unlabeled data by creating their own supervisory signals—provides essential context for grasping why this approach to spatial cognition is significant and how it differs from traditional supervised methods.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/knowledge-graph/index.html">
          <strong>Knowledge graph</strong>
          <span class="read-time">1 min read</span>
        </a>
        <p class="topic-summary">The ODKE+ paper focuses on automatically extracting facts into knowledge graphs from web sources. Knowledge graphs are foundational data structures in AI that represent relationships between entities, and understanding their architecture and applications illuminates why maintaining their freshness and completeness is so challenging and valuable.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/time-series/index.html">
          <strong>Time series</strong>
          <span class="read-time">13 min read</span>
        </a>
        <p class="topic-summary">Chronos-2 is described as a foundation model for forecasting tasks including univariate and multivariate predictions. Time series analysis—the study of data points collected over time intervals—provides the mathematical foundation for understanding what makes forecasting challenging and why a &#039;universal&#039; forecasting model represents a significant advance.</p>
      </li>
        </ul>
      </section>
    

      <div class="article-excerpt">
        <p>This week in deep learning, we bring you <a href="https://deepseek.ai/blog/deepseek-ocr-context-compression">DeepSeek-OCR</a>, <a href="https://www.amazon.science/blog/introducing-chronos-2-from-univariate-to-universal-forecasting">Introducing Chronos-2: From univariate to universal forecasting</a>, and <a href="https://arxiv.org/abs/2510.24668">a paper on InteractComp: Evaluating Search Agents With Ambiguous Queries</a>.</p><p>You may also enjoy <a href="https://www.anthropic.com/news/advancing-claude-for-financial-services">Advancing Claude for Financial Services</a>, <a href="https://www.tensoreconomics.com/p/llm-inference-economics-from-first">LLM Inference Economics from First Principles</a>, <a href="https://arxiv.org/abs/2510.23607">a paper on Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations</a>, and more!</p><p>As always, happy reading and hacking. If you have something you think should be in next week’s issue, find us on Twitter: <a href="https://twitter.com/dl_weekly">@dl_weekly</a>.</p><p>Until next week!</p><div><hr></div><h2><strong>Industry</strong></h2><p><strong><a href="https://deepseek.ai/blog/deepseek-ocr-context-compression">DeepSeek-OCR: Revolutionary Context Compression Through Optical 2D Mapping</a></strong></p><p>DeepSeek AI unveiled DeepSeek-OCR, an approach to compressing long contexts via optical 2D mapping.</p><p><strong><a href="https://www.anthropic.com/news/advancing-claude-for-financial-services">Advancing Claude for Financial Services \ Anthropic</a></strong></p><p>Anthropic expanded Claude for Financial Services with an Excel add-in, additional connectors to real-time market data and portfolio analytics, and new pre-built Agent Skills.</p><p><strong><a href="https://www.amazon.science/blog/introducing-chronos-2-from-univariate-to-universal-forecasting">Introducing Chronos-2: From univariate to universal forecasting</a></strong></p><p>Amazon introduced Chronos-2, a foundation model designed to handle arbitrary forecasting tasks — univariate, multivariate, and covariate informed — in a zero-shot manner.</p><p><strong><a href="https://siliconangle.com/2025/10/29/grammarly-transforms-ai-enabled-productivity-suite-superhuman-rebrand/">Grammarly transforms into AI-enabled productivity suite with Superhuman rebrand</a></strong></p><p>Grammarly, best known for AI-powered proofreading and writing, announced its rebrand to Superhuman: a full-featured AI-native productivity platform.</p><h2><strong>MLOps &amp; LLMOps</strong>.</h2><p><strong><a href="https://www.comet.com/site/blog/llm-tracing/?utm_source=substack&amp;utm_medium=email&amp;utm_campaign=dlw&amp;utm_content=llm-tracing/">LLM Tracing: The Foundation of Reliable AI Applications</a></strong></p><p>An article discussing that LLM tracing is the foundation of reliable AI applications by capturing end-to-end steps to diagnose non-deterministic and semantic failures.</p><p><strong><a href="https://medium.com/mongodb/build-ai-agents-worth-keeping-the-canvas-framework-b582c40db00a">Build AI Agents Worth Keeping: The Canvas Framework</a></strong></p><p>An article about why enterprise AI agent projects fail and how to use product-first canvas frameworks to build agents that actually reach production.</p><h2><strong>Learning</strong></h2><p><strong><a href="https://www.tensoreconomics.com/p/llm-inference-economics-from-first">LLM Inference Economics from First Principles</a></strong></p><p>A detailed article explaining LLM inference economics from first principles, focusing on how batching is the key to profitability by offsetting memory-bound costs in the token-by-token generation phase.</p><p><strong><a href="https://ai.stanford.edu/blog/tstar/">T*: Rethinking Temporal Search for Long-Form Video Understanding</a></strong></p><p>An article introducing the T* temporal search algorithm, which reframes long-form video understanding as spatial search to efficiently locate relevant frames.</p><p><strong><a href="https://blog.ml.cmu.edu/2025/10/27/learning-from-failure-to-tackle-extremely-hard-problems/">Learning from Failure to Tackle Extremely Hard Problems</a></strong></p><p>A research blog post introducing BaNEL (Bayesian Negative Evidence Learning), an algorithm that post-trains generative models efficiently using only negative reward samples to tackle extremely sparse, hard problems.</p><p><strong><a href="https://netflixtechblog.com/post-training-generative-recommenders-with-advantage-weighted-supervised-finetuning-61a538d717a9">Post-Training Generative Recommenders with Advantage-Weighted Supervised Finetuning</a></strong></p><p>A novel study presenting Advantage-Weighted Supervised Fine-tuning (A-SFT), an algorithm for post-training generative recommenders.</p><p><strong><a href="https://www.sustainabilitybynumbers.com/p/artificial-intelligence-could-dramatically">Artificial intelligence could dramatically improve weather forecasting</a></strong></p><p>An article about how AI could dramatically ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://www.deeplearningweekly.com/p/deep-learning-weekly-issue-428" class="read-button" target="_blank" rel="noopener">
          Read full article on Deep Learning Weekly &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>