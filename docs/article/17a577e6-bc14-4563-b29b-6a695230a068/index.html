<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Michael Huemer Is Wrong About AI Hype  - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Michael Huemer Is Wrong About AI Hype </h1>
        <div class="article-meta">
          <span class="author">By Bentham&#039;s Bulldog</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/benthams/index.html" class="publication">
            
          </a>
          <span class="separator">&middot;</span><time>Jan 14, 2026</time>
          <span class="separator">&middot;</span>
          <span class="read-time">11 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p><span class="mention-wrap" data-attrs="{&quot;name&quot;:&quot;Michael Huemer&quot;,&quot;id&quot;:88831205,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F26ba64a6-ae4a-4678-bd22-6f2be92e708f_316x320.jpeg&quot;,&quot;uuid&quot;:&quot;45299e29-f1b3-4cdf-bf04-d4eaae0f5c78&quot;}" data-component-name="MentionToDOM"></span> is one of my favorite philosophers.  I’ve read every book, paper, and article he has ever written, and enjoyed them all (this is the sort of statement that sounds hyperbolic but is not).  However, even very smart and reasonable people are wrong sometimes (for example, I have, upon occasion, been wrong).<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1" href="#footnote-1" target="_self">1</a>  Huemer recently wrote an article called <em><a href="https://fakenous.substack.com/p/is-ai-over-hyped">Is AI Over-Hyped? </a></em>(his conclusion was yes) which I didn’t think was correct.  For this reason, I thought it would be worth explaining my disagreement—to answer the question is “<em>Is AI Over-Hyped?</em>” overhyped?</p><p>My general view on AI is that it is overall underhyped, but in particular, people are hyping the wrong stuff.<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2" href="#footnote-2" target="_self">2</a>  There’s lots of discussion of short-term harms like <a href="https://www.goodthoughts.blog/p/theres-no-moral-objection-to-ai-art?utm_source=publication-search">AI plagiarizing art</a>, <a href="https://andymasley.substack.com/p/the-ai-water-issue-is-fake">water use</a>, and <a href="https://andymasley.substack.com/p/a-cheat-sheet-for-conversations-about">electricity use</a>.  This stuff is mostly bogus.  But there is a real, non-trivial chance of near-term AI that <em>will completely upend the world and bring about economic growth at a speed <a href="https://www.forethought.org/research/preparing-for-the-intelligence-explosion">never seen before in human history</a></em>.  Even if timelines are long, so AI comes in 40 years rather than 5, when it comes, it will probably massively upend the world.</p><p>Why do I think transformative AI soon is likely?  The <a href="https://www.forethought.org/research/preparing-for-the-intelligence-explosion">basic </a>reason <a href="https://blog.ai-futures.org/p/ai-futures-model-dec-2025-update">is</a>: if you just project that current trends continue, or even if they slow considerably, AI progress balloons through the moon soon.  Does balloon through the moon=doom?  Foom?  I’m skeptical of those predictions, but you don’t need to assume them for AI to massively upend the world.</p><p>The tasks AI can perform consistently have been getting twice as long roughly <a href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/">every seven months</a>.  Right now they can do tasks that take hours.  With a few more doublings, AI will be able to, at will, effectively replace any human researcher.  The number of AI models that can be run has been going up <a href="https://www.forethought.org/research/preparing-for-the-intelligence-explosion">25x per year</a>.  So even if it simply reaches human level and plateaus, it will be as if the population of human researchers is going up 25 times a year.  </p><p>Or, put more concisely: it’s possible to run more AIs performing longer tasks.  If these trends continue, then we’ll have a bunch of AIs that can do long tasks, effectively replacing most human researchers.  That will radically change the world.  So why does Huemer disagree? </p><p>Huemer’s first section expressing skepticism is titled “It Couldn’t Very Well Be <em>Under</em>-Hyped,” where ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://benthams.substack.com/p/michael-huemer-is-wrong-about-ai" class="read-button" target="_blank" rel="noopener">
          Read full article on  &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>