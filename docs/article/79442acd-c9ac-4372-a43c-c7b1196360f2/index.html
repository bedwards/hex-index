<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Anthropic&#039;s model welfare announcement: takeaways and further reading - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Anthropic&#039;s model welfare announcement: takeaways and further reading</h1>
        <div class="article-meta">
          <span class="author">By Robert Long</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/experiencemachines/index.html" class="publication">
            
          </a>
          <span class="separator">&middot;</span><time>Apr 24, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">16 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>Earlier today, Anthropic announced that they’ve launched a research program on model welfare—to my knowledge, the most significant step yet by a frontier lab to take potential AI welfare seriously.</p><p>Anthropic’s model welfare researcher is Kyle Fish—a friend and colleague of mine who worked with me to launch the AI welfare organization <a href="https://eleosai.org/">Eleos AI Research</a>, before he joined Anthropic to keep working on AI welfare there. Kyle is also a co-author on “<a href="https://arxiv.org/abs/2411.00986">Taking AI Welfare Seriously</a>”, a report which calls on AI companies to prepare for the possibility of AI consciousness and moral status.</p><p>As part of the announcement, Anthropic shared <a href="https://www.youtube.com/watch?v=pyXouxa0WnY">a conversation between Kyle and Anthropic’s Research Communications Lead Stuart Ritchie</a>, covering why model welfare matters, and what meaningful progress might look like. In this post, I'll highlight some key points from the interview, add some commentary, and suggest further reading.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!jvTB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9cf640b-ffeb-4d15-8835-4fdf55f5de38_1564x1038.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!jvTB!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9cf640b-ffeb-4d15-8835-4fdf55f5de38_1564x1038.png 424w, https://substackcdn.com/image/fetch/$s_!jvTB!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9cf640b-ffeb-4d15-8835-4fdf55f5de38_1564x1038.png 848w, https://substackcdn.com/image/fetch/$s_!jvTB!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9cf640b-ffeb-4d15-8835-4fdf55f5de38_1564x1038.png 1272w, https://substackcdn.com/image/fetch/$s_!jvTB!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9cf640b-ffeb-4d15-8835-4fdf55f5de38_1564x1038.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!jvTB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9cf640b-ffeb-4d15-8835-4fdf55f5de38_1564x1038.png" width="1564" height="1038" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b9cf640b-ffeb-4d15-8835-4fdf55f5de38_1564x1038.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1038,&quot;width&quot;:1564,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3068578,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://experiencemachines.substack.com/i/162087374?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46da6dda-a6e5-4fd7-85a3-8eb869975735_1564x1038.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!jvTB!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9cf640b-ffeb-4d15-8835-4fdf55f5de38_1564x1038.png 424w, https://substackcdn.com/image/fetch/$s_!jvTB!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9cf640b-ffeb-4d15-8835-4fdf55f5de38_1564x1038.png 848w, https://substackcdn.com/image/fetch/$s_!jvTB!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9cf640b-ffeb-4d15-8835-4fdf55f5de38_1564x1038.png 1272w, https://substackcdn.com/image/fetch/$s_!jvTB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9cf640b-ffeb-4d15-8835-4fdf55f5de38_1564x1038.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a><figcaption class="image-caption">Stuart Ritchie and Kyle Fish, courtesy of ChatGPT-4o</figcaption></figure></div><h1><strong>1. Many experts think that AI could be conscious soon</strong></h1><p>Stuart opens the interview on a defensive note:</p><blockquote><p>[00:24]: I suppose the first thing people will say when they're seeing this is, ‘Have they gone completely mad? This is a completely crazy question…’</p></blockquote><p>But as Kyle (like <a href="https://www.nytimes.com/2025/04/24/technology/ai-welfare-anthropic-claude.html?unlocked_article_code=1.CE8._VFI.9HgGKQQkvm3j&amp;smid=url-share">the New York Times article about the announcement</a>) notes, AI welfare is <a href="https://eleosai.org/post/experts-who-say-that-ai-welfare-is-a-serious-near-term-possibility/">increasingly recognized</a> as a legitimate field of study by top researchers.</p><p>Kyle points to "<a href="https://arxiv.org/abs/2308.08708">Consciousness in Artificial Intelligence</a>", a 2023 paper which examines leading scientific theories of consciousness and claims that there are "no obvious technical barriers" to AI systems satisfying computational indicators of consciousness drawn from these theories. Kyle notes that Yoshua Bengio, one of the most cited and respected AI researchers in the world, is a co-author on that paper.</p><p>Not fringe! Kyle continues,</p><blockquote><p>[5:00] I actually collaborated with [David Chalmers] on a recent paper on the topic of AI welfare. And again, this was an interdisciplinary effort trying to look at, ‘might it be the case that AI systems at some point warrant some form of moral consideration, either by nature of being conscious or by having some form of agency?’ And the conclusion from this report was that actually, it looks quite plausible that near-term systems have one or both of these characteristics, and may deserve some form of moral consideration.</p></blockquote><p>Kyle is referring to "<a href="https://arxiv.org/abs/2411.00986">Taking AI Welfare Seriously</a>," a report that Jeff Sebo and I co-authored—along with </p>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://experiencemachines.substack.com/p/anthropics-model-welfare-announcement" class="read-button" target="_blank" rel="noopener">
          Read full article on  &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>