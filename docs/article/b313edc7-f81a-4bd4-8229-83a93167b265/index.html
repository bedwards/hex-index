<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Import AI 421: Kimi 2 - a great Chinese open weight model; giving AI systems rights and what it means; and how to pause AI progress - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Import AI 421: Kimi 2 - a great Chinese open weight model; giving AI systems rights and what it means; and how to pause AI progress</h1>
        <div class="article-meta">
          <span class="author">By Jack Clark</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/importai/index.html" class="publication">
            Import AI
          </a>
          <span class="separator">&middot;</span><time>Jul 21, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">18 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>Welcome to Import AI, a newsletter about AI research. Import AI runs on lattes, ramen, and feedback from readers. If you’d like to support this, please subscribe.</p><p><strong>Want to stop or slow AI progress? Here's what you need:<br></strong><em>…MIRI enumerates the option space…<br></em>Researchers with MIRI have written a paper on the technical tools it'd take to slow or stop AI progress. For those not familiar with MIRI, the organization's leaders are shortly publishing a book called "If Anyone Builds It, Everyone Dies: Why Superhuman AI Would Kill Us All", so that should tell you where they're coming from as an organization. Though people have a range of views on this, I think it's very helpful to dispassionately look at what would be required to achieve a goal like this, which is what the researchers do here.<br><br><strong>So, you want to stop AI progress? Here's how: </strong>Here are the different categories you need to do work in and some of the capabilities you'll need:</p><ul><li><p><strong>Chip location:</strong> Track shipments via manufacturers and distributors; include hardware-enabled location tracking; centralize compute in a small number of secure and registered datacenters; inspect datacenters containing non-trivial amounts of compute; continuously monitor these datacenters. <br></p></li><li><p><strong>Chip manufacturing:</strong> Monitor for the construction of new fabs; restrict/control the equipment and materials; spy on and inspect fabs to ensure they're producing in line with policy restrictions; be able to verifiably deactivate fabs; be able to validate that fabs can make on-chip hardware-enabled governance mechanisms. <br></p></li><li><p><strong>Compute/AI monitoring: </strong>Create 'if then' measures to let you change your governance of a system depending on its capabilities; figure out compute thresholds for different governance regimes; keep track of consumer compute sales as well; build 'inference-only' hardware that can't be used for AI training. <br></p></li><li><p><strong>Non-compute monitoring:</strong> Tell companies to report specific capabilities; ensure you can do third-party and/or government evaluations of AI models; be able to inspect what happens at AI labs or other AI developers; place people inside AI organizations to audit them; create 'automated auditors'; use espionage to figure out what is going on in the private sector; protect whistleblowers who work at AI organizations. <br></p></li><li><p><strong>Avoiding proliferation:</strong> Ensure model weights are hard to steal; ensure algorithmic secrets are hard to steal; mandate 'structured access' (e.g., API-mediated) access to AI systems; limit the release of open weight models with powerful capabilities; tie models to hardware so they can only run on certain compute substrates; </p></li>...</ul>
      </div>

      <div class="read-full-article">
        <a href="https://importai.substack.com/p/import-ai-421-kimi-2-a-great-chinese" class="read-button" target="_blank" rel="noopener">
          Read full article on Import AI &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>