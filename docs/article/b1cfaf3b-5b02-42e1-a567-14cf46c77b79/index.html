<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Is AI Over-Hyped? - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Is AI Over-Hyped?</h1>
        <div class="article-meta">
          <span class="author">By Michael Huemer</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/fakenous/index.html" class="publication">
            Fake Nous
          </a>
          <span class="separator">&middot;</span><time>Dec 6, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">8 min read</span>
        </div>
      </header>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/ai-winter/index.html">
          <strong>AI winter</strong>
          <span class="read-time">14 min read</span>
        </a>
        <p class="topic-summary">Directly relevant to the article&#039;s discussion of past AI hype cycles and failed predictions from Simon, Newell, and Minsky. Provides historical context for periods when AI funding and interest collapsed after overpromising.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/chinese-room/index.html">
          <strong>Chinese room</strong>
          <span class="read-time">17 min read</span>
        </a>
        <p class="topic-summary">Directly relevant to the author&#039;s argument that AI doesn&#039;t truly &#039;understand&#039; anything - that LLMs only process text sequences without genuine comprehension. Searle&#039;s famous thought experiment addresses exactly this philosophical question about machine understanding.</p>
      </li>
        </ul>
      </section>
    

      <div class="article-excerpt">
        <div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!p3em!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!p3em!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif 424w, https://substackcdn.com/image/fetch/$s_!p3em!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif 848w, https://substackcdn.com/image/fetch/$s_!p3em!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif 1272w, https://substackcdn.com/image/fetch/$s_!p3em!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!p3em!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif" width="616" height="410.33865814696486" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:417,&quot;width&quot;:626,&quot;resizeWidth&quot;:616,&quot;bytes&quot;:25006,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/avif&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://fakenous.substack.com/i/178547398?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!p3em!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif 424w, https://substackcdn.com/image/fetch/$s_!p3em!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif 848w, https://substackcdn.com/image/fetch/$s_!p3em!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif 1272w, https://substackcdn.com/image/fetch/$s_!p3em!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F106eb3ee-3ad0-471e-8b69-61c740d9db7e_626x417.avif 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a></figure></div><p>I suspect that people have been over-hyping the importance of AI and how it’s going to change our lives. I doubt that it is as revolutionary as people are saying.</p><p>Why do I say that?</p><h2>1. It Couldn’t Very Well Be <em>Under</em>-Hyped</h2><p>People have been making really extreme statements about AI. Some people are saying that it is literally going to kill everyone, perhaps within a few years. (See <a href="https://www.amazon.com/dp/0316595640">Yudkowsky &amp; Soares</a>.)</p><p>Others think it’s going to usher in a virtual paradise on Earth, curing aging and making us all virtually immortal geniuses. (See <a href="https://www.amazon.com/dp/0593152344/">Kurzweil</a>.)</p><p>The CEO of Google thinks that AI will be a more profound discovery than fire or electricity. (See <a href="https://www.cnbc.com/2018/02/01/google-ceo-sundar-pichai-ai-is-more-important-than-fire-electricity.html">Pichai</a>.)</p><p>The CEO of Open AI says that AI will prove to be the most important technology ever created. (See <a href="https://www.iankhan.com/top-quotes-by-sam-altman-on-ai-the-future-high-tied-to-ai-growth-chatgpt-interest/">Altman</a>.)</p><p>Not everyone is that dramatic. But enough people are being super-dramatic about AI that it is hardly possible that AI is <em>under</em>-hyped at this point. If we’re making an error in one direction or the other, it’s almost certainly in the over-hyping direction. </p><p>It’s like if your friend tells you that person P is the greatest genius who has ever lived. When you meet P, are you going to have a higher or a lower opinion than your friend? Almost certainly lower. It couldn’t very well be higher, and although it could be the same, that is a priori unlikely. Most people are not the greatest genius who has ever lived. </p><p>In general, most things that are said by someone to be the most X thing in the world (for some attribute X) are not in fact the most X thing in the world.</p><h2>2. The History of Hype</h2><p>Which brings me to the history of hype. A lot of things have been over-hyped. And here, I include both overly optimistic and overly pessimistic predictions. </p><h3>The Dramatism Bias</h3><p>Human beings, especially journalists and other authors, have a bias towards the <em>dramatic</em>. That includes predictions of extreme transformations of all kinds. Whether positive or negative, these predictions entertain us and attract attention. We might even decide to believe (or tell ourselves that we believe) these predictions for entertainment purposes.</p><p>Bias toward the dramatic is the best explanation for why there have been so many failed disaster predictions. In 1969, Stanford ecologist Paul Ehrlich predicted that “unless we are extremely lucky, </p>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://fakenous.substack.com/p/is-ai-over-hyped" class="read-button" target="_blank" rel="noopener">
          Read full article on Fake Nous &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>