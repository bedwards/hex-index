<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Scientists should use AI as a tool, not an oracle - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Scientists should use AI as a tool, not an oracle</h1>
        <div class="article-meta">
          <span class="author">By Arvind Narayanan</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/aisnakeoil/index.html" class="publication">
            AI Snake Oil
          </a>
          <span class="separator">&middot;</span><time>Jun 3, 2024</time>
          <span class="separator">&middot;</span>
          <span class="read-time">9 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>Who produces AI hype? As we discuss in the AI Snake Oil <a href="https://www.aisnakeoil.com/p/ai-snake-oil-is-now-available-to">book</a>, it is not just companies and the media but also AI researchers. For example, a pair of widely-publicized papers in Nature in December 2023 claimed to have <a href="https://www.nature.com/articles/s41586-023-06735-9">discovered</a> over 2.2 million new materials using AI, and robotically <a href="https://www.nature.com/articles/s41586-023-06734-w">synthesized</a> 41 of them. Unfortunately, the claims were <a href="https://chemrxiv.org/engage/chemrxiv/article-details/65957d349138d231611ad8f7">quickly</a> <a href="https://x.com/Robert_Palgrave/status/1744383965270581615">debunked</a>: “Most of the [41] materials produced were misidentified, and the rest were already known”. As for the large dataset, examining a sample of 250 compounds showed that it was <a href="https://pubs.acs.org/doi/10.1021/acs.chemmater.4c00643">mostly junk</a>.</p><p>A core selling point of machine learning is discovery without understanding, which is why errors are particularly common in machine-learning-based science. Three years ago, we <a href="https://reproducible.cs.princeton.edu/">compiled evidence</a> revealing that an error called leakage — the machine learning version of teaching to the test — was pervasive, affecting hundreds of papers from 17 disciplines. Since then, we have been trying to understand the problem better and devise solutions.&nbsp;</p><p>This post presents an update. In short, we think things will get worse before they get better, although there are glimmers of hope on the horizon.&nbsp;</p><p><strong>The carnage continues</strong></p><p>In our most recent compilation, the number of disciplines where researchers have <a href="https://reproducible.cs.princeton.edu/#rep-failures">uncovered leakage</a> in published work has reached 30. The majority are medical fields, which we strongly suspect is due to the fact that since errors in medical research can be particularly consequential, medical fields seem to put much more effort into establishing best practices and critically reviewing previously published work. About 650 papers across all fields are affected, which we hypothesize is a vast underestimate — when researchers look for leakage systematically, in many fields they find that the <em>majority</em> of sampled studies commit the error of leakage.</p><p>Leakage is one of many reasons for reproducibility failures. There are widespread <a href="https://reforms.cs.princeton.edu/appendix3.html">shortcomings</a> in every step of ML-based science, from data collection to preprocessing and reporting results. Problems that might lead to irreproducibility include improper comparisons to baselines, unrepresentative samples, results being sensitive to specific modeling choices, and not reporting model uncertainties. There is also the basic problem of researchers failing to publish their code and data, precluding reproducibility. For example, Gabelica et al. <a href="https://pubmed.ncbi.nlm.nih.gov/35654271/">examined</a> 333 open-access journals indexed on BioMed Central in January 2019 and found that out of the 1,800 papers that pledged to share data upon request, 93% did not do so.</p><p><strong>The roots run deep</strong></p><p>Even ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://www.normaltech.ai/p/scientists-should-use-ai-as-a-tool" class="read-button" target="_blank" rel="noopener">
          Read full article on AI Snake Oil &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>