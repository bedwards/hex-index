<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The Shape of AI: Jaggedness, Bottlenecks and Salients - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>The Shape of AI: Jaggedness, Bottlenecks and Salients</h1>
        <div class="article-meta">
          <span class="author">By Ethan Mollick</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/oneusefulthing/index.html" class="publication">
            One Useful Thing
          </a>
          <span class="separator">&middot;</span><time>Dec 20, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">10 min read</span>
        </div>
      </header>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/reverse-salient/index.html">
          <strong>Reverse salient</strong>
          <span class="read-time">12 min read</span>
        </a>
        <p class="topic-summary">The article explicitly references Thomas Hughes&#039;s concept of &#039;reverse salients&#039; - the single technical or social problem holding back a system from advancing. This systems theory concept from the history of technology is directly relevant and likely unfamiliar to most readers.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/theory-of-constraints/index.html">
          <strong>Theory of constraints</strong>
          <span class="read-time">14 min read</span>
        </a>
        <p class="topic-summary">The article&#039;s central argument about bottlenecks limiting AI capability directly parallels Goldratt&#039;s Theory of Constraints from operations management. This would provide readers with a formal framework for understanding why &#039;a system is only as functional as its worst components.&#039;</p>
      </li>
        </ul>
      </section>
    

      <div class="article-excerpt">
        <p>Back in the ancient AI days of 2023, my co-authors and I invented a term to describe the weird ability of AI to do some work incredibly well and other work incredibly badly in ways that didn’t map very well to our human intuition of the difficulty of the task. We called this the <a href="https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged">“Jagged Frontier”</a> of AI ability, and it remains a key feature of AI and an endless source of confusion. How can an AI be <a href="https://arxiv.org/pdf/2412.10849">superhuman at differential medical diagnosis</a> or <a href="https://simonwillison.net/2025/Jul/19/openai-gold-medal-math-olympiad/">good at very hard math </a>(yes, they are really good at math now, famously outside the frontier until recently) and yet still be bad at <a href="https://www.nytimes.com/interactive/2025/03/26/business/ai-smarter-human-intelligence-puzzle.html">relatively simple visual puzzles</a> or <a href="https://www.anthropic.com/research/project-vend-2">running a vending machine</a>? The exact abilities of AI are often a <a href="https://www.nature.com/articles/s41586-024-07930-y">mystery</a>, so it is no wonder AI is harder to use than it seems.</p><p>I think jaggedness is going to remain a big part of AIs going forward, but there is less certainty over what it means. <a href="https://x.com/tomaspueyo">Tomas Pueyo</a> posted this viral image on <a href="https://x.com/tomaspueyo/status/1993360931267473662?s=20">X</a> that outlined his <a href="https://unchartedterritories.tomaspueyo.com/p/when-will-we-make-god">vision</a>. In his view, the growing frontier will outpace jaggedness. Sure, the AI is bad at some things and may still be relatively bad even as it improves, but the collective human ability frontier is mostly fixed, and AI ability is growing rapidly. What does it matter if AI is relatively bad at running a vending machine, if the AI still becomes better than any human?</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!SY-V!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92c4e814-870d-401b-80ac-3ebfa0cfc3af_3444x1924.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!SY-V!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92c4e814-870d-401b-80ac-3ebfa0cfc3af_3444x1924.jpeg 424w, https://substackcdn.com/image/fetch/$s_!SY-V!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92c4e814-870d-401b-80ac-3ebfa0cfc3af_3444x1924.jpeg 848w, https://substackcdn.com/image/fetch/$s_!SY-V!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92c4e814-870d-401b-80ac-3ebfa0cfc3af_3444x1924.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!SY-V!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92c4e814-870d-401b-80ac-3ebfa0cfc3af_3444x1924.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!SY-V!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92c4e814-870d-401b-80ac-3ebfa0cfc3af_3444x1924.jpeg" width="1456" height="813" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/92c4e814-870d-401b-80ac-3ebfa0cfc3af_3444x1924.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:813,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/$s_!SY-V!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92c4e814-870d-401b-80ac-3ebfa0cfc3af_3444x1924.jpeg 424w, https://substackcdn.com/image/fetch/$s_!SY-V!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92c4e814-870d-401b-80ac-3ebfa0cfc3af_3444x1924.jpeg 848w, https://substackcdn.com/image/fetch/$s_!SY-V!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92c4e814-870d-401b-80ac-3ebfa0cfc3af_3444x1924.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!SY-V!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92c4e814-870d-401b-80ac-3ebfa0cfc3af_3444x1924.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a></figure></div><p>While the future is always uncertain, I think this conception misses out on a few critical aspects about the nature of work and technology. First, the frontier is very jagged indeed, and it might be that, because of this jaggedness, we get supersmart AIs which never quite fully overlap with human tasks. For example, a major source of jaggedness is that LLMs do not remember new tasks and learn from them in a permanent way. A lot of AI companies are pursuing solutions to this issue, but it may be that this problem is harder to solve than researchers expect. Without memory, AIs will struggle to do many tasks humans can do, even while being superhuman in other areas. <a href="https://colin-fraser.net/">Colin Fraser</a> drew <a href="https://x.com/colin_fraser/status/1994188009608983008?s=20">two examples</a> of what this sort of AI-human overlap might look like. You can see how AI is indeed superhuman in some areas, but in others it is either far below human level or not </p>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://www.oneusefulthing.org/p/the-shape-of-ai-jaggedness-bottlenecks" class="read-button" target="_blank" rel="noopener">
          Read full article on One Useful Thing &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>