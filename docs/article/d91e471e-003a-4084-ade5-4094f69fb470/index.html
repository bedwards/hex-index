<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LLM Hallucinations Are Still Absolutely Nuts - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>LLM Hallucinations Are Still Absolutely Nuts</h1>
        <div class="article-meta">
          <span class="author">By Freddie deBoer</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/freddiedeboer/index.html" class="publication">
            
          </a>
          <span class="separator">&middot;</span><time>Jan 5, 2026</time>
          <span class="separator">&middot;</span>
          <span class="read-time">21 min read</span>
        </div>
      </header>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/hallucination-artificial-intelligence/index.html">
          <strong>Hallucination (artificial intelligence)</strong>
          <span class="read-time">10 min read</span>
        </a>
        <p class="topic-summary">Core concept of the entire article - the piece is fundamentally about LLM hallucinations, providing a detailed case study of Google Gemini fabricating elaborate false details about Connecticut Valley Hospital. Understanding the technical phenomenon enhances appreciation of the examples.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/catch-22-logic/index.html">
          <strong>Catch-22 (logic)</strong>
          <span class="read-time">13 min read</span>
        </a>
        <p class="topic-summary">The author explicitly questions whether Gemini&#039;s generated scenario constitutes a Catch-22, referencing this specific logical paradox. Understanding the formal definition of paradoxical situations with no escape due to contradictory rules enriches the critique of the AI&#039;s reasoning.</p>
      </li>
        </ul>
      </section>
    

      <div class="article-excerpt">
        <div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!1Ikv!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb1b8bdc-4f64-4d1b-b781-adec524aaa9c_666x375.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!1Ikv!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb1b8bdc-4f64-4d1b-b781-adec524aaa9c_666x375.jpeg 424w, https://substackcdn.com/image/fetch/$s_!1Ikv!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb1b8bdc-4f64-4d1b-b781-adec524aaa9c_666x375.jpeg 848w, https://substackcdn.com/image/fetch/$s_!1Ikv!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb1b8bdc-4f64-4d1b-b781-adec524aaa9c_666x375.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!1Ikv!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb1b8bdc-4f64-4d1b-b781-adec524aaa9c_666x375.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!1Ikv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb1b8bdc-4f64-4d1b-b781-adec524aaa9c_666x375.jpeg" width="666" height="375" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bb1b8bdc-4f64-4d1b-b781-adec524aaa9c_666x375.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:375,&quot;width&quot;:666,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!1Ikv!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb1b8bdc-4f64-4d1b-b781-adec524aaa9c_666x375.jpeg 424w, https://substackcdn.com/image/fetch/$s_!1Ikv!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb1b8bdc-4f64-4d1b-b781-adec524aaa9c_666x375.jpeg 848w, https://substackcdn.com/image/fetch/$s_!1Ikv!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb1b8bdc-4f64-4d1b-b781-adec524aaa9c_666x375.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!1Ikv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb1b8bdc-4f64-4d1b-b781-adec524aaa9c_666x375.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a></figure></div><p>A couple months back, a grad student reached out to me to see if I could help with some research they were doing. (I’m keeping things vague for reasons that will be apparent.) They had heard that I had previously been a patient at Connecticut Valley Hospital. I told them that I would be happy to do my best with whatever questions they might have, but that I hadn’t been there in 20 years and my memories were dimmed by the weight of years, psychosis, and psychiatric medications. But, sure - I would tell them what I knew. I answered questions about my experiences there, mainly focusing on how I came to be admitted, my legal status on my first go round, the wards I had principally been in, and my release. We exchanged email for awhile and that was that.</p><p>Then, just a few days before the Christmas holiday, they got back in touch with me. They had some more questions that they had not been able to solve via research. They asked me about several features of life “on campus” that I couldn’t answer, and I grew confused. One was about the “Vance Building.” I told them I wasn’t familiar with it, but that wasn’t unusual; CVH is a sprawling facility with lots of different buildings that in many ways operate as their own little worlds, and again, it’s been several decades since I was there. Then they asked me if I remembered “the club.” To which I replied, the… club? </p><p>A bit of confused back and forth went down, and eventually they sheepishly admitted that they had been doing some research through Google Gemini. They insisted (quite strenuously) that they would never have an LLM write any of their actual work for them - and, for the record, I believe them - but that they had tried to fill in gaps in information with AI. With my gentle pushback, they were now concerned that they had a few facts wrong. I asked them if they would copy and paste the Gemini output and send it to me and they did. And, hoo boy! Please note that Gemini is <a href="https://www.the-independent.com/tech/google-gemini-vs-chatgpt-cloudflare-ai-b2881240.html">believed by many</a> to be the most capable consumer LLM and that the grad student was using the “Thinking” mode for this. I was sent thousands of words of this stuff; I’m going to try and spare you by </p>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://freddiedeboer.substack.com/p/llm-hallucinations-are-still-fucking" class="read-button" target="_blank" rel="noopener">
          Read full article on  &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>