<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Politics vastly increases AI moral hazards - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Politics vastly increases AI moral hazards</h1>
        <div class="article-meta">
          <span class="author">By Jimmy Alfonso Licon</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/jimmyalfonsolicon/index.html" class="publication">
            
          </a>
          <span class="separator">&middot;</span><time>Feb 16, 2026</time>
          <span class="separator">&middot;</span>
          <span class="read-time">22 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p><em>Please <strong>like</strong>, <strong>share</strong>, <strong>comment</strong>, and <strong>subscribe</strong>. Thank you, as always, for reading and listening.</em></p><div><hr></div><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!0OPF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!0OPF!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png 424w, https://substackcdn.com/image/fetch/$s_!0OPF!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png 848w, https://substackcdn.com/image/fetch/$s_!0OPF!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png 1272w, https://substackcdn.com/image/fetch/$s_!0OPF!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!0OPF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png" width="525" height="787.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1536,&quot;width&quot;:1024,&quot;resizeWidth&quot;:525,&quot;bytes&quot;:4181442,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://jimmyalfonsolicon.substack.com/i/180761027?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!0OPF!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png 424w, https://substackcdn.com/image/fetch/$s_!0OPF!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png 848w, https://substackcdn.com/image/fetch/$s_!0OPF!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png 1272w, https://substackcdn.com/image/fetch/$s_!0OPF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3f7d6f5-624a-47fc-96d8-c3c65a0a958c_1024x1536.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a></figure></div><div><hr></div><h3><strong>About the Author</strong></h3><p><em>Jimmy Alfonso Licon is a philosophy professor at <strong>Arizona State University</strong> working on ignorance, ethics, cooperation and God. Before that, he taught at <strong>University of Maryland</strong>, <strong>Georgetown</strong>, and <strong>Towson University</strong>. He loves classic rock and Western, movies, and combat sports. He lives with his wife, a lawyer, at the foot of the Superstition Mountains. He also abides.</em></p><div><hr></div><p>This post is based on a forthcoming book chapter of a similar name to be published in <em><strong>Philosophy and AI: Applied Issues in the Philosophy of AI</strong></em> from Springer.</p><div><hr></div><p>The rapid rise of artificial intelligence and robots has created both new technologies and new moral risks potentially amplified by politics. As artificial systems become more sophisticated—more fluent, more socially responsive, more deeply integrated into ordinary life—their moral status becomes hard to pin down. Are we dealing with mere tools, or with candidates for moral standing? That issue shapes how we design, deploy, regulate, and relate to artificial systems.</p><p>A moral hazard, for present purposes, exists whenever agents are insulated from the moral consequences of their actions. In the context of AI and robotics, moral hazard arises because we face a dilemma. On one side lies the possibility that some artificial systems will deserve moral consideration—due to features like self-awareness, rationality, or the capacity to suffer—yet be treated as property or slaves. On the other side lies the possibility that artificial systems will not deserve moral consideration, yet will be treated as if they do, diverting finite moral and material resources away from humans and animals who genuinely have moral standing. Either way, serious moral errors are possible, and they will not be costless.¹</p><p>The central claim is that political institutions will tend to make these hazards worse, not better. Democratic incentives reward tribal signaling and rationalized belief. Ambiguous facts about AI consciousness are therefore ripe for political exploitation. Instead of careful attempts to resolve the underlying dilemma, we should expect rival factions to amplify one horn or the other in ways that boost their reputations and extract material or symbolic benefits. The resulting policies and social norms will frequently insulate decision-makers from the costs of their moral and epistemic mistakes.</p><p>What follows clarifies the moral dilemma and the notion of “debatable personhood,” explains how democratic politics encourages irrationality and </p>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://jimmyalfonsolicon.substack.com/p/politics-vastly-increases-ai-moral" class="read-button" target="_blank" rel="noopener">
          Read full article on  &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>