<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>TPUv7: Google Takes a Swing at the King - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>TPUv7: Google Takes a Swing at the King</h1>
        <div class="article-meta">
          <span class="author">By Dylan Patel</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/semianalysis/index.html" class="publication">
            SemiAnalysis
          </a>
          <span class="separator">&middot;</span><time>Nov 28, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">47 min read</span>
        </div>
      </header>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/tensor-processing-unit/index.html">
          <strong>Tensor Processing Unit</strong>
          <span class="read-time">12 min read</span>
        </a>
        <p class="topic-summary">The article centers on Google&#039;s TPU chips competing with Nvidia, but readers may not understand the technical architecture that makes TPUs specialized for AI workloads versus general-purpose GPUs</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/cuda/index.html">
          <strong>CUDA</strong>
          <span class="read-time">12 min read</span>
        </a>
        <p class="topic-summary">The article mentions Nvidia&#039;s &#039;CUDA moat&#039; as a key competitive advantage that Google needs to overcome - understanding CUDA&#039;s parallel computing platform explains why software lock-in is so powerful in the GPU market</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/vertical-integration/index.html">
          <strong>Vertical integration</strong>
          <span class="read-time">15 min read</span>
        </a>
        <p class="topic-summary">The article describes Google&#039;s strategy of controlling the full stack from silicon to software, and the &#039;circular economy&#039; criticism of Nvidia funding startups - this business strategy concept provides crucial context for understanding the competitive dynamics</p>
      </li>
        </ul>
      </section>
    

      <div class="article-excerpt">
        <p>The two best models in the world, Anthropic’s Claude 4.5 Opus and Google’s Gemini 3 have the majority of their training and inference infrastructure on Google’s TPUs and Amazon’s Trainium. Now Google is selling TPUs physically to multiple firms. Is this the end of Nvidia’s dominance?</p><p>The dawn of the AI era is here, and it is crucial to understand that the cost structure of AI-driven software deviates considerably from traditional software. Chip microarchitecture and system architecture play a vital role in the development and scalability of these innovative new forms of software. The hardware infrastructure on which AI software runs has a notably larger impact on Capex and Opex, and subsequently the gross margins, in contrast to earlier generations of software, where developer costs were relatively larger. Consequently, it is even more crucial to devote considerable attention to optimizing your AI infrastructure to be able to deploy AI software. Firms that have an advantage in infrastructure will also have an advantage in the ability to deploy and scale applications with AI.</p><p>Google had <a href="https://cloud.google.com/blog/products/ai-machine-learning/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu">peddled the idea of building AI-specific infrastructure as far back as 2006,</a> but the problem came to a boiling point in 2013. They realized they needed to double the number of datacenters they had if they wanted to deploy AI at any scale. As such, they started laying the groundwork for their TPU chips which were put into production in 2016. It’s interesting to compare this to Amazon, who in the same year, realized they needed to build custom silicon too. <a href="https://www.semianalysis.com/i/108660819/amazon-nitro">In 2013, they started the Nitro Program</a>, which was focused on <a href="https://www.semianalysis.com/i/108660819/amazon-nitro">developing silicon to optimize general-purpose CPU computing and storage</a>. Two very different companies optimized their efforts for infrastructure for <a href="https://www.semianalysis.com/i/108660819/the-next-era-of-computing">different eras of computing and software paradigms</a>.</p><p>We’ve long believed that the TPU is among the world’s best systems for AI training and inference, neck and neck with king of the jungle Nvidia. 2.5 years ago we wrote about TPU supremacy, and this thesis has proven to be very correct.</p><div class="digest-post-embed" data-attrs="{&quot;nodeId&quot;:&quot;c93fafdc-7736-4a8d-85d8-83efe78f3647&quot;,&quot;caption&quot;:&quot;The dawn of the AI era is here, and it is crucial to understand that the cost structure of AI-driven software deviates considerably from traditional software. Chip microarchitecture and system architecture play a vital role in the development and scalability of these innovative new forms of software. The hardware infrastructure on which AI software runs has a notably larger impact on Capex and Opex, and subsequently the gross margins, in contrast to earlier generations of software, where developer costs were relatively larger. Consequently, it is even more crucial to devote considerable attention to optimizing your AI infrastructure to be able to deploy AI software. Firms that have an advantage in infrastructure will also have an advantage in the ability to deploy and scale applications with AI.&quot;,&quot;cta&quot;:&quot;Read full story&quot;,&quot;showBylines&quot;:true,&quot;size&quot;:&quot;sm&quot;,&quot;isEditorNode&quot;:true,&quot;title&quot;:&quot;Google AI Infrastructure Supremacy: Systems Matter More Than Microarchitecture&quot;,&quot;publishedBylines&quot;:[{&quot;id&quot;:21783302,&quot;name&quot;:&quot;Dylan Patel&quot;,&quot;bio&quot;:&quot;Bridging the gap between business and the worlds most important industry.&quot;,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/adcf9d53-769e-4d9e-8982-30c3dc8488dc_501x527.png&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:1000},{&quot;id&quot;:132737451,&quot;name&quot;:&quot;George Cozma&quot;,&quot;bio&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/901a4be5-4278-4b95-8bd3-712c961c59e8_501x527.png&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null},{&quot;id&quot;:135179316,&quot;name&quot;:&quot;Gerald Wong&quot;,&quot;bio&quot;:&quot;Call me Howie&quot;,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!sF8k!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa57a585d-a599-4c4d-abde-e862bfbb98c5_501x527.png&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null}],&quot;post_date&quot;:&quot;2023-04-12T14:32:11.462Z&quot;,&quot;cover_image&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b6fb8cda-5f23-477e-b4f3-27245364be1e_1088x828.png&quot;,&quot;cover_image_alt&quot;:null,&quot;canonical_url&quot;:&quot;https://newsletter.semianalysis.com/p/google-ai-infrastructure-supremacy&quot;,&quot;section_name&quot;:null,&quot;video_upload_id&quot;:null,&quot;id&quot;:175660936,&quot;type&quot;:&quot;newsletter&quot;,&quot;reaction_count&quot;:115,&quot;comment_count&quot;:32,&quot;publication_id&quot;:6349492,&quot;publication_name&quot;:&quot;SemiAnalysis&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!II4V!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88ad87ad-b5c5-4687-b13e-672f72725795_501x501.png&quot;,&quot;belowTheFold&quot;:false}"></div><p>TPU’s results speak for themselves: Gemini 3 is one of the best models in the world and was trained entirely on TPUs. In this report, we will talk about the huge changes in Google’s strategy to properly commercialize the TPU for external customers, becoming the newest and most threatening merchant silicon challenger to Nvidia. </p><p>We plan to:</p><ul><li><p>(Re-)Educate our clients and new </p></li>...</ul>
      </div>

      <div class="read-full-article">
        <a href="https://newsletter.semianalysis.com/p/tpuv7-google-takes-a-swing-at-the" class="read-button" target="_blank" rel="noopener">
          Read full article on SemiAnalysis &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>