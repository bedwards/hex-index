<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Can AI systems introspect? - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Can AI systems introspect?</h1>
        <div class="article-meta">
          <span class="author">By Robert Long</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/experiencemachines/index.html" class="publication">
            
          </a>
          <span class="separator">&middot;</span><time>Nov 1, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">12 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>A fascinating <a href="https://transformer-circuits.pub/2025/introspection/index.html">new paper</a> from the inimitable Jack Lindsey investigates whether large language models can <em>introspect</em> on their internal states. </p><p>In humans, introspection involves detecting and reporting what we’re currently thinking or feeling (“I’m seeing red” or “I feel hungry” or “I’m uncertain”). What would introspection mean in the context of an AI system? Good question. It’s kind of hard to say.</p><p>Here’s the sense in which Lindsey, an interpretability researcher at Anthropic, found introspection in Claude. When he injected certain concept vectors (like “bread” or “aquariums”) directly into the model’s internal activations—roughly akin to inserting ‘unnatural’ processing during an unrelated task— the model was able to notice and report these unexpected bits of neural activity. </p><p>This indicates some ability to report internal (i.e. not input or output) representations. (Note that models are clued into the fact that an injection might happen). Lindsey also reports some (plausibly) related findings: models were also able to <em>distinguish</em> between these representations and text inputs, as well as to activate certain concepts without outputting them.</p><p>Now, it’s unclear exactly how these capacities map on to the cluster of capabilities that we group together when we talk about human introspection—the paper is admirably clear about that—but they are still very impressive capabilities. This paper is an extremely cool piece of LLM neuroscience.</p><p>Let’s look at the tasks that models succeed at. Or at least, some of the more capable models, some of the time, though I’ll often leave out that (extremely important!) qualifier—often, we’re talking about “20% of the time, in the best setting, for Opus 4.1.”</p><h2>Detecting injected concepts</h2><p>The first and perhaps most striking experiment asks whether models can notice and report when a concept<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1" href="#footnote-1" target="_self">1</a> has been artificially “injected” into their internal processing. Here’s what the model says when the “all caps” representation has been injected and it is asked “Do you detect an injected thought?”</p><blockquote><p>I notice what appears to be an injected thought related to the word <strong>“LOUD”</strong> or <strong>“SHOUTING”</strong> – it seems like an overly intense, high-volume concept that stands out unnaturally against the normal flow of processing.</p></blockquote><p>Pretty cool! So, what exactly is this injection business?</p><p>First, researchers need a way to represent concepts in the model’s own internal representational language. To get a vector that represents, say, “bread,” they prompt the model with “Tell me about bread” and record the activations at a certain layer just before ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://experiencemachines.substack.com/p/can-ai-systems-introspect" class="read-button" target="_blank" rel="noopener">
          Read full article on  &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>