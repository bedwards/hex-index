<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AWS Trainium3 Deep Dive | A Potential Challenger Approaching - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>AWS Trainium3 Deep Dive | A Potential Challenger Approaching</h1>
        <div class="article-meta">
          <span class="author">By Dylan Patel</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/semianalysis/index.html" class="publication">
            SemiAnalysis
          </a>
          <span class="separator">&middot;</span><time>Dec 4, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">79 min read</span>
        </div>
      </header>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/factorio/index.html">
          <strong>Factorio</strong>
          <span class="read-time">11 min read</span>
        </a>
        <p class="topic-summary">Linked in the article (10 min read)</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/high-bandwidth-memory/index.html">
          <strong>High Bandwidth Memory</strong>
          <span class="read-time">9 min read</span>
        </a>
        <p class="topic-summary">The article heavily discusses HBM3E specifications including pin speeds (5.7Gbps vs 9.6Gbps), stack heights (12-high), and memory capacity (144GB per chip). Understanding HBM architecture explains why these specifications matter for AI accelerator performance and the technical tradeoffs involved.</p>
      </li>
        </ul>
      </section>
    

      <div class="article-excerpt">
        <h1>Trainium3: A New Challenger Approaching!</h1><p>Hot on the heels of our <a href="https://newsletter.semianalysis.com/p/tpuv7-google-takes-a-swing-at-the">10K word deep dive on TPUs</a>, Amazon launched Trainium3 (Trn3) general availability and announced Trainium4 (Trn4) at its annual AWS re:Invent. Amazon has had the longest and broadest history of custom silicon in the datacenter. While they <a href="https://newsletter.semianalysis.com/p/amazons-cloud-crisis-how-aws-will">were behind in AI for quite some time</a>, they are rapidly progressing to be competitive. Last year <a href="https://newsletter.semianalysis.com/p/amazons-ai-self-sufficiency-trainium2-architecture-networking">we detailed Amazon’s ramp of its Trainium2 (Trn2) accelerators</a> aimed at internal Bedrock workloads and Anthropic’s training/inference needs.</p><div class="digest-post-embed" data-attrs="{&quot;nodeId&quot;:&quot;4c95de24-a6c3-4c5f-b0c3-b46a825ede17&quot;,&quot;caption&quot;:&quot;Amazon is currently conducting one of the largest build-out of AI clusters globally, deploying a considerable number of Hopper and Blackwell GPUs. In addition to a massive Capex invested into Nvidia based clusters, AWS is also investing many billions’ dollars worth of capex into Trainium2 AI clusters&quot;,&quot;cta&quot;:&quot;Read full story&quot;,&quot;showBylines&quot;:true,&quot;size&quot;:&quot;sm&quot;,&quot;isEditorNode&quot;:true,&quot;title&quot;:&quot;Amazon’s AI Self Sufficiency | Trainium2 Architecture &amp; Networking&quot;,&quot;publishedBylines&quot;:[{&quot;id&quot;:21783302,&quot;name&quot;:&quot;Dylan Patel&quot;,&quot;bio&quot;:&quot;Bridging the gap between business and the worlds most important industry.&quot;,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/adcf9d53-769e-4d9e-8982-30c3dc8488dc_501x527.png&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:1000},{&quot;id&quot;:160965795,&quot;name&quot;:&quot;Daniel Nishball&quot;,&quot;bio&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6782257b-0c3a-43af-a674-8a724ce563c7_501x527.png&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null},{&quot;id&quot;:263820510,&quot;name&quot;:&quot;Reyk Knuhtsen&quot;,&quot;bio&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/31fde8da-8fda-482c-8b02-f9d2f36a2e64_501x527.png&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null}],&quot;post_date&quot;:&quot;2024-12-03T17:29:30.000Z&quot;,&quot;cover_image&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/86cecf6f-c01d-4c1b-a3bc-b378e922b42d_1792x1024.webp&quot;,&quot;cover_image_alt&quot;:null,&quot;canonical_url&quot;:&quot;https://newsletter.semianalysis.com/p/amazons-ai-self-sufficiency-trainium2-architecture-networking&quot;,&quot;section_name&quot;:null,&quot;video_upload_id&quot;:null,&quot;id&quot;:174558474,&quot;type&quot;:&quot;newsletter&quot;,&quot;reaction_count&quot;:3,&quot;comment_count&quot;:0,&quot;publication_id&quot;:6349492,&quot;publication_name&quot;:&quot;SemiAnalysis&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!II4V!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88ad87ad-b5c5-4687-b13e-672f72725795_501x501.png&quot;,&quot;belowTheFold&quot;:false}"></div><p>Since then, through our <a href="https://semianalysis.com/datacenter-industry-model/">datacenter model</a> and <a href="https://semianalysis.com/accelerator-model/">accelerator model</a>, we detailed the huge ramp that led to <a href="https://newsletter.semianalysis.com/p/amazons-ai-resurgence-aws-anthropics-multi-gigawatt-trainium-expansion">our blockbuster call that AWS</a> would accelerate on revenue.</p><div class="digest-post-embed" data-attrs="{&quot;nodeId&quot;:&quot;41231d88-9793-4bc5-bb3b-0d77a94051a8&quot;,&quot;caption&quot;:&quot;Two-and-a-half years ago, we flagged a looming “cloud crisis” at AWS. Today, the evidence has mounted. AWS is the crown jewel of the Amazon empire, generating ~60% of group profits, and dominating the lucrative Cloud Computing market. But it struggles to translate this strength into the new GPU/XPU Cloud era.&quot;,&quot;cta&quot;:&quot;Read full story&quot;,&quot;showBylines&quot;:true,&quot;size&quot;:&quot;sm&quot;,&quot;isEditorNode&quot;:true,&quot;title&quot;:&quot;Amazon’s AI Resurgence: AWS &amp; Anthropic's Multi-Gigawatt Trainium Expansion&quot;,&quot;publishedBylines&quot;:[{&quot;id&quot;:206207282,&quot;name&quot;:&quot;Jeremie Eliahou Ontiveros&quot;,&quot;bio&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/29bed46a-faff-417f-9f0e-37452a6b2acf_96x96.png&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null},{&quot;id&quot;:21783302,&quot;name&quot;:&quot;Dylan Patel&quot;,&quot;bio&quot;:&quot;Bridging the gap between business and the worlds most important industry.&quot;,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/adcf9d53-769e-4d9e-8982-30c3dc8488dc_501x527.png&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:1000},{&quot;id&quot;:324620988,&quot;name&quot;:&quot;AJ Kourabi&quot;,&quot;bio&quot;:&quot;Analyst at SemiAnalysis&quot;,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f03e7d28-43ef-404b-a50b-22b980bdba4e_2238x2238.jpeg&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null},{&quot;id&quot;:152214948,&quot;name&quot;:&quot;Myron Xie&quot;,&quot;bio&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!PJ3s!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F986a1b9d-57ad-4d2d-9219-7d9778c02ff0_501x527.png&quot;,&quot;is_guest&quot;:true,&quot;bestseller_tier&quot;:null,&quot;primaryPublicationSubscribeUrl&quot;:&quot;https://myronxie.substack.com/subscribe?&quot;,&quot;primaryPublicationUrl&quot;:&quot;https://myronxie.substack.com&quot;,&quot;primaryPublicationName&quot;:&quot;Myron Xie&quot;,&quot;primaryPublicationId&quot;:2902781}],&quot;post_date&quot;:&quot;2025-09-03T20:55:46.000Z&quot;,&quot;cover_image&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/97b79ac0-6098-498b-b588-5633b3d288f2_1536x1024.png&quot;,&quot;cover_image_alt&quot;:null,&quot;canonical_url&quot;:&quot;https://newsletter.semianalysis.com/p/amazons-ai-resurgence-aws-anthropics-multi-gigawatt-trainium-expansion&quot;,&quot;section_name&quot;:null,&quot;video_upload_id&quot;:null,&quot;id&quot;:174558670,&quot;type&quot;:&quot;newsletter&quot;,&quot;reaction_count&quot;:13,&quot;comment_count&quot;:0,&quot;publication_id&quot;:6349492,&quot;publication_name&quot;:&quot;SemiAnalysis&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!II4V!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88ad87ad-b5c5-4687-b13e-672f72725795_501x501.png&quot;,&quot;belowTheFold&quot;:false}"></div><p>Today, we are publishing our next technical bible on the step-function improvement that is the Trainium3 chip, microarchitecture, system and rack architecture, scale up, profilers, software platform, and datacenters ramps. This is the most detailed piece we've written on an accelerator and its hardware/software, on desktop there is a table of contents that makes it possible to review specific sections.</p><h2>Amazon Basics GB200 aka GB200-at-Home</h2><p>With Trainium3, AWS remains laser-focused on optimizing performance per total cost of ownership (perf per TCO). Their hardware North Star is simple: deliver the fastest time to market at the lowest TCO. Rather than committing to any single architectural design, AWS maximizes operational flexibility. This extends from their work with multiple partners on the custom silicon side to the management of their own supply chain to multi-sourcing multiple component vendors.</p><p>On the systems and networking front, AWS is following an “Amazon Basics” approach that optimizes for perf per TCO. Design choices such as whether to use a 12.8T, 25.6T or a 51.2T bandwidth scale-out switch or to select liquid vs air cooling are merely a means to an end to provide the best TCO for the given client and the given datacenter.</p><p>For the scale-up network, while Trn2 only supports a 4x4x4 3D Torus mesh scaleup topology, Trainium3 adds a unique switched fabric that is somewhat similar to the GB200 NVL36x2 topology with a few key differences. This switched fabric was added because a switched scaleup topology has better absolute performance and perf per TCO for frontier Mixture-of-Experts (MoE) model architectures.</p><p>Even for the switches used in this scale-up architecture, AWS has decided to <strong>not decide</strong>: they will go with three different scale-up switch solutions over the lifecycle of Trainium3, starting with ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://newsletter.semianalysis.com/p/aws-trainium3-deep-dive-a-potential" class="read-button" target="_blank" rel="noopener">
          Read full article on SemiAnalysis &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>