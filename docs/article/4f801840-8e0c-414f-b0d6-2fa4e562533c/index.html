<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LLMs as Ground Truth - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>LLMs as Ground Truth</h1>
        <div class="article-meta">
          <span class="author">By Various</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/nobsai/index.html" class="publication">
            NO BS AI
          </a>
          <span class="separator">&middot;</span><time>Dec 12, 2024</time>
          <span class="separator">&middot;</span>
          <span class="read-time">4 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>In this post I will show:</p><ul><li><p>How to save around 90% of LLM cost of your customer service agent in production.</p></li><li><p>How to combine LLMs with old-school ML to acquire an accurate and cost-efficient hybrid system.</p></li></ul><p>In our previous article, we described the "overfitting" of LLMs via prompting: <a href="https://nobsai.substack.com/p/the-necessity-of-overfitting-llm">https://nobsai.substack.com/p/the-necessity-of-overfitting-llm</a> By crafting a very precise, elaborate prompt, she was able to carefully detect the true intent of a customer question and assign it to a correct class.</p><p>However, detailed prompts like this have their problems:</p><ol><li><p>They are <strong>brittle</strong> - as demonstrated in the article, classification results can often be unstable, influenced by parameters like temperature.</p></li><li><p>They are <strong>costly</strong> - their length and level of detail mean they contain a significant number of tokens, which increases expense.</p></li></ol><p>In this article, I demonstrate a solution to the second problem. In the course of our real-life work, we replaced the expensive LLM with a significantly more affordable model. By leveraging the "overfitted" prompts as a source of high-quality training data, we successfully <strong>trained a traditional machine learning classifier</strong> that performs effectively in production. This approach enables the system to operate at minimal cost.</p><p>The concept is illustrated in the image below:</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!Qs3u!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ca61346-c513-4d31-9da2-5539525c0af0_1865x543.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Qs3u!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ca61346-c513-4d31-9da2-5539525c0af0_1865x543.png 424w, https://substackcdn.com/image/fetch/$s_!Qs3u!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ca61346-c513-4d31-9da2-5539525c0af0_1865x543.png 848w, https://substackcdn.com/image/fetch/$s_!Qs3u!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ca61346-c513-4d31-9da2-5539525c0af0_1865x543.png 1272w, https://substackcdn.com/image/fetch/$s_!Qs3u!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ca61346-c513-4d31-9da2-5539525c0af0_1865x543.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Qs3u!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ca61346-c513-4d31-9da2-5539525c0af0_1865x543.png" width="1200" height="349.45054945054943" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7ca61346-c513-4d31-9da2-5539525c0af0_1865x543.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:424,&quot;width&quot;:1456,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:180475,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-large" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Qs3u!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ca61346-c513-4d31-9da2-5539525c0af0_1865x543.png 424w, https://substackcdn.com/image/fetch/$s_!Qs3u!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ca61346-c513-4d31-9da2-5539525c0af0_1865x543.png 848w, https://substackcdn.com/image/fetch/$s_!Qs3u!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ca61346-c513-4d31-9da2-5539525c0af0_1865x543.png 1272w, https://substackcdn.com/image/fetch/$s_!Qs3u!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ca61346-c513-4d31-9da2-5539525c0af0_1865x543.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"></div></div></div></a></figure></div><p>Before the era of LLMs, a significant amount of time (and money) was usually spent on annotating data. Today, a well-designed prompt can transform an LLM into an excellent annotator for our purposes. While it may incur some cost—since the prompts need to be sufficiently detailed and extensive to ensure high-quality "classification"—this investment is a one-time effort aimed at generating training data.</p><h4>The pipeline:</h4><ol><li><p><strong>Refine your prompt</strong> to ensure it is detailed enough to capture the necessary nuances. Incorporate the secrets of the business, so that it correctly identifies the intents in text (as done in <a href="https://nobsai.substack.com/p/the-necessity-of-overfitting-llm">https://nobsai.substack.com/p/the-necessity-of-overfitting-llm</a>)</p></li><li><p>Once the prompt is finalized and delivers satisfactory classification quality, use it to process your data and<strong> generate the "ground truth."</strong> In my case, I required results for approximately 2,000 examples per class.</p></li><li><p><strong>Embed the data</strong> - I used ada-002 embedder from OpenAI, without any finetuning, and it proved good enough for this case. Much better results will likely come from finetuning the embedder - even if it's a smallish model from Huggingface.</p></li><li><p>Feed the embeddings, together with their class labels assigned by an LLM, to a <strong>classifier like XGBoost</strong>.</p></li></ol><h4><strong>The result?</strong></h4><p>I have trained the classifiers for 3 classes. Each class reflects a </p>...</source>
      </div>

      <div class="read-full-article">
        <a href="https://nobsai.substack.com/p/llms-as-ground-truth" class="read-button" target="_blank" rel="noopener">
          Read full article on NO BS AI &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>