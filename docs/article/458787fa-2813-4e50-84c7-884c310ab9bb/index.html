<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Deep Learning Weekly: Issue 418 - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Deep Learning Weekly: Issue 418</h1>
        <div class="article-meta">
          <span class="author">By Various</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/deeplearningweekly/index.html" class="publication">
            Deep Learning Weekly
          </a>
          <span class="separator">&middot;</span><time>Aug 20, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">6 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p>This week in deep learning, we bring you <a href="https://developers.googleblog.com/en/introducing-gemma-3-270m/">Gemma 3 270M</a>, <a href="https://userjot.com/blog/best-practices-building-agentic-ai-systems">Best Practices for Building Agentic AI Systems: What Actually Works in Production</a>, and <a href="https://arxiv.org/abs/2507.19457">a paper on GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning</a>.</p><p>You may also enjoy <a href="https://research.nvidia.com/labs/adlr/NVIDIA-Nemotron-Nano-2/">NVIDIA Nemotron Nano 2</a>, <a href="https://research.google/blog/beyond-billion-parameter-burdens-unlocking-data-synthesis-with-a-conditional-generator/">Beyond billion-parameter burdens: Unlocking data synthesis with a conditional generator</a>, <a href="https://arxiv.org/abs/2505.02709">a paper on Technical Report: Evaluating Goal Drift in Language Model Agents</a>, and more!</p><p>As always, happy reading and hacking. If you have something you think should be in next week's issue, find us on Twitter: <a href="https://twitter.com/dl_weekly">@dl_weekly</a>.</p><p>Until next week!</p><div><hr></div><h2><strong>Industry</strong></h2><p><strong><a href="https://developers.googleblog.com/en/introducing-gemma-3-270m/">Introducing Gemma 3 270M: The compact model for hyper-efficient AI</a></strong></p><p>Google introduced Gemma 3 270M, a compact, 270-million parameter model designed for task-specific fine-tuning.</p><p><strong><a href="https://research.nvidia.com/labs/adlr/NVIDIA-Nemotron-Nano-2/">NVIDIA Nemotron Nano 2</a></strong></p><p>The NVIDIA team released the NVIDIA Nemotron Nano 2 family of accurate and efficient hybrid Mamba-Transformer reasoning models.</p><p><strong><a href="https://ai.meta.com/blog/dinov3-self-supervised-vision-model/">DINOv3: Self-supervised learning for vision at unprecedented scale</a></strong></p><p>Meta released DINOv3, a generalist, state-of-the-art computer vision model trained with self-supervised learning that produces superior high-resolution visual features.</p><p><strong><a href="https://www.liquid.ai/blog/lfm2-vl-efficient-vision-language-models">LFM2-VL: Efficient Vision-Language Models</a></strong></p><p>Liquid AI released LFM2-VL, their first series of vision-language foundation models.</p><p><strong><a href="https://news.mit.edu/2025/researchers-glimpse-inner-workings-protein-language-models-0818">Researchers glimpse the inner workings of protein language models</a></strong></p><p>In a new study, MIT researchers use sparse autoencoders to determine what features a protein language model takes into account when making predictions.</p><h2><strong>MLOps &amp; LLMOps</strong></h2><p><strong><a href="https://userjot.com/blog/best-practices-building-agentic-ai-systems">Best Practices for Building Agentic AI Systems: What Actually Works in Production</a></strong></p><p>A practical article about best practices for building and implementing agentic AI systems in production, covering architectural patterns, communication, error handling, and performance optimization.</p><p><strong><a href="https://milvus.io/blog/hands-on-with-vdbbench-benchmarking-vector-databases-for-pocs-that-match-production.md">Hands-On with VDBBench: Benchmarking Vector Databases for POCs That Match Production</a></strong></p><p>A practical tutorial on evaluating vector databases for production-matching Proof of Concepts using the VDBBench tool with custom, real-world datasets.</p><h2><strong>Learning</strong></h2><p><strong><a href="https://research.google/blog/beyond-billion-parameter-burdens-unlocking-data-synthesis-with-a-conditional-generator/">Beyond billion-parameter burdens: Unlocking data synthesis with a conditional generator</a></strong></p><p>A blog post from Google detailing CTCL, a novel framework for generating privacy-preserving synthetic data using a lightweight 140M-parameter model, bypassing the need for billion-scale LLM fine-tuning and domain-specific prompt engineering.</p><p><strong><a href="https://huggingface.co/blog/kernel-builder">From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels</a></strong></p><p>A comprehensive guide on building and scaling production-ready custom CUDA kernels for PyTorch.</p><p><strong><a href="https://pytorch.org/blog/accelerating-moes-with-a-triton-persistent-cache-aware-grouped-gemm-kernel/">Accelerating MoEâ€™s with a Triton Persistent Cache-Aware Grouped GEMM Kernel</a></strong></p><p>A post on optimizing Triton BF16 Grouped GEMM kernel for running training and inference on Mixture-of-Experts (MoE) models, such as DeepSeekv3.</p><h2><strong>Libraries &amp; Code</strong></h2><p><strong><a href="https://github.com/huggingface/aisheets">huggingface/aisheets</a></strong></p><p>Build, enrich, and transform datasets using ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://www.deeplearningweekly.com/p/deep-learning-weekly-issue-418" class="read-button" target="_blank" rel="noopener">
          Read full article on Deep Learning Weekly &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>