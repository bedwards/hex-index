<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>How OpenAI, Gemini, and Claude Use Agents to Power Deep Research - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>How OpenAI, Gemini, and Claude Use Agents to Power Deep Research</h1>
        <div class="article-meta">
          <span class="author">By Alex Xu</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/bytebytego/index.html" class="publication">
            ByteByteGo Newsletter
          </a>
          <span class="separator">&middot;</span><time>Dec 12, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">14 min read</span>
        </div>
      </header>

      <div class="article-excerpt">
        <p></p>
        <div class="excerpt-fade"></div>
      </div>

      <div class="read-full-article">
        <a href="https://blog.bytebytego.com/p/how-openai-gemini-and-claude-use" class="read-button" target="_blank" rel="noopener">
          Read full article on ByteByteGo Newsletter &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/reinforcement-learning-from-human-feedback/index.html">
          <strong>Reinforcement learning from human feedback</strong>
          <span class="read-time">13 min read</span>
        </a>
        <p class="topic-summary">The article mentions OpenAI&#039;s deep research agent uses reinforcement learning to train models for planning multi-step research tasks. RLHF is the specific technique that enables these models to improve decision-making through reward signals, which is fundamental to understanding how these agents learn to coordinate tool calls effectively.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/multi-agent-system/index.html">
          <strong>Multi-agent system</strong>
          <span class="read-time">12 min read</span>
        </a>
        <p class="topic-summary">The entire article centers on multi-agent architectures where orchestrator agents coordinate sub-agents for research tasks. Understanding the formal computer science concept of multi-agent systems—including coordination protocols, distributed problem-solving, and agent communication—provides essential theoretical grounding for the practical implementations described.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/information-retrieval/index.html">
          <strong>Information retrieval</strong>
          <span class="read-time">14 min read</span>
        </a>
        <p class="topic-summary">Perplexity&#039;s iterative information retrieval loop and the web search agents across all platforms rely on IR principles. This foundational field covers how systems find relevant documents from large collections, relevance ranking, and query refinement—the technical substrate beneath all the deep research capabilities discussed.</p>
      </li>
        </ul>
      </section>
    
    </article>
  
  </main>
</body>
</html>