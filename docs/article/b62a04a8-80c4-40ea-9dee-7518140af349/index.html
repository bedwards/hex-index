<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Deep Learning Weekly: Issue 433 - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>Deep Learning Weekly: Issue 433</h1>
        <div class="article-meta">
          <span class="author">By Various</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/deeplearningweekly/index.html" class="publication">
            Deep Learning Weekly
          </a>
          <span class="separator">&middot;</span><time>Dec 4, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">5 min read</span>
        </div>
      </header>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/mixture-of-experts/index.html">
          <strong>Mixture of experts</strong>
          <span class="read-time">12 min read</span>
        </a>
        <p class="topic-summary">The article mentions Mistral Large 3 as a &#039;sparse mixture-of-experts model&#039; - understanding this neural network architecture technique would help readers grasp why this is significant and how it differs from dense transformer models</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/theory-of-mind/index.html">
          <strong>Theory of mind</strong>
          <span class="read-time">15 min read</span>
        </a>
        <p class="topic-summary">The SoMi-ToM paper directly evaluates Theory of Mind capabilities in AI models - this cognitive science concept about understanding others&#039; mental states is foundational to understanding why this benchmark matters for AI development</p>
      </li>
        </ul>
      </section>
    

      <div class="article-excerpt">
        <p>This week in deep learning, we bring you <a href="https://mistral.ai/news/mistral-3">Introducing Mistral 3</a>, <a href="https://neurips-mcp-presentation.vercel.app/">MCP Explorer</a>, and <a href="https://openreview.net/pdf?id=Rv664iOMNv">a paper on Agentic Bridge Framework: Closing the Gap Between Agentic Capability and Performance Benchmarks</a>.</p><p>You may also enjoy <a href="https://bfl.ai/blog/our-300m-series-b">Laying the Foundations for Visual Intelligence</a>, <a href="https://posthog.com/blog/8-learnings-from-1-year-of-agents-posthog-ai">8 learnings from 1 year of agents</a>, <a href="https://arxiv.org/abs/2506.23046">a paper on SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions</a>, and more!</p><p>As always, happy reading and hacking. If you have something you think should be in next week’s issue, find us on Twitter: <a href="https://twitter.com/dl_weekly">@dl_weekly</a>.</p><p>Until next week!</p><div><hr></div><h2><strong>Industry</strong></h2><p><strong><a href="https://mistral.ai/news/mistral-3">Introducing Mistral 3</a></strong></p><p>The Mistral team announced Mistral 3, which includes three state-of-the-art small models and Mistral Large 3 — a sparse mixture-of-experts model.</p><p><strong><a href="https://bfl.ai/blog/our-300m-series-b">Laying the Foundations for Visual Intelligence—$300M Series B | Black Forest Labs</a></strong></p><p>Black Forest Labs raises $300M Series B at $3.25B valuation to advance visual intelligence models beyond its popular FLUX image generation platform.</p><p><strong><a href="https://venturebeat.com/ai/new-training-method-boosts-ai-multimodal-reasoning-with-smaller-smarter">New training method boosts AI multimodal reasoning with smaller, smarter datasets</a></strong></p><p>Researchers at MiroMind AI and several Chinese universities have released OpenMMReasoner, a training framework that improves the capabilities of models in multimodal reasoning.</p><p><strong><a href="https://www.letta.com/blog/skill-learning">Skill Learning: Bringing Continual Learning to CLI Agents</a></strong></p><p>The Letta team released Skill Learning, a way for Letta Code to dynamically learn skills over time.</p><h2><strong>MLOps &amp; LLMOps</strong>.</h2><p><strong><a href="https://neurips-mcp-presentation.vercel.app/">MCP Explorer</a></strong></p><p>An educational project for learning Anthropic’s Model Context Protocol through a narrative-driven and interactive learning experience.</p><p><strong><a href="https://posthog.com/blog/8-learnings-from-1-year-of-agents-posthog-ai">8 learnings from 1 year of agents</a></strong></p><p>A detailed retrospective blog post sharing 8 key learnings from a year of developing PostHog AI, focusing on architectural choices like using a single LLM loop and the power of continuous model improvements.</p><p><strong><a href="https://opensearch.org/blog/opensearch-as-an-agentic-memory-solution-building-context-aware-agents-using-persistent-memory/">OpenSearch as an agentic memory solution: Building context-aware agents using persistent memory</a></strong></p><p>A blog post that explores the memory challenges facing AI agents, introduces agentic memory’s core concepts, and demonstrates how to integrate it with your agent frameworks.</p><p><strong><a href="https://developer.nvidia.com/blog/build-and-run-secure-data-driven-ai-agents/">Build and Run Secure, Data-Driven AI Agents</a></strong></p><p>A technical guide detailing the deployment of NVIDIA’s AI-Q Research Assistant and Enterprise RAG Blueprints, which use Nemotron NIMs and an agentic Plan-Refine-Reflect workflow on Amazon EKS.</p><h2><strong>Learning</strong></h2><p><strong><a href="https://alignment.anthropic.com/2025/honesty-elicitation/">Evaluating honesty and lie detection techniques on a diverse suite of dishonest models</a></strong></p><p>An alignment report evaluating techniques like fine-tuning and prompting to improve AI honesty and detect lies across five specialized testbed models.</p><p><strong><a href="https://epoch.ai/blog/a-rosetta-stone-for-ai-benchmarks">A Rosetta Stone for AI benchmarks</a></strong></p><p>A statistical paper introducing a “Rosetta Stone” framework that stitches together around 40 ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://www.deeplearningweekly.com/p/deep-learning-weekly-issue-433" class="read-button" target="_blank" rel="noopener">
          Read full article on Deep Learning Weekly &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>