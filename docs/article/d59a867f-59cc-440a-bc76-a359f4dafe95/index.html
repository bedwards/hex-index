<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>How d-Matrix&#039;s In-Memory Compute Tackles AI Inference Economics - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>How d-Matrix&#039;s In-Memory Compute Tackles AI Inference Economics</h1>
        <div class="article-meta">
          <span class="author">By Vikram Sekar</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/viksnewsletter/index.html" class="publication">
            Vik&#039;s Newsletter
          </a>
          <span class="separator">&middot;</span><time>Dec 9, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">13 min read</span>
        </div>
      </header>

      <div class="article-excerpt">
        <p></p>
        <div class="excerpt-fade"></div>
      </div>

      <div class="read-full-article">
        <a href="https://www.viksnewsletter.com/p/d-matrix-in-memory-compute" class="read-button" target="_blank" rel="noopener">
          Read full article on Vik&#039;s Newsletter &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>

      
      <section class="deep-dives">
        <h2>Deep Dives</h2>
        <p class="deep-dives-intro">Explore related topics with these Wikipedia articles, rewritten for enjoyable reading:</p>
        <ul class="deep-dive-list">
          
      <li class="deep-dive-item">
        <a href="../../wikipedia/in-memory-processing/index.html">
          <strong>In-memory processing</strong>
          <span class="read-time">13 min read</span>
        </a>
        <p class="topic-summary">The article&#039;s central focus is on d-Matrix&#039;s in-memory compute approach for AI inference. Understanding the broader technical foundations of in-memory computing - how it differs from traditional von Neumann architectures and why moving computation closer to data reduces latency - provides essential context for evaluating d-Matrix&#039;s claims.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/memristor/index.html">
          <strong>Memristor</strong>
          <span class="read-time">14 min read</span>
        </a>
        <p class="topic-summary">The article mentions memristors as one approach to implementing analog in-memory compute weights. Memristors are a fascinating fourth fundamental circuit element theorized by Leon Chua in 1971 and first physically realized in 2008, with significant implications for neuromorphic computing that readers may not know deeply.</p>
      </li>

      <li class="deep-dive-item">
        <a href="../../wikipedia/ohms-law/index.html">
          <strong>Ohm&#039;s law</strong>
          <span class="read-time">13 min read</span>
        </a>
        <p class="topic-summary">The article explains how analog in-memory compute leverages Ohm&#039;s law (I=GV) for multiplication operations. While readers may remember the basic formula, the deeper history of Georg Ohm&#039;s discovery, the physics behind electrical resistance, and its foundational role in electronics provides enriching context for understanding why this natural property enables efficient computation.</p>
      </li>
        </ul>
      </section>
    
    </article>
  
  </main>
</body>
</html>