<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The Anatomy of the Least Squares Method, Part Two - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="article-page">
      <header class="article-header">
        <h1>The Anatomy of the Least Squares Method, Part Two</h1>
        <div class="article-meta">
          <span class="author">By Tivadar Danka</span>
          <span class="separator">&middot;</span>
          <a href="../../publication/thepalindrome/index.html" class="publication">
            The Palindrome
          </a>
          <span class="separator">&middot;</span><time>Oct 20, 2025</time>
          <span class="separator">&middot;</span>
          <span class="read-time">19 min read</span>
        </div>
      </header>

      

      <div class="article-excerpt">
        <p><em>Hey! It’s Tivadar from The Palindrome.</em></p><p><em><span class="mention-wrap" data-attrs="{&quot;name&quot;:&quot;Mike X Cohen, PhD&quot;,&quot;id&quot;:382604135,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3c804d93-69c2-49a9-a797-2216b4bae5ba_1000x1000.jpeg&quot;,&quot;uuid&quot;:&quot;8a5e27b6-87dc-4d78-9860-766d8fa5dc48&quot;}" data-component-name="MentionToDOM"></span> is here to continue our deep dive into the least squares method, the bread and butter of data science and machine learning.</em></p><p><em>Without further ado, I’ll pass the mic to him.</em></p><p><em>Enjoy!</em></p><p><em>Cheers,<br>Tivadar</em></p><div><hr></div><p>By the end of this post series, you will be confident about understanding, applying, and interpreting regression models (general linear models) that are solved using the famous least-squares algorithm. Here’s a breakdown of the post series:</p><p><strong><a href="https://thepalindrome.org/p/the-anatomy-of-the-least-squares">Post 1 (the previous post): Theory and math</a></strong><a href="https://thepalindrome.org/p/the-anatomy-of-the-least-squares">.</a> If you haven’t read this post yet, please do so before reading this one!</p><p><strong>Post 2 (this post): Explorations in simulations</strong>. You’ll learn how to simulate data to supercharge your intuition for least-squares, how to visualize the results, and how to run experiments. You’ll also learn about residuals and overfitting.</p><p><strong>Post 3: real-data examples.</strong> Simulated data are great because you have full control over the data characteristics and noise, but there’s no substitute for real data. And that’s what you’ll experience in this post. I’ll also teach you how to use the Python statsmodels library.</p><p><strong>Post 4: modeling GPT activations</strong>. This post will be fun and fascinating. We’ll dissect OpenAI’s LLM GPT2, the precursor to its state-of-the-art ChatGPT. You’ll learn more about least-squares and also about LLM mechanisms.</p><h3>Following along with code</h3><p>I’m a huge fan of learning math through coding. <em>You can learn a lot of math with a bit of code</em><strong>.</strong></p><p>That’s why I have Python notebook files that accompany my posts. The essential code bits are pasted directly into this post, but the complete code files, including all the code for visualization and additional explorations, <a href="https://github.com/mikexcohen/Substack/blob/main/DSUnpacked/leastSquares_2.ipynb">are here on my GitHub</a>.</p><p>If you’re more interested in the theory/concepts, then it’s completely fine to ignore the code and just read the post. But if you want a deeper level of understanding and intuition — and the tools to continue exploring and applying the analyses to your own projects — then I strongly encourage following along with the code while reading this post.</p><p>Here’s a video where I explain how to get my code from GitHub and follow along using Google Colab. It’s free (you need a Google account, but who doesn’t have one??) and runs in your browser, so you don’t need to install anything.</p><div class="native-video-embed" data-component-name="VideoPlaceholder" data-attrs="{&quot;mediaUploadId&quot;:&quot;7dd578c9-b45f-4f52-b388-ea8c78e4e6fd&quot;,&quot;duration&quot;:null}"></div><h2>Why you should use simulated data when learning machine-learning</h2><p>Here’s why I love teaching data ...</p>
      </div>

      <div class="read-full-article">
        <a href="https://thepalindrome.org/p/the-anatomy-of-the-least-squares-ab5" class="read-button" target="_blank" rel="noopener">
          Read full article on The Palindrome &rarr;
        </a>
        <p class="copyright-note">
          This excerpt is provided for preview purposes.
          Full article content is available on the original publication.
        </p>
      </div>
    </article>
  
  </main>
</body>
</html>