<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Low-rank approximation - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="wikipedia-page">
      <header class="wikipedia-header">
        <div class="type-badge">Wikipedia Deep Dive</div>
        <h1>Low-rank approximation</h1>
        <div class="article-meta">
          <span class="read-time">2 min read</span>
        </div>
      </header>

      <div class="wikipedia-content">
        I've written a rewritten version of the Low-Rank Approximation Wikipedia article. The rewrite:

1. **Opens with a compelling hook** - Using image compression as an intuitive entry point rather than the dry mathematical definition
2. **Builds understanding from first principles** - Explains what matrix rank means before diving into the approximation problem
3. **Explains the SVD elegantly** - Presents singular value decomposition as taking apart a machine to find its fundamental components
4. **Varies rhythm** - Mixes short punchy paragraphs with longer explanatory sections
5. **Connects to modern AI** - Explicitly links to LoRA and its variants for fine-tuning large language models, which ties directly to the Substack article context
6. **Covers diverse applications** - Netflix recommendations, image compression, natural language processing
7. **Includes historical context** - The tangled history of Schmidt, Eckart-Young, and Mirsky
8. **Explains why uniqueness can fail** - A subtle but important mathematical point
9. **Ends with philosophical reflection** - The idea that complexity often conceals underlying simplicity

The article is written as an engaging essay suitable for text-to-speech reading, avoiding jargon while still conveying the mathematical substance. It should take approximately 15-20 minutes to read aloud.

However, I'm blocked from writing the file due to directory creation permissions. Could you create the directory `docs/wikipedia/low-rank-approximation/` and then I can write the file?
      </div>

      <footer class="wikipedia-footer">
        <p class="source-link">
          <a href="https://en.wikipedia.org/wiki/Low-rank_approximation" target="_blank" rel="noopener">
            View original Wikipedia article &rarr;
          </a>
        </p>
        <p class="rewrite-note">
          This article has been rewritten from Wikipedia source material for enjoyable reading.
          Content may have been condensed, restructured, or simplified.
        </p>
      </footer>

      
      <section class="related-articles">
        <h2>Related Articles</h2>
        <p class="related-intro">This deep dive was written in connection with these articles:</p>
        <ul class="related-list">
          
      <li class="related-article-item">
        <a href="../../article/fc1b9ee3-a659-4d90-98bf-43ec8b7a4b8f/index.html">
          <strong>Advanced LoRA Fine-Tuning: How to Pick LoRA, QLoRA, DoRA, PiSSA, OLoRA, EVA, and LoftQ for LLMs</strong>
        </a>
        <span class="article-meta">
          by Various in The Kaitchup
        </span>
      </li>
        </ul>
      </section>
    
    </article>
  
  </main>
</body>
</html>