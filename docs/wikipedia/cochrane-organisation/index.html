<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Cochrane (organisation) - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="wikipedia-page">
      <header class="wikipedia-header">
        <div class="type-badge">Wikipedia Deep Dive</div>
        <h1>Cochrane (organisation)</h1>
        <div class="article-meta">
          <span class="read-time">15 min read</span>
        </div>
      </header>

      <div class="wikipedia-content">
        <p class="source-note">Based on <a href="https://en.wikipedia.org/wiki/Cochrane_(organisation)">Wikipedia: Cochrane (organisation)</a></p>

<h2>The Organization That Decides What Medicine Actually Works</h2>

<p>Imagine a world where doctors prescribed treatments based on hunches, tradition, or whatever the last drug rep told them. That world existed not so long ago. In fact, it still exists in pockets of medicine today. But there's an organization that has spent three decades trying to drag healthcare kicking and screaming into the realm of actual evidence. It's called Cochrane, and its story is far stranger and more contentious than you might expect from a medical charity.</p>

<p>Here's what Cochrane does at its core: it reads medical studies so you don't have to. More precisely, it gathers together all the randomized controlled trials on a given medical question—say, whether a particular drug reduces heart attacks—and synthesizes them into a single, digestible review. This might sound straightforward. It is anything but.</p>

<h2>The Man Behind the Name</h2>

<p>Cochrane is named after Archie Cochrane, a British physician who spent much of his career asking an uncomfortable question: how do we know our treatments actually work?</p>

<p>This seems like an obvious thing to ask. But for most of medical history, doctors didn't ask it. They relied on theory, on tradition, on what their mentors had taught them. If bloodletting was what physicians had always done for fever, then bloodletting was what they continued to do. The notion that you might actually test whether bloodletting helped—or, as it turns out, killed patients faster—was strangely radical.</p>

<p>Archie Cochrane championed the randomized controlled trial, or RCT, as the gold standard for medical evidence. In an RCT, you take a group of patients, randomly assign half of them to receive the treatment and half to receive a placebo, and then measure what happens. The randomization is crucial. It means that any difference you observe between the two groups is likely due to the treatment itself, not to some other factor like age, severity of disease, or the patient's belief in the medicine.</p>

<p>But Cochrane noticed something troubling. Even when good RCTs existed, doctors often didn't know about them. Medical knowledge was scattered across thousands of journals, in hundreds of languages, gathering dust in libraries nobody visited. A treatment might be proven useless or harmful, but decades could pass before this information reached the physicians still prescribing it.</p>

<p>He called for systematic reviews—comprehensive surveys of all the evidence on a medical question, kept constantly up to date. He didn't live to see it happen. Archie Cochrane died in 1988. Five years later, in 1993, the organization bearing his name was born.</p>

<h2>How Systematic Reviews Work</h2>

<p>A systematic review is not just reading a bunch of studies and summarizing them. That would be a literature review, the kind students write. A systematic review follows a rigid protocol designed to minimize bias at every step.</p>

<p>First, you specify your question precisely. Not "does exercise help depression?" but something like "in adults diagnosed with major depressive disorder, does aerobic exercise of at least 150 minutes per week, compared to no treatment, reduce depressive symptoms as measured by the Hamilton Depression Rating Scale over a twelve-week period?" The specificity matters because vague questions get vague answers.</p>

<p>Then you search for every relevant study. Not just the ones in the obvious journals. Not just the ones in English. You hunt through obscure databases, unpublished theses, conference abstracts, and the gray literature that lives in filing cabinets at pharmaceutical companies. This is painstaking, unglamorous work, and it's essential.</p>

<p>Why the obsession with finding unpublished studies? Because of publication bias. Studies that show a treatment works are more likely to get published than studies showing it doesn't. A drug company that runs ten trials and gets positive results in three of them will trumpet those three and quietly shelve the other seven. If you only look at published literature, you might conclude the drug is effective when the totality of evidence says otherwise.</p>

<p>Once you've gathered your studies, you assess their quality. Was the randomization truly random, or did doctors unconsciously put sicker patients in one group? Did researchers know which patients got the real treatment? Did patients drop out of the study at different rates? Each of these flaws can distort the results, and Cochrane reviewers systematically evaluate each one.</p>

<p>Finally, you combine the results statistically, using a technique called meta-analysis. The idea is simple: if you have ten small studies, each too underpowered to detect a treatment effect, combining them might reveal a pattern that none could detect alone. It's like listening for a faint signal by averaging across many slightly noisy recordings.</p>

<h2>The Forest Plot</h2>

<p>Cochrane's logo tells you everything about what the organization values. It contains a forest plot—a specific type of graph used in meta-analysis.</p>

<p>The plot in the logo comes from a famous review about corticosteroids given to pregnant women at risk of premature birth. The steroids help the baby's lungs mature faster, reducing the risk of death. This was proven by 1972. But the systematic review wasn't published until 1989, and the treatment wasn't widely adopted until the 1990s. During those two decades of delay, thousands of premature babies died unnecessarily.</p>

<p>This is why Cochrane exists. Not to produce academic papers, but to get evidence into practice faster. The logo is a reminder of what happens when evidence synthesis fails.</p>

<h2>Better Reviews, But Not Perfect</h2>

<p>Studies consistently show that Cochrane reviews are of higher quality than reviews published elsewhere. They're more methodologically rigorous, more transparent about their methods, more likely to register their protocols in advance, and less likely to reach favorable conclusions about treatments. That last point is significant: when you do the hard work of including unpublished studies and assessing quality systematically, the treatments often look less impressive than industry-funded reviews suggest.</p>

<p>But Cochrane has faced legitimate criticism. Some reviews don't include enough unpublished studies, despite the organization's stated commitment to finding them. Some reviews are rarely updated, meaning the evidence they summarize is years out of date. And a troublingly high percentage of Cochrane reviews reach inconclusive results—not because the evidence is genuinely equivocal, but because the review was too narrowly scoped or the included studies too flawed.</p>

<p>There's also the problem of ghostwriting and honorary authorship. Cochrane reviews have sometimes listed as authors people who didn't do the work, or failed to list people who did. This isn't unique to Cochrane—it's endemic in medical publishing—but it's embarrassing for an organization that positions itself as a beacon of methodological integrity.</p>

<h2>The Gøtzsche Affair</h2>

<p>In September 2018, Cochrane's governing board expelled Peter Gøtzsche, a Danish physician who had been on the board and directed Cochrane's Nordic center for years. The expulsion tore the organization apart.</p>

<p>Gøtzsche was controversial long before 2018. He had written books arguing that psychiatric medications are overprescribed and that the pharmaceutical industry has corrupted medical research. He was abrasive, uncompromising, and frequently at odds with his colleagues. But he was also a founding member of Cochrane and one of its most visible public advocates.</p>

<p>The proximate cause of his expulsion was a paper he co-authored criticizing Cochrane's review of HPV vaccines—the vaccines given to prevent cervical cancer. Gøtzsche argued that the review was biased, that it had excluded relevant studies, and that it downplayed evidence of harms. The Cochrane board said they had received "numerous complaints" about his behavior and that an independent investigation had found problems.</p>

<p>Four elected board members resigned in protest. The board then removed two appointed members to maintain the required ratio between elected and appointed members. Gøtzsche published an open letter accusing Cochrane of developing "a growing top-down authoritarian culture and an increasingly commercial business model."</p>

<p>The whole episode raised uncomfortable questions. Was Gøtzsche expelled for legitimate behavioral issues, or for being too critical of vaccines in an era when vaccine hesitancy was becoming a public health crisis? Was Cochrane protecting its methodological integrity, or its relationships with the pharmaceutical industry that funds medical research? Different people came to different conclusions, and the organization's reputation suffered either way.</p>

<h2>Following the Money</h2>

<p>Cochrane has always been sensitive about funding. The organization refuses money from pharmaceutical companies, medical device manufacturers, and other corporate interests that might bias its reviews. This is admirable and unusual. Most medical research is funded, directly or indirectly, by the companies that profit from favorable results.</p>

<p>Instead, Cochrane relies on governments, universities, hospitals, and foundations. Its major funders include the United Kingdom's National Institute for Health and Care Research (abbreviated NIHR), Denmark's health authority, Germany's Federal Ministry of Health, and the United States National Institutes of Health (abbreviated NIH). Universities like McMaster, Amsterdam, and Copenhagen contribute as well.</p>

<p>This funding model creates its own pressures. Government funders want Cochrane to produce reviews on topics governments care about, which may not be the topics where evidence is most needed. And the sheer scale of the evidence synthesis task means Cochrane is perpetually underfunded relative to its ambitions.</p>

<h2>An Army of Volunteers</h2>

<p>Cochrane's secret weapon is its volunteers. Over 37,000 people from around the world contribute their time to the organization, organized into 53 review groups based at research institutions globally. These aren't just physicians. They include statisticians, librarians, patient advocates, and methodologists—specialists in the arcane art of research synthesis.</p>

<p>In 2013, Cochrane began explicitly training people in developing countries to conduct systematic reviews. This matters because the burden of disease is not evenly distributed. Conditions that devastate low-income countries often receive less research attention than conditions affecting wealthy populations. Having reviewers from these countries means having advocates for the evidence that matters there.</p>

<p>The volunteer model has its limitations. Volunteers burn out. Reviews take longer than they should. Quality varies between review groups. But the model also ensures a kind of independence. An organization run by volunteers with day jobs elsewhere is harder to capture than one dependent on a small number of large funders.</p>

<h2>The Wikipedia Connection</h2>

<p>Since 2014, Cochrane has had a formal partnership with Wikipedia. This might seem like an odd coupling—a rigorous evidence synthesis organization teaming up with an encyclopedia anyone can edit. But it makes a strange kind of sense.</p>

<p>Wikipedia medical articles are read by hundreds of millions of people. When someone googles a health question, Wikipedia is often in the top results. If those articles cite the best available evidence, they can improve public understanding of medicine on a massive scale. If they cite unreliable sources, they can spread misinformation just as broadly.</p>

<p>Under the partnership, Cochrane provides free accounts to Wikipedia medical editors—accounts that would otherwise cost tens of thousands of dollars annually—so they can access Cochrane reviews. Cochrane also funds a Wikipedian in Residence, someone whose job is to improve the integration between Cochrane evidence and Wikipedia content.</p>

<p>It's a clever bit of public health infrastructure hiding in plain sight. The research university produces the evidence. The volunteer encyclopedia distributes it to the public. No pharmaceutical company gets to decide what you read about their drugs.</p>

<h2>The World Health Organization Relationship</h2>

<p>Cochrane maintains an official relationship with the World Health Organization (abbreviated WHO). This means Cochrane can send non-voting representatives to WHO meetings, including sessions of the World Health Assembly—the decision-making body where global health policy is hammered out.</p>

<p>This relationship gives Cochrane a seat at the table when international health standards are set. Guidelines on everything from vaccination schedules to essential medicines lists draw on systematic review evidence. Having Cochrane in the room means having an advocate for rigorous evidence synthesis in deliberations that might otherwise be dominated by political or commercial considerations.</p>

<h2>What This Has to Do with AI</h2>

<p>You might be wondering what a medical evidence organization has to do with the jagged frontier of artificial intelligence. The connection is more profound than it first appears.</p>

<p>AI systems are, in a sense, doing evidence synthesis at scale. When a language model answers a medical question, it's drawing on patterns learned from millions of documents. But unlike a Cochrane review, there's no systematic search protocol. No quality assessment. No transparent methodology. The model doesn't know which of its training data came from rigorous trials and which came from drug company marketing materials.</p>

<p>This creates exactly the kind of jagged frontier the Substack article describes. AI can sound authoritative about medicine while citing sources of wildly varying quality. It can give confident answers to questions where the evidence is genuinely uncertain. It can miss nuances that a careful systematic review would catch.</p>

<p>Cochrane represents one approach to this problem: slow, methodical, human-intensive evidence synthesis with obsessive attention to methodology. It's expensive, it takes years, and it can't scale to every question anyone might ask. But it produces reliable answers.</p>

<p>AI represents the opposite approach: fast, scalable, capable of addressing any question immediately. But with no guarantee that the answer reflects the best available evidence.</p>

<p>The interesting question is whether these approaches can be combined. Can AI systems learn to weight evidence the way Cochrane reviewers do? Can they identify publication bias, assess study quality, and synthesize findings systematically? Some researchers are trying. The results so far are mixed, which is to say—jagged.</p>

<h2>The Case for Slow Evidence</h2>

<p>In an age of instant answers, there's something countercultural about an organization that takes years to answer a single medical question. Cochrane reviews are slow by design. The methodology requires it. Rushing produces exactly the kind of sloppy synthesis that Cochrane was created to replace.</p>

<p>But slowness has costs. Patients are dying while reviews are in progress. Doctors need guidance now, not in three years when the review is finally published. The gap between the speed of medical practice and the speed of evidence synthesis is one of healthcare's fundamental tensions.</p>

<p>Cochrane has tried to address this. They've developed methods for rapid reviews, for living reviews that update continuously as new evidence emerges. But these are compromises, and they come with tradeoffs. Faster reviews are less comprehensive. Continuous updating requires continuous funding.</p>

<p>Perhaps the most honest thing to say is that evidence synthesis is genuinely hard. There's no shortcut that preserves the methodological rigor Archie Cochrane called for. The baby's lungs either mature or they don't. The drug either prevents heart attacks or it doesn't. Reality doesn't care whether we find the answer quickly.</p>

<h2>A Very Particular Kind of Disagreement</h2>

<p>One of the stranger things about Cochrane reviews is how often they conclude that we simply don't know whether a treatment works. This frustrates doctors who need to make decisions today. It frustrates patients who want clear guidance. But it's often the honest answer.</p>

<p>Medical research is expensive. Many conditions—especially rare ones, or ones affecting populations with little political power—are understudied. The trials that exist are often too small, too short, or too poorly designed to answer the questions we care about. A systematic review can't conjure evidence out of thin air. It can only synthesize what exists.</p>

<p>This is where Cochrane provides an underappreciated service. By mapping the gaps in medical knowledge, it helps funders and researchers decide where to invest. A Cochrane review concluding "insufficient evidence" is not a failure. It's a signpost pointing toward the research that still needs to be done.</p>

<h2>Women at the Table</h2>

<p>Studies have found that Cochrane has better representation of women among its editors than comparable organizations. This matters more than you might think.</p>

<p>For decades, medical research systematically excluded women from clinical trials. The assumption was that male bodies were the default, and findings would generalize. This turned out to be wrong in countless ways. Women metabolize drugs differently. Their symptoms present differently. Diseases that disproportionately affect women were chronically understudied.</p>

<p>Having women in leadership positions doesn't automatically fix these problems. But it helps. Perspectives that were historically marginalized are more likely to be heard. Questions that were historically ignored are more likely to be asked. An organization's composition shapes what it sees as important.</p>

<h2>The Unfinished Project</h2>

<p>Thirty years after its founding, Cochrane remains a work in progress. Its reviews cover only a fraction of medical questions. Many reviews are out of date. The organization has been rocked by internal conflicts. Its funding is precarious.</p>

<p>And yet. When you or someone you love is diagnosed with a serious condition, and you want to know what the evidence actually says—not what a drug company wants you to believe, not what some random website claims, but what careful analysis of all the relevant trials shows—Cochrane is often the best resource that exists. Not perfect. Not comprehensive. But more rigorous than almost anything else available.</p>

<p>This is the strange position evidence synthesis occupies in modern medicine. It's essential and underfunded. Rigorous and slow. Trusted and controversial. It represents a bet that the truth matters, that knowing what works is worth the immense effort of finding out. In a healthcare system awash in marketing, misinformation, and motivated reasoning, that bet seems worth making.</p>

<p>Archie Cochrane died before he could see his vision realized. But every time a doctor changes a prescription because a systematic review revealed unexpected harms, every time a health system drops an ineffective treatment because the evidence said it didn't work, every time a patient makes an informed choice based on the best available data—his vision lives on. The project remains unfinished. But then again, science always is.</p>
      </div>

      <footer class="wikipedia-footer">
        <p class="source-link">
          <a href="https://en.wikipedia.org/wiki/Cochrane_(organisation)" target="_blank" rel="noopener">
            View original Wikipedia article &rarr;
          </a>
        </p>
        <p class="rewrite-note">
          This article has been rewritten from Wikipedia source material for enjoyable reading.
          Content may have been condensed, restructured, or simplified.
        </p>
      </footer>

      
    </article>
  
  </main>
</body>
</html>