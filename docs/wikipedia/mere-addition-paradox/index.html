<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Mere addition paradox - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="wikipedia-page">
      <header class="wikipedia-header">
        <div class="type-badge">Wikipedia Deep Dive</div>
        <h1>Mere addition paradox</h1>
        <div class="article-meta">
          <span class="read-time">11 min read</span>
        </div>
      </header>

      <div class="wikipedia-content">
        <p class="source-note">Based on <a href="https://en.wikipedia.org/wiki/Mere_addition_paradox">Wikipedia: Mere addition paradox</a></p>

<h2>The Paradox That Makes Philosophers Lose Sleep</h2>

<p>Imagine you could design the future of humanity. You have two choices. Behind door number one: a small population of extraordinarily happy people, each living lives of profound fulfillment, deep relationships, and meaningful work. Behind door number two: a vastly larger population where everyone's life is just barely worth living—not miserable, but containing only the slightest sliver of positive experience above the threshold of "I'm glad I exist."</p>

<p>Which future is better?</p>

<p>Most people instinctively reach for door number one. Obviously a world of deeply flourishing humans beats a world of billions barely scraping by, right?</p>

<p>Here's the problem: through a series of seemingly reasonable steps, each one almost impossible to reject, the philosopher Derek Parfit showed in 1984 that we're logically committed to choosing door number two. He called this the "repugnant conclusion"—and the name stuck because that's exactly how it feels.</p>

<h2>The Trap Parfit Set</h2>

<p>Parfit's argument works like a logic puzzle, the kind where each step seems obviously true until you realize where you've ended up. Let me walk you through it.</p>

<p>Picture four different possible populations. We'll call them A, A+, B−, and B. Think of each group of people as a bar on a graph, where the width of the bar represents how many people there are, and the height represents how happy each person is.</p>

<p>Population A is simple: a group of very happy people. Everyone's flourishing. Life is good.</p>

<p>Now consider A+. It contains all the same people from A, still just as happy. But we've added a second group—people whose lives are less wonderful but still genuinely positive. They're glad to be alive. Their existence doesn't affect the original group at all.</p>

<p>Here comes the first seemingly innocent step: Is A+ worse than A?</p>

<p>Think carefully. The original people are exactly as happy as before. We've simply added more people whose lives are worth living. How could adding happy people—even if they're less happy than the originals—make the world worse? That seems almost mathematically impossible. So A+ is at least as good as A, maybe better.</p>

<p>Now look at B−. This is another complex population with two groups. One group is moderately happy, and the other is slightly less so. Here's the key: if you average everything out, B− has more total happiness than A+, distributed more equally. The inequality in A+ (very happy people alongside merely happy people) seems unfair compared to the more egalitarian B−.</p>

<p>Most ethical frameworks would say B− beats A+. More happiness overall? Check. More equality? Check. Surely B− is better.</p>

<p>Finally, population B. This is just B− with the artificial line between the two groups erased. Same people, same happiness levels—we've simply stopped dividing them into separate categories. Since nothing actually changed about anyone's welfare, B must be exactly as good as B−.</p>

<p>Do you see the trap closing?</p>

<h2>The Walls Close In</h2>

<p>Let's connect the dots:</p>

<ul>
<li>A+ is no worse than A (we just added happy people)</li>
<li>B− is better than A+ (more happiness, more equality)</li>
<li>B is exactly as good as B− (same people, same happiness)</li>
</ul>

<p>Therefore, B is better than A.</p>

<p>But wait. Look at what B actually is compared to A. Population A was our small group of extremely happy people. Population B is a larger group where everyone is less happy. We've somehow concluded that replacing deep flourishing with mediocre-but-positive existence is an improvement.</p>

<p>And here's where Parfit twists the knife: this process can repeat. From B, we can construct B+, then C−, then C. Each step is as reasonable as the last. We keep adding more people with slightly lower but still positive welfare, and each time we can't find the logical flaw.</p>

<p>Eventually, we arrive at population Z: an almost unimaginably vast number of people, each living a life that's just barely worth living. By the same logic that got us from A to B, we must conclude that Z is better than A.</p>

<p>That's the repugnant conclusion. A philosophical checkmate that says we should prefer trillions of barely-satisfied people over a smaller population living rich, meaningful lives.</p>

<h2>Why Can't We Just Reject It?</h2>

<p>The obvious response is: clearly something's wrong with this argument. Let's just reject the conclusion and move on.</p>

<p>But here's why philosophers have been wrestling with this since 1984: which step do you reject? Each individual step seems rock-solid.</p>

<p>Can adding genuinely happy people to the world make it worse? That seems cruel—we'd be saying some lives aren't worth creating even though the people living them are glad to exist.</p>

<p>Can we reject the idea that more total happiness with more equality is better? That throws out most of our moral intuitions about fairness and wellbeing.</p>

<p>Can we say that erasing an arbitrary line between groups changes the moral calculation? That seems absurd—we haven't changed anyone's actual experience.</p>

<p>Every escape route seems to lead somewhere even more troubling than the repugnant conclusion itself.</p>

<h2>The Attempted Escapes</h2>

<p>Philosophers have spent decades looking for the exit. Here are the main attempts:</p>

<h3>Reject Transitivity</h3>

<p>Some philosophers, including Larry Temkin and Stuart Rachels, have proposed a radical solution: maybe "better than" doesn't work the way we assume.</p>

<p>In mathematics, transitivity is a basic property. If A is greater than B, and B is greater than C, then A must be greater than C. We assume moral comparisons work the same way. If world A is better than world B, and B is better than C, then A should be better than C.</p>

<p>But what if that's wrong? What if moral value is more like rock-paper-scissors than a number line? Perhaps A+ beats A, and B− beats A+, but somehow A beats B− when we compare them directly. This would dissolve the paradox—but at the cost of making moral reasoning much stranger and less intuitive than we thought.</p>

<h3>Switch to Average Utilitarianism</h3>

<p>Classical utilitarianism says we should maximize total happiness—add up everyone's welfare and make that number as big as possible. Under this view, more happy people always means more value, which is exactly what creates Parfit's trap.</p>

<p>Average utilitarianism offers an alternative: we should maximize average happiness per person, not total happiness. Under this framework, A+ is actually worse than A because those additional people drag down the average.</p>

<p>Problem solved?</p>

<p>Not quite. Parfit pointed out that average utilitarianism has its own absurd implications. Imagine a world of ten people living wonderful lives. Now suppose we could add a new person whose life would be merely good—positive, but below the current average. Average utilitarianism says we shouldn't create this person. Their existence would be a net negative because it lowers the average.</p>

<p>That seems just as troubling. We'd be saying that perfectly good lives shouldn't exist because other people are doing better. It implies that in a world of millionaires, a happy middle-class person is somehow a bad thing.</p>

<h3>Embrace the Conclusion</h3>

<p>Some philosophers, including Torbjörn Tännsjö and Michael Huemer, have argued that we should stop resisting and accept the repugnant conclusion. Maybe it's not actually repugnant—maybe our intuition is simply wrong.</p>

<p>Tännsjö's argument runs like this: yes, each individual in population Z is worse off than individuals in population A. But there are so many more of them. The collective value—the sum of all those lives being lived, all those moments of mild satisfaction—adds up to more than the intense flourishing of a smaller group.</p>

<p>We might compare it to asking whether you'd rather have one magnificent diamond or a mountain of decent-quality gems. Your first instinct might favor the single stunning stone, but when you actually do the math...</p>

<p>This approach requires us to trust logic over intuition. Our gut reaction against population Z might be a cognitive bias, not a moral truth.</p>

<h3>Abandon the Search</h3>

<p>The most pessimistic response comes from Gustaf Arrhenius, who proved something remarkable: no theory of population ethics can satisfy all of our reasonable intuitions simultaneously. We're not just failing to find the right answer—there may be no right answer to find.</p>

<p>Arrhenius showed that any ethical framework for comparing populations must violate at least one of several extremely plausible principles. It's not that we haven't been clever enough. The problem is mathematically impossible to solve in a way that satisfies our full set of intuitions.</p>

<p>This suggests that population ethics might be a domain where human moral intuition simply breaks down, the way our physical intuitions break down in quantum mechanics or at relativistic speeds.</p>

<h2>The Very Repugnant Conclusion</h2>

<p>As if the original paradox weren't troubling enough, philosophers have discovered an even darker variant.</p>

<p>The very repugnant conclusion shows that some ethical theories imply something worse than population Z. According to these frameworks, for any population of flourishing people, there exists a "better" population consisting of two groups: a substantial number of people living in genuine misery, plus an even larger number of people with lives barely worth living.</p>

<p>In other words, it's not just that we should prefer billions of mediocre lives to millions of excellent ones. We should potentially prefer a world with significant suffering, as long as there are enough barely-positive lives to "outweigh" it.</p>

<p>This extension pushes our intuitions even harder. Most people find it nearly impossible to accept that adding suffering could be offset by adding sufficient quantities of minimal satisfaction.</p>

<h2>A Statistical Twist</h2>

<p>In 2010, philosopher Nicole Hassoun identified a completely different version of the mere addition paradox—one that shows up in economics and statistics rather than ethics.</p>

<p>Consider this scenario: a village of 100 people collectively controls $100 in resources. The average wealth per capita is $1. Now a billionaire moves to the village, bringing $1,000,000.</p>

<p>What's the new average wealth per capita? The village now has 101 people controlling $1,000,100. That's an average of $9,901 per person.</p>

<p>The statistics suggest the village has experienced a dramatic increase in prosperity. By many measures, it would appear that poverty has been virtually eliminated. But nothing has actually changed for the original 100 villagers. They're still living on their same $100.</p>

<p>This is "mere addition" in a different sense: merely adding a rich person to a population can make poverty statistics look better without improving anyone's actual situation. Hassoun proposed that any sensible measure of poverty should satisfy a "no mere addition" axiom—adding a wealthy person shouldn't, by itself, be counted as reducing poverty.</p>

<p>While this version lacks the philosophical depth of Parfit's puzzle, it has practical implications for how we measure and address economic inequality.</p>

<h2>Why This Matters Beyond Philosophy Departments</h2>

<p>The mere addition paradox might seem like an abstract game for academics, but it has real implications for how we think about some of humanity's biggest questions.</p>

<p>Consider climate change and future generations. We're making decisions today that will affect how many people can live on Earth and how well they'll live. Should we prioritize creating a smaller population with high quality of life, or is there value in maximizing the total number of future lives, even at some cost to individual welfare?</p>

<p>Consider reproductive ethics. If adding people with worthwhile lives is always at least neutral (as step one of Parfit's argument suggests), does that mean we have obligations to create more people? Some philosophers have argued exactly this—that there's something wrong with choosing not to bring happy people into existence.</p>

<p>Consider existential risk. If the repugnant conclusion is correct, then preventing human extinction becomes extraordinarily important. A future with vast numbers of people living barely-positive lives would be better than no future at all—which means we should be willing to accept significant costs now to ensure humanity's long-term survival.</p>

<p>These aren't just thought experiments. They connect to live debates about population policy, environmental ethics, and how much we should sacrifice for future generations.</p>

<h2>Where Does This Leave Us?</h2>

<p>After forty years, the mere addition paradox remains unsolved. Philosophers have proposed dozens of approaches, each with its own uncomfortable implications. The uncomfortable truth may be that our moral intuitions about population ethics are simply inconsistent—that there's no coherent way to rank possible futures that matches all of our gut feelings about what matters.</p>

<p>Perhaps the real lesson is humility. When our best reasoning leads to conclusions that feel deeply wrong, we face a choice: trust the reasoning or trust the feeling. Neither option is obviously correct.</p>

<p>Derek Parfit himself never found an answer he was satisfied with. He continued working on population ethics until his death in 2017, convinced that the question mattered enormously but uncertain of the solution.</p>

<p>Some problems in philosophy get resolved. Others get dissolved—we realize we were asking the wrong question. But some, like the mere addition paradox, may simply be hard in a way that resists resolution. They're not puzzles waiting to be solved but genuine dilemmas at the edge of what moral reasoning can handle.</p>

<p>The next time someone asks you whether you'd prefer a world of deep flourishing or vast mediocrity, you'll know the answer is far from obvious. And that uncertainty itself might be the most honest response philosophy can offer.</p>
      </div>

      <footer class="wikipedia-footer">
        <p class="source-link">
          <a href="https://en.wikipedia.org/wiki/Mere_addition_paradox" target="_blank" rel="noopener">
            View original Wikipedia article &rarr;
          </a>
        </p>
        <p class="rewrite-note">
          This article has been rewritten from Wikipedia source material for enjoyable reading.
          Content may have been condensed, restructured, or simplified.
        </p>
      </footer>

      
      <section class="related-articles">
        <h2>Related Articles</h2>
        <p class="related-intro">This deep dive was written in connection with these articles:</p>
        <ul class="related-list">
          
      <li class="related-article-item">
        <a href="../../article/f6888f86-6d25-4969-8b29-1fcd71a07faa/index.html">
          <strong>It&#039;s Good To Create Happy People: A Comprehensive Case </strong>
        </a>
        <span class="article-meta">
          by Bentham&#039;s Bulldog in 
        </span>
      </li>
        </ul>
      </section>
    
    </article>
  
  </main>
</body>
</html>