<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Effective altruism - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="wikipedia-page">
      <header class="wikipedia-header">
        <div class="type-badge">Wikipedia Deep Dive</div>
        <h1>Effective altruism</h1>
        <div class="article-meta">
          <span class="read-time">14 min read</span>
        </div>
      </header>

      <div class="wikipedia-content">
        <p class="source-note">Based on <a href="https://en.wikipedia.org/wiki/Effective_altruism">Wikipedia: Effective altruism</a></p>

<h2>The Trolley Problem With Real Money</h2>

<p>Here's a question that sounds absurd until you think about it: If you saw a child drowning in a pond, you'd jump in to save them, ruining your expensive suit in the process. Nobody would hesitate. But what if, instead of jumping in, you could sell that suit for a thousand dollars and donate the money to a charity that would save not one child but five children from dying of malaria?</p>

<p>The philosopher William MacAskill says you should sell the suit.</p>

<p>This uncomfortable answer sits at the heart of effective altruism, a movement that emerged in the early 2010s and has since channeled hundreds of millions of dollars toward causes its adherents believe do the most good per dollar spent. It's a community that includes Facebook co-founder Dustin Moskovitz, Skype creator Jaan Tallinn, and until his spectacular downfall, cryptocurrency exchange founder Sam Bankman-Fried.</p>

<p>The movement asks a deceptively simple question: If you want to help others, shouldn't you try to help them as much as possible?</p>

<h2>The Birth of Calculated Compassion</h2>

<p>Effective altruism didn't spring from nowhere. Its intellectual roots trace back to 1972, when the Australian philosopher Peter Singer published an essay called "Famine, Affluence, and Morality." Singer made an argument that still unsettles people half a century later: geographic distance, he insisted, has no moral significance. A starving child in Bangladesh deserves exactly as much of your concern as a starving child next door.</p>

<p>For decades, this remained an interesting philosophical position—the kind of thing students debated in ethics seminars before going on to live perfectly normal lives. But in the late 2000s, several separate communities began coalescing around the idea of actually doing something about it.</p>

<p>One group formed around GiveWell, an organization that emerged from the hedge fund world in 2007. Its founders wanted to apply the same rigorous analysis they used for investments to charitable giving. Which charities actually worked? Which ones wasted money? Could you measure the impact of a donated dollar the way you measured the return on a stock?</p>

<p>Another thread came from Oxford University, where a young philosopher named Toby Ord founded Giving What We Can in 2009. Members pledged to donate at least ten percent of their income to highly effective charities—a secular tithe, but one directed by evidence rather than tradition.</p>

<p>A third strand emerged from the rationalist community clustered around LessWrong, an online forum where participants tried to apply clear thinking to everything from artificial intelligence to personal decision-making. Many of these people were already worried about existential risks—threats that could end or permanently cripple human civilization—and they saw effective altruism as a natural extension of their concerns.</p>

<p>In 2011, these groups merged under a new umbrella organization and held a vote for its name. The winner: the Centre for Effective Altruism.</p>

<h2>How to Choose What to Care About</h2>

<p>Most charitable giving is driven by emotion. Someone sees a heartbreaking photograph, reads a compelling story, or encounters a charismatic fundraiser. Money flows toward whatever captures attention in the moment.</p>

<p>Effective altruists find this deeply irrational.</p>

<p>Instead, they advocate for what they call "cause prioritization"—the systematic comparison of different ways you might spend your charitable dollars. The framework they developed evaluates causes along three dimensions.</p>

<p>First, importance: How much would the world improve if this problem were solved? Curing aging would be more important than curing a rare disease that affects a handful of people, simply by the numbers.</p>

<p>Second, tractability: How much of the problem can actually be solved with additional resources? Some issues, however important, resist intervention. Others yield dramatically to relatively modest investments.</p>

<p>Third, neglectedness: How much attention is the cause already receiving? If a problem is both important and tractable but already attracts billions in funding, your marginal contribution matters less than it would for an equally worthy cause that few others support.</p>

<p>This framework led effective altruists to some surprising conclusions. Global health and poverty alleviation emerged as obvious priorities—organizations like the Against Malaria Foundation could demonstrate that distributing insecticide-treated bed nets saved lives at a cost of roughly four thousand dollars per death averted. That's an extraordinary return on charitable investment compared to, say, funding an art museum in a wealthy city.</p>

<p>But the framework also pointed toward causes that most people had never considered. Animal welfare, for instance, when measured by the number of sentient beings affected. Factory farms confine and kill billions of chickens every year under conditions that would horrify most consumers if they saw them directly. If animal suffering counts morally—and many effective altruists believe it does—then improving conditions on factory farms might be one of the most impactful things a person could do.</p>

<p>And then there's the long-term future.</p>

<h2>The Billion-Year View</h2>

<p>Some effective altruists take their reasoning to what critics consider an absurd extreme. If all lives count equally, they argue, then future lives count too. And there could be vastly more future people than there are present people.</p>

<p>This perspective, called longtermism, suggests that reducing existential risks—threats that could either destroy humanity entirely or permanently prevent us from reaching our potential—might be the most important thing we could possibly do. A catastrophe that ended civilization would eliminate not just the eight billion people alive today but the trillions upon trillions of people who might otherwise exist over millions of future years.</p>

<p>From this vantage point, even a small reduction in the probability of human extinction could outweigh almost any present-day intervention. Preventing a pandemic that might kill millions still leaves humanity intact. Preventing an artificial intelligence catastrophe that might end human civilization forever saves effectively everyone who would ever exist.</p>

<p>This is why effective altruist funding has poured into artificial intelligence safety research. The concern isn't science fiction—it's the mathematically driven observation that superintelligent systems, if they ever emerge, might not share human values, and that the transition to a world with such systems could be the most dangerous moment in our species' history.</p>

<p>In 2020, Toby Ord published "The Precipice," a book arguing that humanity faces perhaps a one-in-six chance of existential catastrophe over the next century. He compared our situation to that of a teenager who has acquired tremendous power—nuclear weapons, engineered pathogens, increasingly capable AI—before developing the wisdom to wield it safely.</p>

<h2>The Quality-Adjusted Life Year</h2>

<p>To compare interventions across wildly different domains, effective altruists needed a common currency. In health economics, that currency is the QALY—the quality-adjusted life year.</p>

<p>The concept works like this: One year of perfect health equals one QALY. A year of life with significant disability might count as 0.7 QALYs, or 0.5, depending on the severity. Death contributes zero. If a treatment extends someone's life by ten years but at reduced quality, you multiply the years by the quality weight to get the total QALYs gained.</p>

<p>This sounds coldly mathematical, and it is. It's also the kind of calculation that health systems around the world already use to decide which treatments to fund. The British National Health Service, for instance, generally won't pay more than twenty to thirty thousand pounds per QALY gained—a threshold that has sparked fierce debate but also forces honest conversations about scarcity and trade-offs.</p>

<p>Effective altruists took this framework and ran with it. GiveWell's recommended charities are selected partly on the basis of cost per life saved or cost per QALY, adjusted for uncertainty. The Against Malaria Foundation, a perennial favorite, achieves its results at rates that dwarf what most developed-world health interventions can match.</p>

<p>But the QALY framework also reveals uncomfortable truths. Many interventions that feel obviously good—building schools, funding scholarships, supporting local hospitals—turn out to be far less cost-effective than distributing antimalarial bed nets or providing vitamin A supplementation to children in developing countries. The intuition that charity should start at home runs directly into the arithmetic of global inequality.</p>

<h2>The Drowning Child Problem, Revisited</h2>

<p>Return for a moment to that drowning child in the pond. The philosopher Kwame Anthony Appiah posed a clever challenge to Singer's original analogy in 2006. What if the most effective action isn't to save the child yourself—ruining your expensive suit in the process—but to sell the suit and donate the proceeds to charity? You could save multiple children instead of just one.</p>

<p>Singer would respond that this misses the point. The drowning child is right in front of you. The duty to rescue is immediate and compelling in a way that the duty to send money is not.</p>

<p>But MacAskill went further. Presented with a scenario in which he could either save a child from a burning building or save a Picasso painting to sell for charity, he said the effective altruist should save the Picasso.</p>

<p>This answer struck many observers as monstrous. The psychologist Alan Jern called it "unnatural, even distasteful, to many people." It violates deep moral intuitions about the importance of immediate rescue, about the special obligations we have to those we can directly help.</p>

<p>MacAskill later softened his position, endorsing a "qualified definition of effective altruism" that acknowledges constraints—special obligations to those nearby, moral rules against letting preventable harm occur right in front of you. But the tension remains. Effective altruism, taken to its logical conclusion, seems to demand that we become calculating machines, optimizing every decision for maximum impact regardless of emotional pull or social convention.</p>

<h2>The Problem With Measurement</h2>

<p>Not everything that matters can be counted, and not everything that can be counted matters. This aphorism, often attributed to Einstein, captures a fundamental challenge for effective altruism.</p>

<p>The movement's emphasis on evidence and quantification naturally directs resources toward interventions with clear, measurable outcomes. Distributing bed nets is easy to count. So is administering vaccinations or providing deworming medication to schoolchildren. These interventions produce data points: number of nets distributed, number of vaccines administered, reduction in disease prevalence.</p>

<p>But what about political reform? What about strengthening democratic institutions, or fighting corruption, or shifting cultural attitudes toward human rights? These interventions are "worked on one grinding step at a time," as the writer Pascal-Emmanuel Gobry observed, and their results resist controlled experiments.</p>

<p>Critics worry that effective altruism systematically undervalues interventions that address root causes—structural inequality, political oppression, cultural discrimination—in favor of interventions that treat symptoms. Distributing bed nets is wonderful, but it doesn't address the reasons why some countries remain poor while others become rich. It's a band-aid on a wound that requires surgery.</p>

<p>The movement has responded to these criticisms in part by expanding its scope. Open Philanthropy, the grantmaking organization funded primarily by Dustin Moskovitz and Cari Tuna, has made significant investments in criminal justice reform, immigration policy research, and other systemic issues. But the tension between measurable and important remains unresolved.</p>

<h2>Effective Altruism and Its Discontents</h2>

<p>The New York Times columnist Ross Douthat once imagined "effective altruists sitting around in a San Francisco skyscraper calculating how to relieve suffering halfway around the world while the city decays beneath them." It's a vivid image, and it captures something real about the movement's demographics and blind spots.</p>

<p>Effective altruism emerged from elite universities—Oxford, Cambridge, Harvard, Stanford—and has remained concentrated there. Its adherents are disproportionately male, disproportionately white, and disproportionately employed in technology and finance. The movement's emphasis on impartial, detached reasoning appeals to people who are comfortable with abstraction, which correlates strongly with certain educational and socioeconomic backgrounds.</p>

<p>The philosopher William Schambra has argued that effective altruism undermines the kind of face-to-face, community-based charitable giving that builds social trust and sustains democracy. When neighbors help neighbors, they strengthen bonds of reciprocity that make civil society possible. When donors write checks to distant charities selected by algorithms, they participate in a fundamentally different—and perhaps less valuable—form of altruism.</p>

<p>There's also the awkward matter of how some effective altruists acquired the wealth they're now giving away. The technology industry that produced so many of the movement's major donors has its own moral complexities: addictive social media platforms, algorithmic systems that amplify misinformation, working conditions that have drawn regulatory scrutiny.</p>

<p>And then there's Sam Bankman-Fried.</p>

<h2>The FTX Catastrophe</h2>

<p>For several years, Bankman-Fried was effective altruism's most prominent public face. The founder of the cryptocurrency exchange FTX, he had made his wealth explicitly to give it away—a strategy the movement called "earning to give." He lived frugally, at least by billionaire standards. He spoke at effective altruism conferences. He funded effective altruism organizations to the tune of hundreds of millions of dollars.</p>

<p>Then, in November 2022, FTX collapsed. Bankman-Fried was eventually convicted of fraud. It emerged that much of his charitable giving had been funded by customer deposits—other people's money, which he had no right to give away.</p>

<p>The scandal forced the movement into painful self-examination. Had effective altruism's emphasis on impact encouraged reckless risk-taking? Had the community been too eager to celebrate a wealthy donor without scrutinizing how he acquired his wealth? Was "earning to give" an invitation to ethical shortcuts—a framework that judged the ends while ignoring the means?</p>

<p>Defenders of effective altruism pointed out that fraud is fraud regardless of the fraudster's stated philosophy. Bankman-Fried's crimes were crimes; his effective altruism was incidental. But critics noted that the movement had provided him with social capital and moral cover, amplifying his influence in ways that may have delayed accountability.</p>

<p>The FTX collapse also revealed the degree to which effective altruism had become dependent on a small number of extremely wealthy donors. When those donors stumbled—whether through fraud, market downturns, or simply changing priorities—the organizations they funded became vulnerable.</p>

<h2>What Effective Altruism Gets Right</h2>

<p>Despite its controversies, effective altruism has introduced ideas that deserve to outlast any particular scandal or criticism.</p>

<p>The movement has normalized talking about charitable effectiveness. Before GiveWell, most donors had no way to compare charities rigorously. Now there are multiple organizations devoted to researching which interventions work and which don't. This is straightforwardly valuable.</p>

<p>Effective altruism has also surfaced neglected causes. Factory farming affects billions of animals under conditions that are genuinely horrifying, but until recently it received almost no philanthropic attention. Artificial intelligence safety research seemed like science fiction until effective altruists began funding it seriously; now it's a mainstream policy concern.</p>

<p>Perhaps most importantly, the movement has made explicit what was always implicit: that how we allocate our charitable resources involves trade-offs. Giving to one cause means not giving to another. Pretending otherwise—treating all charitable impulses as equally worthy—may be emotionally comfortable, but it comes at the cost of impact.</p>

<p>The philosopher Richard Pettigrew has argued that effective altruists often feel more profound dismay at distant suffering than most people feel for suffering nearby. They're not unemotional calculating machines; they're people whose empathy extends further than convention suggests it should. Larissa MacFarquhar, who profiled several effective altruists in her book "Strangers Drowning," found the same thing: these were not coldly rational optimizers but people possessed by an unusual intensity of moral concern.</p>

<h2>The Question That Won't Go Away</h2>

<p>In 2015, MacAskill published a book called "Doing Good Better." The title captured both the ambition and the humility of effective altruism. Not doing good perfectly. Not doing the most good possible. Just doing good better than we otherwise would.</p>

<p>This modest framing appeals to people who find the movement's more extreme implications troubling. You don't have to sell the Picasso. You don't have to donate everything above subsistence income to GiveWell's top charities. You don't have to work on AI safety instead of becoming a doctor.</p>

<p>But you could ask whether your giving is actually accomplishing anything. You could compare charities. You could consider causes you'd never thought about. You could do good better.</p>

<p>The drowning child is still in the pond. The question is what you do about it.</p>
      </div>

      <footer class="wikipedia-footer">
        <p class="source-link">
          <a href="https://en.wikipedia.org/wiki/Effective_altruism" target="_blank" rel="noopener">
            View original Wikipedia article &rarr;
          </a>
        </p>
        <p class="rewrite-note">
          This article has been rewritten from Wikipedia source material for enjoyable reading.
          Content may have been condensed, restructured, or simplified.
        </p>
      </footer>

      
      <section class="related-articles">
        <h2>Related Articles</h2>
        <p class="related-intro">This deep dive was written in connection with these articles:</p>
        <ul class="related-list">
          
      <li class="related-article-item">
        <a href="../../article/1db66da0-6263-478e-b61e-516a13f5f053/index.html">
          <strong>25 Propositions about the New Romanticism</strong>
        </a>
        <span class="article-meta">
          by Ted Gioia in 
        </span>
      </li>

      <li class="related-article-item">
        <a href="../../article/9dc524b3-ca65-4d03-9059-9362a2ecb69d/index.html">
          <strong>Bentham&#039;s Bulldog 2025 In Review</strong>
        </a>
        <span class="article-meta">
          by Bentham&#039;s Bulldog in 
        </span>
      </li>

      <li class="related-article-item">
        <a href="../../article/0f09daca-24ab-4b8c-8e8b-e73738bb86c4/index.html">
          <strong>Addressing My Critics</strong>
        </a>
        <span class="article-meta">
          by Bentham&#039;s Bulldog in 
        </span>
      </li>

      <li class="related-article-item">
        <a href="../../article/1f5ed959-7b0c-4e49-bc54-ebb547e48f70/index.html">
          <strong>Philosophy and The English Language</strong>
        </a>
        <span class="article-meta">
          by Bentham&#039;s Bulldog in 
        </span>
      </li>

      <li class="related-article-item">
        <a href="../../article/795b920f-ed86-4f9b-ba55-cd4f19abb94f/index.html">
          <strong>Why Are They So Bad? </strong>
        </a>
        <span class="article-meta">
          by Bentham&#039;s Bulldog in 
        </span>
      </li>

      <li class="related-article-item">
        <a href="../../article/bcb73dce-69fb-4dd4-86ff-4b95138cb170/index.html">
          <strong>OpenAI is a normal company now</strong>
        </a>
        <span class="article-meta">
          by Casey Newton in Platformer
        </span>
      </li>

      <li class="related-article-item">
        <a href="../../article/e3858af1-dbdd-4c4e-8440-df3601923002/index.html">
          <strong>The AI industry’s $100 million play to influence the 2026 elections</strong>
        </a>
        <span class="article-meta">
          by Judd Legum in Popular Information
        </span>
      </li>

      <li class="related-article-item">
        <a href="../../article/66616ff2-9ce4-4d1d-baf5-5daf3dbc82ca/index.html">
          <strong>Open Thread 409</strong>
        </a>
        <span class="article-meta">
          by Scott Alexander in Astral Codex Ten
        </span>
      </li>
        </ul>
      </section>
    
    </article>
  
  </main>
</body>
</html>