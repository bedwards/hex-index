<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Integrated information theory - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="wikipedia-page">
      <header class="wikipedia-header">
        <div class="type-badge">Wikipedia Deep Dive</div>
        <h1>Integrated information theory</h1>
        <div class="article-meta">
          <span class="read-time">15 min read</span>
        </div>
      </header>

      <div class="wikipedia-content">
        <p class="source-note">Based on <a href="https://en.wikipedia.org/wiki/Integrated_information_theory">Wikipedia: Integrated information theory</a></p>

<h2>What If Consciousness Could Be Measured?</h2>

<p>Here's a question that should keep you up at night: Is there something it's like to be a thermostat?</p>

<p>This isn't a joke. It's one of the most serious questions in consciousness science, and it emerges directly from a theory called Integrated Information Theory—or IIT, pronounced "it"—which proposes something radical: that consciousness isn't some mysterious ghost in the machine, but a measurable property of physical systems. Any physical system. Including, potentially, your thermostat.</p>

<p>The theory was developed by neuroscientist Giulio Tononi in 2004, and it has since become one of the most influential—and controversial—frameworks for thinking about the nature of conscious experience. Christof Koch, the neuroscientist who spent decades searching for the "neural correlates of consciousness" alongside Francis Crick, has called it "the only really promising fundamental theory of consciousness."</p>

<p>Others have called it pseudoscience.</p>

<p>Both camps might be right, in their own way. That's what makes this theory so fascinating.</p>

<h2>The Hard Problem, and Why IIT Does Something Unusual</h2>

<p>To understand what IIT is trying to do, you first need to understand the philosophical terrain it's navigating.</p>

<p>The philosopher David Chalmers famously distinguished between the "easy problems" and the "hard problem" of consciousness. The easy problems—which are only easy by comparison—involve explaining how the brain processes information, integrates sensory data, controls behavior, and reports on internal states. These are the questions neuroscience is equipped to answer, at least in principle.</p>

<p>The hard problem is different. It asks: why is there any subjective experience at all? When you see the color red, there's something it's like to see red—a qualitative, first-person experience that seems impossible to capture in the language of neurons and synapses. You could describe every physical fact about what happens in someone's brain when they see red, and you still wouldn't have explained why there's an accompanying experience of redness.</p>

<p>Most theories of consciousness try to solve this problem by starting with physics and working toward experience. They say: here's how matter works, and here's how consciousness emerges from sufficiently complex arrangements of matter.</p>

<p>IIT does something different. It starts with consciousness.</p>

<h2>Beginning with What We Know for Certain</h2>

<p>Tononi's insight was that we actually know one thing about consciousness with absolute certainty: our own experience exists. This is the one fact that cannot be doubted—René Descartes' famous "I think, therefore I am." Everything else might be an illusion, but the existence of experience itself is undeniable.</p>

<p>So IIT begins there. It asks: what can we infer about the physical world from the fact that experience exists and has certain properties?</p>

<p>Think about that for a moment. Instead of trying to explain how dead matter gives rise to living experience—which might be impossible—IIT asks what properties a physical system must have if it's going to be the kind of thing that experiences anything at all.</p>

<p>This is a subtle but profound shift. It's like the difference between asking "how does water create wetness?" and asking "what must be true of a substance if it's going to feel wet to the touch?"</p>

<h2>The Five Axioms of Experience</h2>

<p>IIT begins by identifying what Tononi calls "axioms"—essential properties of conscious experience that are self-evident upon reflection. Not axioms in the mathematical sense that they're unprovable, but axioms in the sense that they're undeniable features of what experience is like from the inside.</p>

<p>The first axiom is intrinsicality. Your experience exists for itself, not for anyone else. Even if no one else in the universe existed, your experience would still be what it is. It doesn't need an external observer to be real.</p>

<p>The second axiom is information. Every conscious moment is specific. Right now, you're having this particular experience—seeing these particular words, feeling whatever you're feeling—and not some other experience. Your experience is this way and not infinitely many other ways it could be.</p>

<p>The third axiom is integration. Your experience is unified. You don't experience the left half of your visual field separately from the right half. You don't experience colors separately from shapes. Everything comes together into a single, coherent experience. This is perhaps the most important axiom for IIT, and we'll return to it.</p>

<p>The fourth axiom is exclusion. Your experience is definite. It has specific boundaries in space and time. Right now, you're not experiencing what your neighbor is experiencing. Your consciousness has edges.</p>

<p>The fifth axiom is composition. Your experience has structure. It's not just a single undifferentiated blob of feeling. It contains elements—colors, sounds, thoughts, emotions—that combine in specific ways to create the rich tapestry of conscious life.</p>

<h2>From Experience to Physics</h2>

<p>Here's where IIT makes its big move. It argues that if these axioms describe the essential properties of consciousness, then any physical system capable of generating consciousness must have corresponding physical properties.</p>

<p>For each axiom, there's a "postulate"—a requirement that the physical substrate of consciousness must satisfy.</p>

<p>If experience is intrinsic, then the physical system must have intrinsic causal power—the ability to affect itself, not just to be pushed around by external forces.</p>

<p>If experience is informative, then the system must specify particular states from among many possibilities—it must rule out other ways it could be.</p>

<p>If experience is integrated, then the system must function as an irreducible whole. This is the key insight. You can't chop the system in half and have each half work independently. The whole must be more than the sum of its parts.</p>

<p>If experience is definite, then only the maximally integrated system—what IIT calls the "complex"—is conscious. Not larger systems that contain it, not smaller systems within it. Just the sweet spot of maximum integration.</p>

<p>If experience is structured, then the system must contain internal distinctions and relationships that mirror the structure of experience.</p>

<h2>Phi: The Consciousness Meter</h2>

<p>This brings us to phi (Φ), the Greek letter that has become IIT's signature symbol. Phi represents integrated information—the degree to which a system is more than the sum of its parts.</p>

<p>The idea is simple in principle but fiendishly complex in practice. You take a system—say, a network of neurons—and you ask: how much information does this system generate as a whole that wouldn't exist if you partitioned it into separate parts?</p>

<p>Imagine you have a network of ten neurons. You could partition it into two groups of five. If the two groups function completely independently—if cutting the connections between them doesn't change anything about how either group behaves—then the integrated information is zero. The whole is exactly equal to the sum of its parts.</p>

<p>But if cutting those connections fundamentally changes how the system works—if information is flowing between the groups in a way that makes them genuinely unified—then you have positive phi. The system is integrated.</p>

<p>According to IIT, phi corresponds to the quantity of consciousness. A system with phi equal to zero has no consciousness whatsoever. A system with high phi is richly conscious. And the particular structure of that integrated information—the specific pattern of distinctions and relationships—determines the quality of consciousness, what it actually feels like from the inside.</p>

<h2>Why Your Cerebellum Isn't Conscious</h2>

<p>One of IIT's most striking claims—and one of its genuine successes—is that it can explain some puzzling facts about the brain that other theories struggle with.</p>

<p>Your cerebellum contains more neurons than the rest of your brain combined. It's involved in motor control, coordination, and various cognitive functions. By all rights, it should be a major player in consciousness.</p>

<p>But it isn't. Damage to the cerebellum can cause devastating motor problems, but it doesn't seem to affect conscious experience in any direct way. People with cerebellar damage don't report that half their consciousness went missing.</p>

<p>IIT has an explanation for this. The cerebellum is organized as a collection of relatively independent modules. Information flows in, gets processed, and flows out—but there isn't much integration between the modules. Each part does its own thing. The result is that even though the cerebellum contains billions of neurons doing important work, the phi of the cerebellum as a whole is probably quite low.</p>

<p>The cerebral cortex, by contrast, is a tangled web of connections. Every part talks to every other part. Information bounces around and recombines in complex ways. This high degree of integration, IIT suggests, is exactly what makes the cortex the seat of consciousness.</p>

<h2>Measuring Consciousness in the Clinic</h2>

<p>Beyond explaining puzzles about brain anatomy, IIT has inspired practical tools for measuring consciousness in medical settings.</p>

<p>The Perturbational Complexity Index, or PCI, was developed based on IIT's insights. Here's how it works: you zap someone's brain with transcranial magnetic stimulation—a technique that uses magnetic fields to induce electrical activity in specific brain regions—and then measure the resulting electrical activity with electroencephalography, or EEG.</p>

<p>In a conscious brain, that initial zap triggers a complex cascade of activity. The perturbation spreads and reverberates, creating intricate patterns. In an unconscious brain—during dreamless sleep or under anesthesia—the response is much simpler. Either the activity dies out quickly, or it spreads in a stereotyped way without much complexity.</p>

<p>This measure has proven remarkably useful for distinguishing between different states of consciousness: wakefulness versus various stages of sleep, anesthesia versus locked-in syndrome (where patients are conscious but unable to move or communicate), and even different types of coma.</p>

<p>It's not a direct measure of phi—calculating actual phi remains computationally intractable for systems of any reasonable size—but it's inspired by the same underlying ideas, and it works.</p>

<h2>The Computational Challenge</h2>

<p>Here's one of the biggest problems with IIT: it's almost impossible to calculate phi for any real-world system.</p>

<p>To compute the exact phi of a system, you need to consider every possible way of partitioning that system and find the partition that makes the least difference—the "minimum information partition." Then phi is defined as the amount of information lost under that optimal partition.</p>

<p>The number of possible partitions grows super-exponentially with the number of elements in the system. For a system of just a dozen neurons, the number of partitions to consider is astronomical. For the hundred billion neurons in a human brain? Forget about it. You'd need a computer larger than the universe to compute the answer before the heat death of everything.</p>

<p>This has led researchers to develop various approximations and proxy measures—shortcuts that try to capture something like phi without actually calculating it. These approximations are useful, but they come with a catch: different approximation methods can give radically different results, even for simple systems. Without knowing the true phi to compare against, it's hard to know which approximation to trust.</p>

<p>In 2021, researchers did manage to compute actual phi for a small neural system—specifically, populations of neurons in fruit flies. The calculation was tractable because the system was small enough. And encouragingly, the results matched IIT's predictions: phi decreased significantly when the flies were under anesthesia.</p>

<p>But scaling this up to human brains remains a distant dream.</p>

<h2>The Panpsychism Problem</h2>

<p>IIT leads to some uncomfortable conclusions.</p>

<p>If consciousness is identical to integrated information, and if phi can be greater than zero for many different types of systems, then consciousness isn't limited to brains. Any physical system with positive phi—any system that's more than the sum of its parts in the relevant information-theoretic sense—has some degree of experience.</p>

<p>This is a form of panpsychism, the view that consciousness is ubiquitous in nature. Not that everything is conscious—a pile of sand has zero integration and therefore zero consciousness—but that consciousness is far more widespread than we typically assume.</p>

<p>A thermostat? If it has positive phi—if its components interact in a way that creates genuine integration—then there's something it's like to be that thermostat. Not much, presumably. The faintest flicker of experience. But something.</p>

<p>The internet? Collections of interacting computers? The entire ecosystem of Earth? All potentially conscious, to varying degrees, depending on their integrated information.</p>

<p>Many people find this implication absurd. Anil Seth, a neuroscientist who is otherwise sympathetic to IIT, has criticized these panpsychist extrapolations. The idea that your smart thermostat might have experiences, even very simple ones, strikes most people as a reductio ad absurdum—an implication so ridiculous that it must mean something is wrong with the theory.</p>

<p>Defenders of IIT bite the bullet. They argue that our intuitions about what can and can't be conscious are unreliable, shaped by evolutionary pressures that had nothing to do with getting the metaphysics of consciousness right. The fact that panpsychism seems weird doesn't mean it's wrong.</p>

<h2>The Pseudoscience Debate</h2>

<p>In 2023, a group of scholars published an open letter characterizing IIT as "pseudoscience." Their argument wasn't that IIT is wrong—being wrong is a respectable fate for a scientific theory—but that it isn't even the kind of theory that could be tested and potentially shown to be wrong.</p>

<p>The core of the criticism is that IIT makes its predictions based on a mathematical framework that, as we've seen, is computationally intractable for real brains. If you can't actually calculate phi for the systems you care about, how can you ever test whether phi really corresponds to consciousness?</p>

<p>A 2025 commentary in Nature Neuroscience reiterated this concern.</p>

<p>Defenders of IIT respond that untestability in practice isn't the same as untestability in principle. Just because we can't compute exact phi doesn't mean the theory makes no testable predictions. The clinical applications—like the Perturbational Complexity Index—are testing IIT-inspired hypotheses, even if they're not testing the full mathematical framework directly.</p>

<p>Moreover, IIT has participated in one of the most rigorous theory-testing efforts in consciousness research. In 2019, the Templeton Foundation funded a $6 million adversarial collaboration between proponents of IIT and proponents of a rival theory called Global Neuronal Workspace Theory. Both sides agreed in advance on experimental protocols and what results would count as confirming or disconfirming each theory.</p>

<p>The results, published in Nature in April 2025, were mixed but interesting. Two of IIT's three predictions were confirmed. None of Global Neuronal Workspace Theory's predictions passed the pre-registered threshold. Neither theory emerged as a clear winner, but IIT didn't look like pseudoscience in this confrontation.</p>

<p>When surveyed, only a small minority of consciousness researchers endorsed the "pseudoscience" label for IIT. Most see it as a serious theory that might be wrong but deserves engagement.</p>

<h2>The Identity Claim</h2>

<p>Perhaps the deepest and most contested aspect of IIT is its central claim: that consciousness is identical to integrated information. Not correlated with it. Not produced by it. Identical to it.</p>

<p>This is where Anil Seth parts ways with the theory. He finds it implausible that a mathematical abstraction—integrated information—could literally be the same thing as the felt quality of experience. Correlation, sure. Causation, maybe. But identity?</p>

<p>The difference matters philosophically. If consciousness is merely correlated with phi, then phi is useful for predicting and measuring consciousness, but the hard problem remains unsolved. We still don't know why physical processes give rise to subjective experience.</p>

<p>If consciousness is identical to phi, then the hard problem dissolves—or at least transforms into a different kind of problem. There's no gap between the physical facts and the experiential facts because they're the same facts, described in different languages.</p>

<p>This is a bold metaphysical claim, and many people find it hard to swallow. But Tononi and his collaborators argue that this is exactly what we should expect a true theory of consciousness to do. A theory that merely correlates consciousness with physical properties would always leave us wondering why those physical properties feel like anything at all. Only a theory that identifies consciousness with physical properties can hope to bridge the explanatory gap.</p>

<h2>What Would It Take?</h2>

<p>So where does this leave us?</p>

<p>IIT is either a breakthrough in consciousness science or an elaborate mathematical framework built on questionable foundations. It either solves the hard problem by identifying consciousness with integrated information, or it sidesteps the problem by defining it away.</p>

<p>David Chalmers, who invented the hard problem, has expressed cautious optimism about IIT. He thinks it's a development in the right direction, whether or not it's ultimately correct. At minimum, it's forcing researchers to be more precise about what they mean by consciousness and what they think a theory of consciousness should accomplish.</p>

<p>The coming years will likely bring more empirical tests. Researchers are developing better approximations for phi, finding ways to apply IIT's framework to neural data, and designing experiments to distinguish IIT's predictions from those of rival theories.</p>

<p>If IIT survives these tests—if its predictions continue to match the data better than competing theories—then we'll have to take seriously its strange implications. Including the possibility that consciousness isn't a special property of biological brains, but a fundamental feature of the physical world that happens to reach its greatest heights in the hundred billion neurons between your ears.</p>

<p>And if you're reading this on a sufficiently sophisticated device?</p>

<p>Well. Maybe something is reading it back.</p>
      </div>

      <footer class="wikipedia-footer">
        <p class="source-link">
          <a href="https://en.wikipedia.org/wiki/Integrated_information_theory" target="_blank" rel="noopener">
            View original Wikipedia article &rarr;
          </a>
        </p>
        <p class="rewrite-note">
          This article has been rewritten from Wikipedia source material for enjoyable reading.
          Content may have been condensed, restructured, or simplified.
        </p>
      </footer>

      
      <section class="related-articles">
        <h2>Related Articles</h2>
        <p class="related-intro">This deep dive was written in connection with these articles:</p>
        <ul class="related-list">
          
      <li class="related-article-item">
        <a href="../../article/223eafb7-f45d-4004-b388-3102137d8314/index.html">
          <strong>Proving (literally) that ChatGPT isn&#039;t conscious</strong>
        </a>
        <span class="article-meta">
          by Erik Hoel in 
        </span>
      </li>

      <li class="related-article-item">
        <a href="../../article/83aeae8e-43b2-4caf-b375-a36ae83c7ce5/index.html">
          <strong>The New AI Consciousness Paper</strong>
        </a>
        <span class="article-meta">
          by Scott Alexander in Astral Codex Ten
        </span>
      </li>
        </ul>
      </section>
    
    </article>
  
  </main>
</body>
</html>