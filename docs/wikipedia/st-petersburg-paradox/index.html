<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>St. Petersburg paradox - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="wikipedia-page">
      <header class="wikipedia-header">
        <div class="type-badge">Wikipedia Deep Dive</div>
        <h1>St. Petersburg paradox</h1>
        <div class="article-meta">
          <span class="read-time">12 min read</span>
        </div>
      </header>

      <div class="wikipedia-content">
        <p class="source-note">Based on <a href="https://en.wikipedia.org/wiki/St._Petersburg_paradox">Wikipedia: St. Petersburg paradox</a></p>

<h2>The Game That Broke Mathematics</h2>

<p>Here's a simple game. I flip a coin. If it lands heads on the first flip, I pay you two dollars. If it lands tails, I flip again. Heads on the second flip? Four dollars. Tails again? We keep going. Eight dollars, then sixteen, then thirty-two—doubling each time until heads finally appears and you collect your winnings.</p>

<p>How much would you pay to play this game?</p>

<p>Most people say something between five and twenty-five dollars. That seems reasonable—you'll probably get heads within the first few flips and walk away with a modest sum. But here's the thing that has haunted mathematicians for over three hundred years: according to the standard rules of probability, you should be willing to pay <em>any</em> amount to play. A million dollars. A billion. Everything you own.</p>

<p>This is the Saint Petersburg paradox, and it reveals something deeply strange about how we make decisions under uncertainty.</p>

<h2>The Math That Goes Wrong</h2>

<p>Let's work through why the expected value of this game is infinite. Expected value is a fundamental concept in probability—you calculate it by multiplying each possible outcome by its probability, then adding everything up. It tells you what you'd win on average if you played the game many, many times.</p>

<p>In our coin-flip game, the outcomes look like this:</p>

<ul>
<li>Heads on flip one (probability one-half): you win two dollars</li>
<li>Heads on flip two (probability one-quarter): you win four dollars</li>
<li>Heads on flip three (probability one-eighth): you win eight dollars</li>
<li>And so on, forever</li>
</ul>

<p>Now calculate the expected value. Each outcome contributes: probability times payout. So we get one-half times two dollars, plus one-quarter times four dollars, plus one-eighth times eight dollars. That's one dollar, plus one dollar, plus one dollar. Every term in this infinite sum equals exactly one dollar.</p>

<p>One plus one plus one plus one, continuing forever.</p>

<p>The expected value is infinite.</p>

<p>This means that if you <em>truly</em> believed in maximizing expected value—the cornerstone of rational decision-making in economics—you should mortgage your house to play this game. You should sell everything. Any finite price is a bargain compared to infinity.</p>

<p>But of course, nobody would actually do that. And the gap between what the math says and what any sensible person would do is the paradox.</p>

<h2>A Family Affair</h2>

<p>The problem was invented by Nicolas Bernoulli, a Swiss mathematician, who described it in a letter to Pierre Raymond de Montmort on September 9, 1713. But the paradox takes its name from Nicolas's cousin Daniel Bernoulli, who published his analysis in the Commentaries of the Imperial Academy of Science of Saint Petersburg in 1738—hence "Saint Petersburg."</p>

<p>The Bernoulli family was absurdly accomplished in mathematics. Over three generations, they produced eight prominent mathematicians. Nicolas and Daniel's work on probability and decision theory laid groundwork that economists still build on today. But in this case, they stumbled onto something that resisted easy answers.</p>

<p>Daniel Bernoulli captured the puzzle perfectly: "Although the standard calculation shows that the value of the player's expectation is infinitely great, it has to be admitted that any fairly reasonable man would sell his chance, with great pleasure, for twenty ducats."</p>

<p>Twenty ducats. Not infinity. Not even close.</p>

<h2>The Utility Solution</h2>

<p>Daniel Bernoulli's proposed solution was elegant and influential: the problem, he argued, is that we shouldn't care about money itself. We should care about what money does for us—its <em>utility</em>.</p>

<p>Think about it this way. If you have ten dollars and someone gives you another hundred, that's transformative—you can buy dinner, fill your gas tank, maybe catch a movie. But if you have ten million dollars and someone gives you another hundred, you barely notice. The same hundred dollars creates vastly different amounts of actual benefit depending on how much you already have.</p>

<p>Bernoulli suggested that the utility of money follows a logarithmic pattern. The jump from one dollar to ten dollars feels about as significant as the jump from ten dollars to a hundred, which feels about as significant as the jump from a hundred to a thousand. Each multiplication gives roughly equal satisfaction.</p>

<p>When you recalculate the Saint Petersburg game using logarithmic utility instead of raw dollars, something remarkable happens. The infinite sum suddenly converges to a finite number. A millionaire, by this math, should pay about twenty-one dollars to play. Someone with only a thousand dollars should pay about eleven. The answers start matching what people actually say.</p>

<p>This was a breakthrough. It introduced the concept of <em>expected utility</em>—the idea that rational decision-making isn't about maximizing money but maximizing the satisfaction that money brings. This concept became foundational to modern economics.</p>

<p>But there's a catch.</p>

<h2>The Paradox Strikes Back</h2>

<p>Gabriel Cramer, a mathematician from Geneva, had actually beaten Daniel Bernoulli to part of this insight by a decade. In 1728, Cramer wrote that "mathematicians estimate money in proportion to its quantity, and men of good sense in proportion to the usage that they may make of it."</p>

<p>But both Cramer's and Bernoulli's solutions have a vulnerability. You can construct a modified version of the game that brings the paradox roaring back.</p>

<p>How? Just make the payouts grow faster. If logarithmic utility tames the original game, design new payouts that grow exponentially faster than the logarithm shrinks them. Mathematician Karl Menger pointed this out: for <em>any</em> unbounded utility function—any function that keeps growing forever, no matter how slowly—you can construct a variant of the Saint Petersburg game that produces infinite expected utility.</p>

<p>This is like a mathematical arms race. Every proposed solution can be defeated by a cleverer version of the game. The only way to truly escape is to say that utility is <em>bounded</em>—that there's some maximum level of satisfaction, and beyond that point, more money simply doesn't help. But this seems philosophically strange. Is there really no difference between having a trillion dollars and having a trillion trillion?</p>

<h2>The Casino Goes Bankrupt</h2>

<p>Perhaps the most practical objection to the paradox is simply this: no casino could actually run this game.</p>

<p>The math assumes the casino has infinite resources. But of course it doesn't. If you flip tails thirty times in a row (probability about one in a billion), the casino would owe you over a billion dollars. Flip forty times? Over a trillion. At some point, the casino simply can't pay.</p>

<p>Georges-Louis Leclerc, the Comte de Buffon—a French naturalist better known for his work on biology—calculated in 1777 that after just twenty-nine rounds, the required payout would exceed all the money in the Kingdom of France.</p>

<p>When you factor in realistic limits, the expected value drops dramatically. Against a casino with a million dollars, the expected value is only about twenty dollars. Against the entire wealth of a modern nation, it might be thirty or forty dollars. Against all the money that exists on Earth—maybe fifty dollars. The "infinity" only appears when you assume impossible resources.</p>

<p>This resolution is satisfying in one way: it explains why no one offers this game and why no one would pay much to play it. But it sidesteps the deeper question. The paradox was meant to test our theories of rational choice. Saying "the game can't exist" doesn't tell us whether expected value maximization is the right way to think.</p>

<h2>Ignoring the Impossible</h2>

<p>The Comte de Buffon proposed another solution: reasonable people simply ignore events that are sufficiently unlikely.</p>

<p>He offered a wonderfully morbid way to calibrate this. A healthy fifty-six-year-old man, Buffon noted, doesn't spend his days worrying about dying in the next twenty-four hours—even though the mortality tables of his era put this probability at about one in ten thousand. If we routinely ignore risks at that level, Buffon argued, we should ignore coin-flip sequences that improbable too.</p>

<p>Cutting off the Saint Petersburg game at the point where probabilities drop below one in ten thousand leaves you with only thirteen relevant flips. The expected value? Exactly thirteen dollars. A far cry from infinity, and much closer to what people actually report.</p>

<p>This feels intuitively right. We <em>do</em> ignore sufficiently unlikely events in daily life. You don't refuse to leave your house because a meteor might hit you. But as a theory of rational choice, it has problems. Where exactly do you draw the line? Why one in ten thousand and not one in a hundred thousand? And isn't it a bit arbitrary to simply declare that unlikely enough events don't count?</p>

<h2>The Psychology of Risk</h2>

<p>Nicolas Bernoulli himself—the original inventor of the problem—suggested that people naturally underweight unlikely events. We don't properly account for those one-in-a-million possibilities, even when they carry enormous payoffs.</p>

<p>This intuition eventually flowered into prospect theory, developed by psychologists Daniel Kahneman and Amos Tversky in the late twentieth century. Prospect theory showed that people don't treat probabilities linearly. We tend to overweight small probabilities in some contexts (that's why people buy lottery tickets) and underweight them in others (that's why people underinsure against rare disasters).</p>

<p>But here's an ironic twist: in some versions of prospect theory, the Saint Petersburg paradox actually gets <em>worse</em>. The theory's probability weighting function can sometimes inflate the value of unlikely events rather than diminish it. Whether you escape the paradox depends on technical details about how curved the utility function is relative to the probability weights.</p>

<p>There's a deeper issue too. Paul Weirich argued that risk aversion should resolve the paradox—surely people are willing to accept lower expected value in exchange for certainty. But others point out that some people actively enjoy risk. They seek out gambling precisely because of the thrill. And it seems logically strange to say that making a game's prizes <em>bigger</em> should make people <em>less</em> willing to play.</p>

<h2>The Peter and Paul Problem</h2>

<p>Economist Paul Samuelson, a Nobel laureate, offered a different perspective entirely. Even if someone <em>could</em> run this game, he argued, they never <em>would</em>.</p>

<p>Think about it from the casino's side. If the expected value to the player is infinite, then the expected value to the house is <em>negative</em> infinity. The casino expects to lose an infinite amount of money. What rational operator would offer such a game at any finite price?</p>

<p>Samuelson put it memorably: "Paul will never be willing to give as much as Peter will demand for such a contract; and hence the indicated activity will take place at the equilibrium level of zero intensity." In plain language: no deal will ever be struck. The game exists only as a thought experiment because no one on either side would actually agree to play it.</p>

<p>This doesn't resolve the philosophical puzzle—it still seems like expected value maximization gives crazy answers—but it explains why we never encounter the paradox in practice.</p>

<h2>Time and Ergodicity</h2>

<p>A more recent approach attacks the problem from an unexpected angle: the physics of time.</p>

<p>Expected value calculations implicitly assume you can play a game infinitely many times and average the results. But you can't. You're one person with one life and one bankroll. Physicist Ole Peters argued that we should think about what happens to a single player over time, not what happens to an infinite population of players in a single instant.</p>

<p>When you do this math—analyzing the "time-average" rather than the "ensemble average"—the Saint Petersburg game looks very different. A real person playing repeatedly would, with probability approaching certainty, eventually go broke. The infinite expected value is a mirage created by averaging over possibilities that no individual would actually experience.</p>

<p>This connects to ideas from investment theory. The Kelly criterion, a formula for optimal bet sizing developed by physicist John Kelly at Bell Labs in 1956, tells you to bet a fraction of your bankroll proportional to your edge. It explicitly avoids bet sizes that could wipe you out, even if those bets have positive expected value. The Kelly criterion and logarithmic utility turn out to be mathematically related—different perspectives on the same underlying truth about sustainable decision-making.</p>

<h2>The Game Mutates</h2>

<p>As if the original paradox weren't troublesome enough, creative mathematicians have invented variants that defeat various proposed solutions.</p>

<p>Consider the "Pasadena game." Instead of the standard doubling payoffs, you win or lose based on whether the number of coin flips is odd or even. The payoff structure is designed so that the expected value depends on how you add up the terms. Rearrange the infinite sum one way, and you get one answer. Rearrange it another way, and you get a completely different answer. The expected value isn't just infinite—it's <em>undefined</em>.</p>

<p>This is mathematically legitimate. The sum involved is "conditionally convergent," meaning its value genuinely depends on the order of terms. It's like having a game where the expected value is simultaneously every number. What should a rational person pay for that?</p>

<h2>What the Paradox Teaches</h2>

<p>Three centuries after Nicolas Bernoulli first posed the problem, the Saint Petersburg paradox remains genuinely unresolved. Every proposed solution either has counterexamples, requires somewhat arbitrary assumptions, or sidesteps rather than answers the core question.</p>

<p>But perhaps that's the point. The paradox isn't a puzzle waiting to be solved—it's a permanent warning sign at the edge of decision theory.</p>

<p>Expected value maximization is a powerful tool. It works beautifully for insurance pricing, investment analysis, and countless practical applications. But push it far enough, into regimes of infinite resources and unbounded outcomes, and it starts giving answers that no sane person would follow.</p>

<p>This matters beyond mathematics. Modern finance, artificial intelligence, and public policy all use expected value calculations. The Saint Petersburg paradox reminds us that these calculations have limits. When stakes become extreme, when probabilities become tiny, when payoffs become astronomical, the standard framework may quietly stop working.</p>

<p>The paradox also reveals something about human nature. We don't actually maximize expected value, and maybe we <em>shouldn't</em>. We care about risk. We care about ruin. We care about what's likely, not just what's theoretically possible. Our instinctive reluctance to pay much for the Saint Petersburg game isn't irrationality—it might be wisdom that the mathematics hasn't yet captured.</p>

<p>Daniel Bernoulli's reasonable man, happily selling his chance for twenty ducats, understood something that the infinite expected value misses. The math is correct. The math is also, in some deep sense, wrong. That gap—between rigorous calculation and sound judgment—is where the paradox lives, as vital and unresolved today as it was in 1713.</p>
      </div>

      <footer class="wikipedia-footer">
        <p class="source-link">
          <a href="https://en.wikipedia.org/wiki/St._Petersburg_paradox" target="_blank" rel="noopener">
            View original Wikipedia article &rarr;
          </a>
        </p>
        <p class="rewrite-note">
          This article has been rewritten from Wikipedia source material for enjoyable reading.
          Content may have been condensed, restructured, or simplified.
        </p>
      </footer>

      
      <section class="related-articles">
        <h2>Related Articles</h2>
        <p class="related-intro">This deep dive was written in connection with these articles:</p>
        <ul class="related-list">
          
      <li class="related-article-item">
        <a href="../../article/bb5f22fd-1db4-47c0-bb87-956ec2ddc81d/index.html">
          <strong>Three Mistakes in “Three Mistakes in the Moral Mathematics of Existential Risk”</strong>
        </a>
        <span class="article-meta">
          by Bentham&#039;s Bulldog in 
        </span>
      </li>
        </ul>
      </section>
    
    </article>
  
  </main>
</body>
</html>