<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Principal–agent problem - Hex Index</title>
  <link rel="stylesheet" href="../../styles.css">
</head>
<body class="reading-mode">
  <header class="reading-header">
    <a href="../../index.html" class="back-link">&larr; Back to Library</a>
  </header>
  <main class="reading-content">
    
    <article class="wikipedia-page">
      <header class="wikipedia-header">
        <div class="type-badge">Wikipedia Deep Dive</div>
        <h1>Principal–agent problem</h1>
        <div class="article-meta">
          <span class="read-time">12 min read</span>
        </div>
      </header>

      <div class="wikipedia-content">
        <p class="source-note">Based on <a href="https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem">Wikipedia: Principal–agent problem</a></p>

<p>Your waiter wants you to have a wonderful evening. He also wants you to order the most expensive wine on the menu, linger over dessert, and leave a generous tip. These desires mostly align with yours—but not entirely. Welcome to one of the most pervasive problems in human organization, a problem that explains everything from why your real estate agent might not fight for the best price on your home to why corporate executives sometimes run companies into the ground while collecting millions in bonuses.</p>

<p>Economists call it the principal-agent problem, though you've experienced it a thousand times without knowing its name.</p>

<h2>The Basic Dilemma</h2>

<p>Here's the situation in its simplest form: You need someone to do something for you. Maybe you're a shareholder who needs executives to run a company. Maybe you're a citizen who needs politicians to govern. Maybe you're a patient who needs a doctor to recommend treatment. In each case, you're the "principal"—the person whose interests should be served. The person acting on your behalf is the "agent."</p>

<p>The problem? Your agent knows more than you do. And your agent has their own interests, which don't perfectly match yours.</p>

<p>Think about it. When your doctor recommends a procedure, are they thinking purely about your health? Or might they also be thinking about their malpractice insurance, the hospital's revenue targets, or the pharmaceutical rep who bought lunch last week? You can't know for certain because you weren't in medical school for eight years. You don't have access to the studies. You can't evaluate whether this doctor is exceptional or mediocre.</p>

<p>This information gap is called "asymmetric information," and it's the oxygen that lets the principal-agent problem breathe.</p>

<h2>Where the Theory Came From</h2>

<p>The formal study of this problem emerged in the 1970s, born from the marriage of economics and institutional theory. Two scholars, Stephen Ross and Barry Mitnick, both claim to have originated it—a fitting irony for a theory about conflicting interests. Ross reportedly described it with a charming example: imagine choosing an ice cream flavor for someone whose taste preferences you don't know. How do you act in their interest when you lack crucial information about what they actually want?</p>

<p>The paper that made the concept famous, though, came from Michael Jensen and William Meckling in 1976. They applied the framework to corporate governance, asking a pointed question: When shareholders own a company but managers run it, whose interests actually get served?</p>

<p>The answer, they suggested, was often "the managers' interests." And the cost of this misalignment—all the ways that agents' actions deviate from what principals would want—they called "agency costs."</p>

<h2>The Problem Multiplies</h2>

<p>It gets worse. What happens when an agent serves multiple principals at once?</p>

<p>Consider a politician. In theory, they serve all their constituents—the principal. But constituents don't speak with one voice. Some want lower taxes; others want more services. Some prioritize climate action; others prioritize jobs in coal country. The politician can't maximize everyone's interests simultaneously. So whose interests win?</p>

<p>Usually, it's the principals who organize most effectively. The ones who lobby. The ones who donate. The ones who show up. This creates what theorists call the "multiple principal problem," and it's particularly severe in the public sector, where agents theoretically serve millions of principals with wildly different preferences.</p>

<p>The quiet majority often loses to the vocal minority. Not through conspiracy, but through the simple mechanics of who can make their interests known.</p>

<h2>The Tipping Point</h2>

<p>Here's where the theory meets your dinner table.</p>

<p>Tipping is, at its core, an attempt to solve the principal-agent problem. You're the principal; your server is the agent. You want attentive service, honest recommendations, food that arrives hot. The server wants to maximize income while minimizing effort. How do you align these interests?</p>

<p>By making the server's pay contingent on your satisfaction.</p>

<p>A researcher at the New Zealand Institute for the Study of Competition and Regulation put it bluntly: tipping can efficiently match workers' attitudes to service with the jobs they perform. Friendly servers work harder, earn better tips, and make higher incomes. Grumpy servers either improve their disposition or find jobs better suited to their personalities—maybe in a back office somewhere, away from customers.</p>

<p>But tipping isn't a perfect solution. Consider the incentives it creates.</p>

<p>A server hoping for a generous tip might pour you an extra-large glass of wine. Delightful for you. Terrible for the restaurant's profit margin. That same server might lavish attention on tables that look like good tippers while neglecting others. The agent's interests are now aligned with some principals at the expense of others—and at the expense of the restaurant owner, yet another principal in this tangled web.</p>

<h2>Beyond Money: The Psychology of Motivation</h2>

<p>Here's something the early economists missed: people don't work purely for money.</p>

<p>Sociologists and psychologists have long argued that workers take pride in their craft. A carpenter cares about the quality of the joint. A nurse cares about patient outcomes. A programmer cares about elegant code. This intrinsic motivation—working well because it feels good to work well—is a powerful force.</p>

<p>And it can be destroyed.</p>

<p>When you tie everything to financial incentives, you risk transforming a rich human relationship into a narrow economic transaction. The carpenter who once took pride in invisible perfection might start cutting corners because corners aren't measured. The nurse might spend less time holding a dying patient's hand because hand-holding isn't tracked.</p>

<p>Research from the 1970s by Edward Deci and others suggested that external rewards can actually undermine internal motivation. Pay someone for a task they previously enjoyed, and they might start to enjoy it less. The joy was in the doing; now it's just a job.</p>

<p>Not everyone agrees with this interpretation—the evidence is contested. But it raises an uncomfortable question: Are we sometimes making the principal-agent problem worse by trying to solve it?</p>

<h2>The Team Problem</h2>

<p>Modern work is increasingly collaborative. Software is written by teams. Research is conducted by labs. Products are built by cross-functional groups. And this creates a nasty variant of the principal-agent problem.</p>

<p>When output reflects the contribution of many individuals, and you can't easily identify who did what, how do you reward performance?</p>

<p>The temptation is to reward the team based on collective output. But this invites free-riding. Why should I work late when my extra effort gets diluted across ten team members? Economist Bengt Holmström analyzed this in 1982 and found that individual pay-for-performance becomes less effective as team production increases.</p>

<p>Australian research confirmed the dark side: workers placed on individual pay-for-performance schemes become less likely to help their coworkers. Why would they? Helping others doesn't help their bonus. In fact, it might hurt it if their coworkers outperform them.</p>

<p>So collective incentives encourage free-riding, and individual incentives discourage cooperation. Organizations need both cooperation and individual effort. There's no clean solution.</p>

<p>Some research suggests that peer pressure can help—if coworkers can monitor and sanction each other at low cost. But this introduces its own problems. Do you really want a workplace where everyone is watching everyone else for signs of slacking?</p>

<h2>The Numbers Game</h2>

<p>Despite the complications, there's strong evidence that financial incentives work—at least for certain jobs.</p>

<p>Economist Edward Lazear studied a company that switched from salaries to piece rates—paying workers per unit produced rather than per hour worked. Productivity jumped 44 percent. Wages rose 10 percent. Half of the productivity gain came from an interesting source: worker selection. When you pay for performance, high performers are attracted and low performers leave. The workforce composition changes.</p>

<p>Other studies tell similar stories. British jockeys perform significantly better when paid a percentage of prize money rather than flat retainers. Chinese agricultural reforms that introduced individual incentives led to dramatic productivity increases. Real estate agents sell their own homes for about 4.5 percent more than they sell their clients' homes—suggesting they don't fight quite as hard for you as they do for themselves.</p>

<p>But here's the catch: these effects are strongest for "simple" jobs where output is easily measured. Factory piece rates. Sales commissions. Race winnings. When work is creative, complex, or collaborative, the relationship between pay and performance becomes murkier. Some research suggests that pay-for-performance actually reduces creative output. When you're focused on the reward, you take fewer risks. You try fewer unconventional approaches. You optimize for the measured outcome rather than the best outcome.</p>

<h2>The Executive Suite</h2>

<p>Which brings us to corporate executives—perhaps the most consequential arena for the principal-agent problem.</p>

<p>Chief Executive Officers (CEOs) are agents of shareholders. In theory, their compensation should align their interests with the owners'. In practice, the correlation between CEO pay and company performance is remarkably weak. Some CEOs collect enormous bonuses while their companies founder. Others receive modest pay while generating tremendous value.</p>

<p>Why the disconnect? Several reasons.</p>

<p>First, CEO performance is genuinely hard to measure. Was that stock price increase due to executive genius or a rising tide that lifted all boats? Was that acquisition brilliant or lucky? You often can't know for years.</p>

<p>Second, who sets CEO pay? Typically, the board of directors—people often selected with significant input from the CEO. The agent has influence over the principal's representatives. The fox isn't guarding the henhouse, but it's helping choose the security system.</p>

<p>Third, CEOs can manipulate the metrics on which they're measured. When compensation depends on stock price, executives have incentives to make decisions that boost short-term stock price even at the expense of long-term value. Announcing layoffs often causes stock prices to rise. So does cutting research and development. These decisions might destroy value over time, but by then, the CEO has cashed out and moved on.</p>

<p>Researchers have found that CEOs exhibit what they call "risk aversion" in effort—when not offered strong incentives, they tend to play it safe, inputting less work and taking fewer chances. Incentives do seem to increase effort. But designing incentives that reward genuine value creation rather than metric manipulation remains an unsolved problem.</p>

<h2>The Information Principle</h2>

<p>In 1979, economist Bengt Holmström developed what he called the "Informativeness Principle." The idea is elegant: any measure that reveals information about the agent's effort should be included in the compensation contract.</p>

<p>What does this mean in practice?</p>

<p>Consider a sales representative whose territory happens to include a booming region. Their sales numbers look great—but is that due to their skill or their luck? The Informativeness Principle suggests comparing their performance to other representatives in similar territories. If everyone in booming regions is doing well, maybe this rep isn't doing anything special. If this rep is outperforming peers in comparable situations, that's meaningful information.</p>

<p>This "relative performance evaluation" filters out noise. It removes what economists call "exogenous sources of randomness"—factors outside the agent's control. What remains is a purer signal of actual effort and skill.</p>

<p>But relative evaluation creates its own problems. Now your agent is being compared to peers. What's the easiest way to look good by comparison? Make your peers look bad. Suddenly you've created incentives for sabotage, or at least for withholding help.</p>

<h2>No Perfect Solution</h2>

<p>The management theorist W. Edwards Deming, famous for his influence on Japanese manufacturing and the quality movement, included performance-based compensation in what he called the "Seven Deadly Diseases of Management." He argued that such systems destroy teamwork, foster rivalry, and focus attention on short-term metrics at the expense of long-term quality.</p>

<p>Deming might have been too absolute. The evidence suggests incentive systems can work well in some contexts—particularly simple, measurable, individual tasks. But he was pointing at something real: the principal-agent problem doesn't have a clean solution. Every mechanism for aligning interests creates new distortions.</p>

<p>Piece rates improve productivity but reduce cooperation. Team incentives foster collaboration but invite free-riding. Relative evaluation filters noise but encourages sabotage. Stock options align executives with shareholders but encourage short-termism. The list goes on.</p>

<h2>Living with the Problem</h2>

<p>So what do we do?</p>

<p>First, recognize that the problem is inherent to any situation where someone acts on another's behalf. It's not going away. Every relationship between a professional and a client, an employee and an employer, a politician and a constituent involves misaligned interests and asymmetric information.</p>

<p>Second, design systems that acknowledge the trade-offs rather than pretending they don't exist. Profit-sharing seems to boost productivity by about three to five percent—not transformative, but meaningful. Mixing intrinsic and extrinsic motivation often works better than relying on either alone. Transparency about metrics reduces gaming. Competition between agents can help, if the competition isn't so intense that it destroys cooperation.</p>

<p>Third, invest in trust. When principals and agents trust each other, they can operate with lower monitoring costs and more flexibility. Trust doesn't eliminate the principal-agent problem, but it reduces its severity. Building trust takes time and requires principals to accept some vulnerability.</p>

<p>Finally, remember the limits of economics. The principal-agent framework is powerful, but it's not complete. People are motivated by pride, by meaning, by relationships, by identity—not just by money. Sometimes the best way to get good work from an agent is to hire someone who cares about the work, treat them with respect, and then get out of their way.</p>

<p>The waiter who genuinely wants you to have a great meal will usually serve you better than the waiter who's just calculating tips. The challenge is creating an environment where that genuine care can flourish—while still having some incentives in place for those who need them.</p>

<p>It's a balance we're always getting wrong, always adjusting, never perfecting. Which might be the most honest thing to say about the principal-agent problem: it's not really a problem to be solved. It's a condition to be managed, imperfectly and forever.</p>
      </div>

      <footer class="wikipedia-footer">
        <p class="source-link">
          <a href="https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem" target="_blank" rel="noopener">
            View original Wikipedia article &rarr;
          </a>
        </p>
        <p class="rewrite-note">
          This article has been rewritten from Wikipedia source material for enjoyable reading.
          Content may have been condensed, restructured, or simplified.
        </p>
      </footer>

      
      <section class="related-articles">
        <h2>Related Articles</h2>
        <p class="related-intro">This deep dive was written in connection with these articles:</p>
        <ul class="related-list">
          
      <li class="related-article-item">
        <a href="../../article/aec41562-90cc-4502-a5ef-ad9de64d1d63/index.html">
          <strong>Okta’s Ric Smith: Your AI Agent Is Roaming The Office Hallway. Do You Know What It&#039;s Doing?</strong>
        </a>
        <span class="article-meta">
          by Alex Kantrowitz in Big Technology
        </span>
      </li>

      <li class="related-article-item">
        <a href="../../article/29ffadfb-4371-41f1-8c54-2a79e4c0dd78/index.html">
          <strong>Not getting incentives right can kill a security initiative or a security startup</strong>
        </a>
        <span class="article-meta">
          by Ross Haleliuk in Venture in Security
        </span>
      </li>
        </ul>
      </section>
    
    </article>
  
  </main>
</body>
</html>